{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# links to scrape:\n",
    "### - [ph.com model-page](https://pornhub.com/model/heather-kane/)\n",
    "### - [ph.com hot-videos-page](https://pornhub.com/)\n",
    "### - OTHER PEOPLES VIDEOS (comment)\n",
    "\n",
    "---\n",
    "\n",
    "# two paths:\n",
    "\n",
    "1) crawl\n",
    "\n",
    "2) comment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *ATTEMPT-1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-17 15:23:09,219 root   DEBUG    === Initialized Proxy Parsers ===\n",
      "2019-11-17 15:23:09,361 root   DEBUG    \t FreeProxy parser of 'http://free-proxy-list.net' with required bandwidth: '150' KBs\n",
      "2019-11-17 15:23:09,366 root   DEBUG    \t PremProxy parser of 'https://premproxy.com/list/' with required bandwidth: '150' KBs\n",
      "2019-11-17 15:23:09,366 root   DEBUG    =================================\n",
      "2019-11-17 15:23:10,837 root   DEBUG    Added 300 proxies from FreeProxy\n",
      "2019-11-17 15:23:11,379 http_request_randomizer.requests.parsers.PremProxyParser DEBUG    Pages: {'', '04.htm', '09.htm', '03.htm', '02.htm', '07.htm', '05.htm', '08.htm', '06.htm'}\n",
      "2019-11-17 15:23:11,798 http_request_randomizer.requests.parsers.js.UnPacker INFO     JS UnPacker init path: https://premproxy.com/js/c6d6c.js\n",
      "2019-11-17 15:23:12,347 http_request_randomizer.requests.parsers.js.UnPacker DEBUG    portmap: {'r1a1f': '8080', 'r2dcd': '51162', 'reb25': '80', 'r5b67': '47253', 'rca58': '58461', 'r786d': '999', 'r1938': '34930', 'rb755': '59763', 'ra275': '3128', 'r0eba': '51376', 'r3147': '54685', 'rdc38': '39012', 'r3dd5': '58732', 'r413a': '23500', 'r1b0e': '53281', 'r343a': '39181', 'r82bc': '57797', 'r99e2': '33630', 'rabb7': '61209', 'rdf62': '8081', 'rdda7': '38581', 'ra740': '65205', 'r49d9': '20183', 'rfb9a': '38182', 'ra7f0': '41312', 'r6a8f': '55714', 'rebb4': '30544', 'r5644': '53990', 'rc977': '40155', 'r1d48': '51392', 'rd5e7': '51650', 'r5ebd': '48242', 'rb6f4': '55090', 'r9e5f': '88', 'r3624': '63000', 'r6cee': '34880', 'r28a9': '42248', 'rfe1e': '61911', 'r9a80': '57646', 'r970c': '39371', 'r3d38': '57482', 'rc926': '30139', 'rf4a8': '43980', 'r21ee': '41258', 'rf88d': '46611', 'r0c73': '37584', 'rf187': '55045', 'r6907': '40573', 'r3172': '38525', 'r01e5': '30565', 'rd42d': '8811', 'r0169': '30323', 'rdb85': '34824', 'ref7c': '32022', 'r0b75': '48678', 'r5082': '47738', 'r4a2f': '31673', 'rad73': '33611', 'rd535': '3129', 'rbba4': '8888', 'rd7a7': '52378', 'r1f83': '6666', 'r49b0': '33735', 'r2e96': '51221', 'rc262': '29965', 'r72f5': '41325', 'r7207': '8585', 're343': '48958', 'r1594': '3135', 'r9b5b': '3133', 'r02e9': '57548', 'r5d33': '37251', 'r043e': '47314', 'r7834': '44072', 'r7413': '37545', 'r1596': '9090', 'rcb42': '57444', 'r9577': '41537', 'raba4': '48439', 're3c6': '32836', 'r606e': '8118', 'rb870': '57914', 'rd3a1': '32626', 'r5eb4': '48458', 'rc41d': '41049', 'rb5bc': '30726', 'r5934': '57837', 'r05aa': '49031', 'r2cb0': '52890', 'r7167': '45282', 'r13a1': '51007', 'rfa22': '30573', 'rf942': '38195', 'rc096': '33729', 'r48a4': '30736', 'r9c5e': '45014', 'rfd28': '36104', 'r26cc': '59280', 'r737e': '34511', 'r6d75': '43523', 'r1ba6': '49846', 'r9198': '54179', 'rbc98': '53991', 'rd6b5': '42925', 'racb9': '54490', 'rfd95': '51027', 'r3414': '51024', 'r417f': '50136', 'r0a14': '53570', 'r0c2f': '43747', 'r78c4': '51850', 'r22cd': '30250', 'rafa6': '59404', 'r35e9': '37211', 'r1ce9': '37947', 'r9b80': '32040', 'rdbbf': '47087', 'r19f9': '59355', 'r2b91': '9999', 'r59ca': '56618', 'rf4e1': '60944', 'r282d': '33895', 'r86d4': '34184', 'r32d3': '44061', 'r96d3': '36739', 'r0523': '33446', 'rccff': '35202', 'rb974': '31892', 'rab42': '49201', 'r768d': '54421', 'rff37': '1218', 'r974c': '34084', 'r07f7': '45156', 'r1a8e': '45637', 'r689f': '40329', 'r544a': '34561', 'r8600': '53692', 'r65a7': '34740', 'r5d5a': '40080', 'rbdc0': '46974', 'r2b34': '54921', 'r6c64': '36543'}\n",
      "2019-11-17 15:23:19,358 root   DEBUG    Added 386 proxies from PremProxy\n",
      "2019-11-17 15:23:19,359 root   DEBUG    Total proxies = 686\n",
      "2019-11-17 15:23:19,373 root   DEBUG    Filtered proxies = 686\n"
     ]
    }
   ],
   "source": [
    "from http_request_randomizer.requests.proxy.requestProxy import RequestProxy\n",
    "req_proxy = RequestProxy() #you may get different number of proxy when  you run this at each time\n",
    "proxies = req_proxy.get_proxy_list() #this will create proxy list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check IP address and country of proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'103.92.212.242:43399'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxies[0].get_address()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bangladesh'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxies[0].country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use in **Firefox**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "PROXY = proxies[0].get_address()\n",
    "webdriver.DesiredCapabilities.FIREFOX['proxy']={\n",
    "    \"httpProxy\":PROXY,\n",
    "    \"ftpProxy\":PROXY,\n",
    "    \"sslProxy\":PROXY,\n",
    "    \n",
    "    \"proxyType\":\"MANUAL\",\n",
    "    \n",
    "}\n",
    "driver = webdriver.Firefox(executable_path=\"C:/FireFox/geckodriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use in Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-17 15:45:47,076 selenium.webdriver.remote.remote_connection DEBUG    POST http://127.0.0.1:51746/session {\"capabilities\": {\"firstMatch\": [{}], \"alwaysMatch\": {\"browserName\": \"chrome\", \"platformName\": \"any\", \"proxy\": {\"httpProxy\": \"103.92.212.242:43399\", \"ftpProxy\": \"103.92.212.242:43399\", \"sslProxy\": \"103.92.212.242:43399\", \"proxyType\": \"manual\"}, \"goog:chromeOptions\": {\"extensions\": [], \"args\": []}}}, \"desiredCapabilities\": {\"browserName\": \"chrome\", \"version\": \"\", \"platform\": \"ANY\", \"proxy\": {\"httpProxy\": \"103.92.212.242:43399\", \"ftpProxy\": \"103.92.212.242:43399\", \"sslProxy\": \"103.92.212.242:43399\", \"proxyType\": \"MANUAL\"}, \"goog:chromeOptions\": {\"extensions\": [], \"args\": []}}}\n",
      "2019-11-17 15:45:50,868 selenium.webdriver.remote.remote_connection DEBUG    Finished Request\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "PROXY = proxies[0].get_address()\n",
    "webdriver.DesiredCapabilities.CHROME['proxy']={\n",
    "    \"httpProxy\":PROXY,\n",
    "    \"ftpProxy\":PROXY,\n",
    "    \"sslProxy\":PROXY,\n",
    "    \n",
    "    \"proxyType\":\"MANUAL\",\n",
    "    \n",
    "}\n",
    "driver = webdriver.Chrome()\n",
    "# [2019-11-17]\\\\(executable_path= r\"C:\\Users\\siddhartha\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your IP address in browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-17 15:45:55,245 selenium.webdriver.remote.remote_connection DEBUG    POST http://127.0.0.1:51746/session/9585c13044df01dac83fe9ca5903bee4/url {\"url\": \"https://www.expressvpn.com/what-is-my-ip\"}\n",
      "2019-11-17 15:46:17,019 selenium.webdriver.remote.remote_connection DEBUG    Finished Request\n"
     ]
    }
   ],
   "source": [
    "driver.get('https://www.expressvpn.com/what-is-my-ip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *ATTEMPT-2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-17 17:04:02,216 root   DEBUG    === Initialized Proxy Parsers ===\n",
      "2019-11-17 17:04:02,222 root   DEBUG    \t FreeProxy parser of 'http://free-proxy-list.net' with required bandwidth: '150' KBs\n",
      "2019-11-17 17:04:02,222 root   DEBUG    \t PremProxy parser of 'https://premproxy.com/list/' with required bandwidth: '150' KBs\n",
      "2019-11-17 17:04:02,223 root   DEBUG    =================================\n",
      "2019-11-17 17:04:02,674 root   DEBUG    Added 300 proxies from FreeProxy\n",
      "2019-11-17 17:04:03,081 http_request_randomizer.requests.parsers.PremProxyParser DEBUG    Pages: {'', '05.htm', '07.htm', '03.htm', '11.htm', '04.htm', '06.htm', '10.htm', '08.htm', '02.htm', '09.htm'}\n",
      "2019-11-17 17:04:03,471 http_request_randomizer.requests.parsers.js.UnPacker INFO     JS UnPacker init path: https://premproxy.com/js/0bebd.js\n",
      "2019-11-17 17:04:03,886 http_request_randomizer.requests.parsers.js.UnPacker DEBUG    portmap: {'r15b6': '8080', 'r6dc8': '53281', 'r7468': '80', 'r546d': '47253', 'r609d': '58461', 'r3aa0': '999', 'r39f5': '8000', 'r1218': '8081', 'rc195': '47244', 'r118d': '56955', 'rb765': '3128', 'r1b9c': '45305', 'r1a5f': '443', 'r8e59': '58710', 'r758c': '8888', 'r50e1': '65301', 'r9a61': '60122', 'r04d6': '40536', 'rb98f': '56609', 'r8880': '35090', 'rd3c3': '57797', 'r613d': '60020', 'r7a82': '59994', 'r1da4': '52335', 'r3976': '35406', 'ra827': '38581', 'r1ad4': '65205', 'r3883': '38723', 'rd87b': '20183', 'ra1c2': '55714', 'r5058': '41374', 're706': '55667', 'r55c6': '37790', 'rd70c': '54351', 'r4fdc': '51392', 'rcd14': '40155', 'r41b5': '36127', 'r08be': '9999', 'r4739': '65001', 'r5a9e': '35690', 'r7909': '43459', 'r15fa': '43659', 'r4ad1': '45999', 'r7d8d': '36681', 'rc647': '34273', 'r689e': '30139', 'r733f': '57482', 'r4830': '41258', 'rcd9c': '53038', 'r31cb': '46611', 'r0b49': '37584', 'r4f32': '44097', 'r96c3': '52622', 'r752c': '44811', 'r2224': '58727', 'r39c3': '49302', 'r3631': '38525', 'rd6f8': '45053', 'r303f': '30565', 'r340a': '8118', 're4cf': '8123', 're62f': '51194', 'r8536': '34824', 'r81f1': '32022', 'rd35d': '36036', 'r8f1a': '48678', 'r3131': '50892', 'rb85a': '49016', 'r2f05': '38123', 'rd664': '42382', 'r6ef7': '55619', 'r3a9e': '3129', 'r5f5a': '61623', 'r9308': '52378', 'r71f7': '47186', 'r313a': '36253', 'r7250': '84', 'rdccf': '35101', 'rd53c': '63141', 'rc918': '31475', 'rf055': '50617', 'r95fb': '3131', 'r673d': '3135', 'rc430': '3137', 'r098f': '50357', 'rf354': '46909', 'rbe1d': '30560', 'rd073': '38038', 'r013c': '60045', 'r4162': '57735', 'rd962': '30665', 'r5a1e': '52261', 'rf59a': '53268', 'raeec': '49693', 'r419f': '40945', 'r8bee': '32529', 'rd290': '41537', 'rcf2c': '57444', 'r2ddd': '48439', 're251': '37547', 'r3fe5': '41091', 'r0b14': '38662', 'ra311': '61367', 'r76f5': '31977', 'r3bb4': '48458', 'rb090': '56145', 'r1d02': '41049', 'r7257': '38717', 'rcc2a': '36792', 'rad23': '30726', 'r7dbb': '58047', 'ra666': '52890', 'rc8e8': '45282', 'r2735': '32483', 'r13f8': '51007', 'r72a0': '38195', 'r9866': '54375', 'r8cd5': '38998', 'r1bda': '56466', 'r5120': '48047', 'rca43': '59280', 'r2794': '34511', 'rd5ee': '45218', 'rcf8f': '23500', 'ra23b': '42890', 'r2bb3': '59565', 'red78': '49846', 'ra206': '54179', 'r4b75': '40485', 'r59ea': '53991', 'r4575': '35332', 'rfae0': '33035', 'r6f75': '49377', 'rcc44': '51024', 'r6e40': '46003', 'rfd4b': '54290', 'r2b6a': '49674', 'r4dc2': '30290', 'r546c': '30250', 'r78c2': '31899', 'rbb2e': '43615', 'rbbb0': '59061', 'rb698': '59355', 'r4817': '56130', 're351': '49010', 'r851c': '53100', 'r9a1b': '34184', 'r077e': '37979', 'r4c95': '37641', 'reeae': '44061', 'r1f90': '36739', 'r5025': '35276', 'r9f8e': '35202', 'r54b1': '46799', 're42b': '56975', 'ra8e4': '59648', 'r1b24': '1108', 'r7a3c': '53245', 'reb98': '1289', 'rf73a': '32125', 'r1627': '4444', 'rebaf': '59324', 'r889a': '60636', 'rd2b3': '8213', 'r4018': '34514', 're036': '44274', 'raf14': '35116', 'r52ce': '34638', 'r5624': '45156', 'r3d76': '9090', 'rd94b': '42608', 'rb3f4': '52782', 'rba52': '34561', 'rcb15': '53692', 'r4daf': '34740', 're388': '42550', 'rf4cf': '58388', 'r03cd': '31893', 'r9fd5': '46974', 'r796c': '36543', 'r7787': '54921'}\n",
      "2019-11-17 17:04:08,379 root   DEBUG    Added 496 proxies from PremProxy\n",
      "2019-11-17 17:04:08,380 root   DEBUG    Total proxies = 796\n",
      "2019-11-17 17:04:08,381 root   DEBUG    Filtered proxies = 796\n"
     ]
    }
   ],
   "source": [
    "from http_request_randomizer.requests.proxy.requestProxy import RequestProxy\n",
    "req_proxy = RequestProxy() #you may get different number of proxy when  you run this at each time\n",
    "proxies = req_proxy.get_proxy_list() #this will create proxy list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'213.80.235.59:55887'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxies[0].get_address()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Russian Federation'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxies[0].country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-17 17:04:12,395 selenium.webdriver.remote.remote_connection DEBUG    POST http://127.0.0.1:54981/session {\"capabilities\": {\"firstMatch\": [{}], \"alwaysMatch\": {\"browserName\": \"firefox\", \"acceptInsecureCerts\": true, \"proxy\": {\"httpProxy\": \"213.80.235.59:55887\", \"ftpProxy\": \"213.80.235.59:55887\", \"sslProxy\": \"213.80.235.59:55887\", \"proxyType\": \"manual\"}}}, \"desiredCapabilities\": {\"browserName\": \"firefox\", \"acceptInsecureCerts\": true, \"proxy\": {\"httpProxy\": \"213.80.235.59:55887\", \"ftpProxy\": \"213.80.235.59:55887\", \"sslProxy\": \"213.80.235.59:55887\", \"proxyType\": \"MANUAL\"}, \"marionette\": true}}\n",
      "2019-11-17 17:04:24,612 selenium.webdriver.remote.remote_connection DEBUG    Finished Request\n",
      "2019-11-17 17:04:24,613 selenium.webdriver.remote.remote_connection DEBUG    POST http://127.0.0.1:54981/session/57c06779-fcd3-48a2-adf1-653598c0c329/url {\"url\": \"https://www.expressvpn.com/what-is-my-ip\"}\n",
      "2019-11-17 17:04:27,419 selenium.webdriver.remote.remote_connection DEBUG    Finished Request\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: Reached error page: about:neterror?e=proxyConnectFailure&u=https%3A//www.expressvpn.com/what-is-my-ip&c=UTF-8&f=regular&d=Firefox%20is%20configured%20to%20use%20a%20proxy%20server%20that%20is%20refusing%20connections.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-eb942bee5b5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFirefox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C:/FireFox/geckodriver.exe\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.expressvpn.com/what-is-my-ip'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \"\"\"\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: Reached error page: about:neterror?e=proxyConnectFailure&u=https%3A//www.expressvpn.com/what-is-my-ip&c=UTF-8&f=regular&d=Firefox%20is%20configured%20to%20use%20a%20proxy%20server%20that%20is%20refusing%20connections.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "PROXY = proxies[0].get_address()\n",
    "webdriver.DesiredCapabilities.FIREFOX['proxy']={\n",
    "    \"httpProxy\":PROXY,\n",
    "    \"ftpProxy\":PROXY,\n",
    "    \"sslProxy\":PROXY,\n",
    "    \n",
    "    \"proxyType\":\"MANUAL\",\n",
    "    \n",
    "}\n",
    "driver = webdriver.Firefox(executable_path=\"C:/FireFox/geckodriver.exe\")\n",
    "\n",
    "driver.get('https://www.expressvpn.com/what-is-my-ip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "import random, fnmatch, logging\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import WebDriverException as WDE\n",
    "from selenium.webdriver.common.proxy import Proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "# IMPORT THE LIBRARY USED TO QUERY A WEBSITE\n",
    "from urllib.request import urlopen\n",
    "import wget\n",
    "from random import choice, randint\n",
    "from threading import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger(): #{\n",
    "    # RE-INSTANTIATE GLOBAL\n",
    "    global timestamp_str\n",
    "    # TRY THE FOLLOWING\n",
    "    try: #{\n",
    "        logging.basicConfig(level=logging.INFO,\n",
    "                           format=\"%(asctime)s:%(message)s\",\n",
    "                           filename=\"C:/data/Logs/PH-BOT-\" + timestamp_str + \".log\",\n",
    "                           filemode=\"a\")\n",
    "    #}\n",
    "    except: #{\n",
    "        print(\"failed setting up logger yo\")\n",
    "    #}\n",
    "    else: #{\n",
    "        print(\"SUCCESS! VERY NICE!\")\n",
    "    #}\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class phBot(): #{\n",
    "    \n",
    "    # INSTANTIATE CLASS VARIABLES\n",
    "    \n",
    "    # [2019-11-04]\\\\out_directory = \"C:/data/outbound/ph_viewer\"\n",
    "    ts_date_str = str(pd.Timestamp.now())[:10]\n",
    "    ts_time_str = str(pd.Timestamp.now())[11:19]\n",
    "    ts_time_str = ts_time_str.replace(\":\",\"-\")\n",
    "    logging_directory = \"C:/data/Logs/PH-BOT-\" + ts_time_str + \".log\"\n",
    "    timestamp_str = ts_date_str + \"_\" + ts_time_str\n",
    "    links_df = pd.DataFrame(data=None, dtype=np.str)\n",
    "    \n",
    "    def __init__(self, infile, duration): #{\n",
    "        self.infile = infile\n",
    "        self.duration = duration\n",
    "        # DRIVER VARIABLE\n",
    "        print(\"...SETTING UP DRIVER...\")\n",
    "        self.driver = webdriver.Chrome()\n",
    "        self.driver.maximize_window()\n",
    "        print(\"infile == \" + str(self.infile))\n",
    "        print(\"duration == \" + str(duration))\n",
    "        print(\"\\nREADING IN 'infile' \\n\")\n",
    "        # OVERWRITE / SAVE DATAFRAME\n",
    "        self.links_df = pd.read_csv(self.infile, names=['Link','Count'], dtype=np.str, engine='python')\n",
    "        print(\"len of infile == \" + str(len(self.links_df)))\n",
    "        # PRINT OUT DATAFRAME HEAD \n",
    "        print(str(self.links_df.head()))\n",
    "    #}\n",
    "    \n",
    "    def countdown(n): #{\n",
    "        while n >= 0: #{\n",
    "            print(str(n))\n",
    "            sleep(1)\n",
    "            n -= 1\n",
    "        #}\n",
    "        else: #{\n",
    "            print(\"blast off!\")\n",
    "        #}\n",
    "    #}\n",
    "    \n",
    "    def get_proxy(self): #{\n",
    "        url = \"https://www.ssslproxies.org\"\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.content, 'html5lib')\n",
    "        return {'https': choice(list(map(lambda x:x[0]+':'+x[1], list(zip(map(lambda x:x.text, soup.findAll('td')[::8]), \n",
    "                                                                          map(lambda x:x.text, soup.findAll('td')[1::8]))))))}\n",
    "    #}\n",
    "    \n",
    "    def proxy_request(self, request_type, url, **kwargs): #{\n",
    "        while 1: #{\n",
    "            try: #{\n",
    "                proxy = self.get_proxy()\n",
    "                print(\"Using proxy: {}\".format(proxy))\n",
    "                r = requests.request(request_type, url, proxies=proxy, timeout=5, **kwargs)\n",
    "                break\n",
    "            #}\n",
    "            except: #{\n",
    "                pass\n",
    "            #}\n",
    "        #}\n",
    "        return r\n",
    "    #}\n",
    "    \n",
    "    def visit_site(self, site_url): #{\n",
    "        self.driver.get(site_url)\n",
    "    #}\n",
    "    \n",
    "    def get_video_count(self, video_url): #{\n",
    "        # CREATE NEW VAR FOR RETURN\n",
    "        counts = []\n",
    "        # GET REQUEST FROM URL LINK\n",
    "        r = requests.get(url)\n",
    "        # set request to text\n",
    "        data = r.text\n",
    "        # CREATE SEXY SOUP OBJECT\n",
    "        soup = BeautifulSoup(data)\n",
    "        count_list = soup.find_all('span', {'class':'count'})\n",
    "        \n",
    "        for count in count_list: #{\n",
    "            print(count.get_text())\n",
    "            counts.append(str(count.get_text()))\n",
    "        #}\n",
    "        # RETURN LIST OF COUNTS\n",
    "        return str(counts[0])\n",
    "    #}\n",
    "    \n",
    "    def teardown_driver(self): #{\n",
    "        # quit/end driver\n",
    "        self.driver.close()\n",
    "    #}\n",
    "    \n",
    "    def crawl_video_list(self): #{\n",
    "        # CREATE DATAFRAME TO HOLD LINKS\n",
    "        #links_df = pd.DataFrame(data=links, dtype= np.str)\n",
    "        the_list = list(self.links_df['Link'])\n",
    "        print(\"[START]=============[START]\")\n",
    "        # setup variables\n",
    "        sleep_time = int(self.duration)\n",
    "        #####################\n",
    "        # check input types #\n",
    "        #####################\n",
    "        if type(the_list) is list: #{\n",
    "            print(\"...list lenth == \" + str(len(the_list)))\n",
    "            print(\"...generating random number...\")\n",
    "            rand_vid_num = randint(0, len(the_list))\n",
    "            print(\"\\t\" + str(rand_vid_num))\n",
    "            print(\"THIS IS THE LIST:\")\n",
    "            # lOOP THROUGH\n",
    "            for list_item in the_list: #{\n",
    "                # VISIT WEBSITE\n",
    "                self.driver.get(str(list_item))\n",
    "                print(list_item)\n",
    "                # PRINT SITE TITLE\n",
    "                print(str(self.driver.title))\n",
    "                sleep(sleep_time)\n",
    "            #}\n",
    "            print(\"[END]============[END]\")\n",
    "            # pop off item from list\n",
    "            lepop = the_list.pop(0)\n",
    "            print(\"LIST ITEM POPPED: \" + str(lepop) + \"\\n[end-TRAVERSE&DROP]==========\")\n",
    "            # RECURSIVE CALL\n",
    "            #traverse_and_drop(the_list, sleep_time + 1)\n",
    "        #}\n",
    "        elif type(the_list) is pd.core.frame.DataFrame : #{\n",
    "            # LOOP THRU DATAFRAME\n",
    "            for item in the_list.itertuples(index=False): #{\n",
    "                print(item)\n",
    "            #}\n",
    "        #}\n",
    "        else: #{\n",
    "            print(\"not a list\")\n",
    "        #}\n",
    "    #}\n",
    "    \n",
    "    def print_list(self): #{\n",
    "        print(str(self.links_df['Link']))\n",
    "    #}\n",
    "    \n",
    "    def post_comments(self, link_to_comment, comment_to_post): #{\n",
    "        pass\n",
    "    #}\n",
    "    \n",
    "    def download_thumbnails(self, url_link): #{\n",
    "        pass\n",
    "    #}\n",
    "    \n",
    "    def enlarge_image(the_image_file, save_location): #{\n",
    "        pass\n",
    "    #}\n",
    "    \n",
    "    def scrape_urls(self, url_to_scrape, save_location): #{\n",
    "        pass\n",
    "    #}\n",
    "    \n",
    "    def check_file(self, infile): #{\n",
    "        print(infile)\n",
    "        print(self.infile)\n",
    "    #}\n",
    "    \n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": #{\n",
    "    # CREATE INSTANCE OF BOT\n",
    "    ph_apollo = phBot(infile=\"c:/data/inbound/PH_list.csv\", duration=randint(120, 360))\n",
    "    # PRINT OUT VIDEO_CRAWL_LIST\n",
    "    ph_apollo.print_list()\n",
    "    # SET BOT TO BEGIN CRAWL...\n",
    "    ph_apollo.crawl_video_list(interval_num=45)\n",
    "#}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def setup_driver(self): #{\n",
    "    self.driver = webdriver.Chrome()\n",
    "    self.driver.minimize_window()\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infile == C:/data/inbound/PH_list.csv\n",
      "duration == 30\n",
      "len of infile == 21\n",
      "  https://www.pornhub.com/view_video.php?viewkey=ph5d47460626ec3  3\n",
      "0  https://www.pornhub.com/view_video.php?viewkey...              4\n",
      "1  https://www.pornhub.com/view_video.php?viewkey...              2\n",
      "2  https://www.pornhub.com/view_video.php?viewkey...              2\n",
      "3  https://www.pornhub.com/view_video.php?viewkey...              6\n",
      "4  https://www.pornhub.com/view_video.php?viewkey...              4\n"
     ]
    }
   ],
   "source": [
    "ph_1 = phBot(infile=\"C:/data/inbound/PH_list.csv\", duration=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poopyHEAD\n",
      "poop\n"
     ]
    }
   ],
   "source": [
    "ph_1.check_file(\"poopyHEAD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `BeautifulSoup4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_video_ids_from_url(the_url): #{\n",
    "    # [2019-10-31]\\\\url = input(\"Enter a website to extract the ID's from:\")\n",
    "    url = str(the_url)\n",
    "    # [2019-10-31]\\\\r = requests.get(\"http://\" + url)\n",
    "    r = requests.get(\"http://\" + url)\n",
    "    data = r.text\n",
    "    soup = BeautifulSoup(data)\n",
    "    for li in soup.find_all('li'): #{\n",
    "        # WRITE TO LOG\n",
    "        logging.info(li.get('id'))\n",
    "    #}\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_images_from_url(the_url): #{\n",
    "    # [2019-11-04]\\\\url = input(\"Enter a website to extract the IMG's from: \")\n",
    "    url = str(the_url)\n",
    "    r = requests.get(\"http://\" + url)\n",
    "    data = r.text\n",
    "    soup = BeautifulSoup(data)\n",
    "    for img in soup.find_all('img'): #{\n",
    "        print(img.get('src'))\n",
    "        # CHECK IF .JPG\n",
    "        # WRITE TO LOG\n",
    "        logging.info(img.get('src'))\n",
    "    #}\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_links_from_url(): #{\n",
    "    # RE-INSTANTIATE GLOBALS\n",
    "    global link_list\n",
    "    url = input(\"Enter a website to extract the URL's from: \")\n",
    "    r = requests.get(\"http://\" + url)\n",
    "    data = r.text\n",
    "    soup = BeautifulSoup(data)\n",
    "    for link in soup.find_all('a'): #{\n",
    "        # WRTIE TO LOG\n",
    "        logging.info(link.get('href'))\n",
    "        # CREATE VARIABLE OF POSSIBLE LINK\n",
    "        soup_link = str(link.get('href'))\n",
    "        # CHECK TO SEE IF VALID LINK\n",
    "        if fnmatch.fnmatch(soup_link, \"*view_video.php?*\"): #{\n",
    "            # IS A LEGIT LINK... now check if fully complete or not\n",
    "            #print(soup_link)\n",
    "            if fnmatch.fnmatch(soup_link, \"*https://www.pornhub.com/*\"): #{\n",
    "                # IT IS A COMPLETE LINK! append to list?\n",
    "                print(soup_link)\n",
    "                link_list.append(soup_link)\n",
    "            #}\n",
    "            else: #{\n",
    "                # ITS NOT COMPLETE! SO COMPLETE IT!\n",
    "                corrected_link = str(\"https://www.pornhub.com\" + soup_link)\n",
    "                print(\"CORRECTED LINK == \" + corrected_link)\n",
    "                link_list.append(soup_link)\n",
    "            #}\n",
    "        #}\n",
    "        else: #{\n",
    "            print(\"NOT LEGIT LINK!\")\n",
    "        #}\n",
    "        \n",
    "    #}\n",
    "#}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
