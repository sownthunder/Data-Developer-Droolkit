{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# links to scrape:\n",
    "### - [ph.com model-page](https://pornhub.com/model/heather-kane/)\n",
    "### - [ph.com hot-videos-page](https://pornhub.com/)\n",
    "### - OTHER PEOPLES VIDEOS (comment)\n",
    "\n",
    "---\n",
    "\n",
    "# two paths:\n",
    "\n",
    "1) crawl\n",
    "\n",
    "2) comment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "import random, fnmatch, logging\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import WebDriverException as WDE\n",
    "from selenium.webdriver.common.proxy import Proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "# IMPORT THE LIBRARY USED TO QUERY A WEBSITE\n",
    "from urllib.request import urlopen\n",
    "import wget\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger(): #{\n",
    "    # RE-INSTANTIATE GLOBAL\n",
    "    global timestamp_str\n",
    "    # TRY THE FOLLOWING\n",
    "    try: #{\n",
    "        logging.basicConfig(level=logging.INFO,\n",
    "                           format=\"%(asctime)s:%(message)s\",\n",
    "                           filename=\"C:/data/Logs/PH-BOT-\" + timestamp_str + \".log\",\n",
    "                           filemode=\"a\")\n",
    "    #}\n",
    "    except: #{\n",
    "        print(\"failed setting up logger yo\")\n",
    "    #}\n",
    "    else: #{\n",
    "        print(\"SUCCESS! VERY NICE!\")\n",
    "    #}\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class phBot(): #{\n",
    "    \n",
    "    # INSTANTIATE CLASS VARIABLES\n",
    "    logging_directory = \"C:/data/Logs/PH-BOT-.log\"\n",
    "    links_df = pd.DataFrame(data=None, dtype=np.str)\n",
    "    \n",
    "    def __init__(self, infile, duration): #{\n",
    "        self.infile = infile\n",
    "        self.duration = duration\n",
    "        print(\"infile == \" + str(self.infile))\n",
    "        print(\"duration == \" + str(duration))\n",
    "        print(\"\\nREADING IN 'infile' \\n\")\n",
    "        # OVERWRITE / SAVE DATAFRAME\n",
    "        self.links_df = pd.read_csv(self.infile, dtype=np.str, engine='python')\n",
    "        print(\"len of infile == \" + str(len(self.links_df)))\n",
    "        # PRINT OUT DATAFRAME HEAD \n",
    "        print(str(self.links_df.head()))\n",
    "    #}\n",
    "    \n",
    "    def get_proxy(self): #{\n",
    "        url = \"https://www.ssslproxies.org\"\n",
    "    #}\n",
    "    \n",
    "    \"\"\"\n",
    "    def begin_crawl(self, url_to crawl): #{\n",
    "        \n",
    "    #}\n",
    "    \"\"\"\n",
    "    \n",
    "    def crawl_video_list(self, interval_num): #{\n",
    "        # CREATE DATAFRAME TO HOLD LINKS\n",
    "        #links_df = pd.DataFrame(data=links, dtype= np.str)\n",
    "        the_list = list(self.links_df)\n",
    "        print(\"[START]=============[START]\")\n",
    "        # setup variables\n",
    "        sleep_time = int(interval_num)\n",
    "        #####################\n",
    "        # check input types #\n",
    "        #####################\n",
    "        if type(the_list) is list: #{\n",
    "            print(\"THIS IS THE LIST:\")\n",
    "            # lOOP THROUGH\n",
    "            for list_item in the_list: #{\n",
    "                print(list_item)\n",
    "                sleep(sleep_time)\n",
    "            #}\n",
    "            print(\"[END]============[END]\")\n",
    "            # pop off item from list\n",
    "            lepop = the_list.pop(0)\n",
    "            print(\"LIST ITEM POPPED: \" + str(lepop) + \"\\n[end-TRAVERSE&DROP]==========\")\n",
    "            # RECURSIVE CALL\n",
    "            #traverse_and_drop(the_list, sleep_time + 1)\n",
    "        #}\n",
    "        elif type(the_list) is pd.core.frame.DataFrame : #{\n",
    "            # LOOP THRU DATAFRAME\n",
    "            for item in the_list.itertuples(index=False): #{\n",
    "                print(item)\n",
    "            #}\n",
    "        #}\n",
    "        else: #{\n",
    "            print(\"not a list\")\n",
    "        #}\n",
    "    #}\n",
    "    def print_list(self): #{\n",
    "        print(self.links_df)\n",
    "    #}\n",
    "    \n",
    "    def make_comments(self, link_to_comment): #{\n",
    "        pass\n",
    "    #}\n",
    "    \n",
    "    def download_thumbnails(self, url_link): #{\n",
    "        pass\n",
    "    #}\n",
    "    \n",
    "    def scrape_urls(self, url_to_scrape, save_location): #{\n",
    "        pass\n",
    "    #}\n",
    "    \n",
    "    def check_file(self, infile): #{\n",
    "        print(infile)\n",
    "        print(self.infile)\n",
    "    #}\n",
    "    \n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infile == c:/data/inbound/PH_list.csv\n",
      "duration == 120\n",
      "\n",
      "READING IN 'infile' \n",
      "\n",
      "len of infile == 21\n",
      "  https://www.pornhub.com/view_video.php?viewkey=ph5d47460626ec3  3\n",
      "0  https://www.pornhub.com/view_video.php?viewkey...              4\n",
      "1  https://www.pornhub.com/view_video.php?viewkey...              2\n",
      "2  https://www.pornhub.com/view_video.php?viewkey...              2\n",
      "3  https://www.pornhub.com/view_video.php?viewkey...              6\n",
      "4  https://www.pornhub.com/view_video.php?viewkey...              4\n"
     ]
    }
   ],
   "source": [
    "ph_apollo = phBot(infile=\"c:/data/inbound/PH_list.csv\", duration=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   https://www.pornhub.com/view_video.php?viewkey=ph5d47460626ec3  3\n",
      "0   https://www.pornhub.com/view_video.php?viewkey...              4\n",
      "1   https://www.pornhub.com/view_video.php?viewkey...              2\n",
      "2   https://www.pornhub.com/view_video.php?viewkey...              2\n",
      "3   https://www.pornhub.com/view_video.php?viewkey...              6\n",
      "4   https://www.pornhub.com/view_video.php?viewkey...              4\n",
      "5   https://www.pornhub.com/view_video.php?viewkey...              3\n",
      "6   https://www.pornhub.com/view_video.php?viewkey...              4\n",
      "7   https://www.pornhub.com/view_video.php?viewkey...              3\n",
      "8   https://www.pornhub.com/view_video.php?viewkey...              4\n",
      "9   https://www.pornhub.com/view_video.php?viewkey...              4\n",
      "10  https://www.pornhub.com/view_video.php?viewkey...              3\n",
      "11  https://www.pornhub.com/view_video.php?viewkey...              9\n",
      "12  https://www.pornhub.com/view_video.php?viewkey...              5\n",
      "13  https://www.pornhub.com/view_video.php?viewkey...              3\n",
      "14  https://www.pornhub.com/view_video.php?viewkey...              3\n",
      "15  https://www.pornhub.com/view_video.php?viewkey...              5\n",
      "16  https://www.pornhub.com/view_video.php?viewkey...              5\n",
      "17  https://www.pornhub.com/view_video.php?viewkey...              4\n",
      "18  https://www.pornhub.com/view_video.php?viewkey...              3\n",
      "19  https://www.pornhub.com/view_video.php?viewkey...              2\n",
      "20  https://www.pornhub.com/view_video.php?viewkey...              3\n"
     ]
    }
   ],
   "source": [
    "ph_apollo.print_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START]=============[START]\n",
      "THIS IS THE LIST:\n",
      "https://www.pornhub.com/view_video.php?viewkey=ph5d47460626ec3\n"
     ]
    }
   ],
   "source": [
    "ph_apollo.crawl_video_list(interval_num=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_driver(): #{\n",
    "    driver = webdriver.Chrome()\n",
    "    return driver\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teardown_driver(the_driver): #{\n",
    "    # quit/end driver\n",
    "    the_driver.quit()\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countdown(n): #{\n",
    "    while n >= 0: #{\n",
    "        print(str(n))\n",
    "        sleep(1)\n",
    "        n -= 1\n",
    "    #}\n",
    "    else: #{\n",
    "        print(\"blast off!\")\n",
    "    #}\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infile == C:/data/inbound/PH_list.csv\n",
      "duration == 30\n",
      "len of infile == 21\n",
      "  https://www.pornhub.com/view_video.php?viewkey=ph5d47460626ec3  3\n",
      "0  https://www.pornhub.com/view_video.php?viewkey...              4\n",
      "1  https://www.pornhub.com/view_video.php?viewkey...              2\n",
      "2  https://www.pornhub.com/view_video.php?viewkey...              2\n",
      "3  https://www.pornhub.com/view_video.php?viewkey...              6\n",
      "4  https://www.pornhub.com/view_video.php?viewkey...              4\n"
     ]
    }
   ],
   "source": [
    "ph_1 = phBot(infile=\"C:/data/inbound/PH_list.csv\", duration=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poopyHEAD\n",
      "poop\n"
     ]
    }
   ],
   "source": [
    "ph_1.check_file(\"poopyHEAD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `BeautifulSoup4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_video_ids_from_url(the_url): #{\n",
    "    # [2019-10-31]\\\\url = input(\"Enter a website to extract the ID's from:\")\n",
    "    url = str(the_url)\n",
    "    # [2019-10-31]\\\\r = requests.get(\"http://\" + url)\n",
    "    r = requests.get(\"http://\" + url)\n",
    "    data = r.text\n",
    "    soup = BeautifulSoup(data)\n",
    "    for li in soup.find_all('li'): #{\n",
    "        # WRITE TO LOG\n",
    "        logging.info(li.get('id'))\n",
    "    #}\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enlarge_image(the_image_file, save_location): #{\n",
    "    pass\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_images_from_url(): #{\n",
    "    url = input(\"Enter a website to extract the IMG's from: \")\n",
    "    r = requests.get(\"http://\" + url)\n",
    "    data = r.text\n",
    "    soup = BeautifulSoup(data)\n",
    "    for img in soup.find_all('img'): #{\n",
    "        print(img.get('src'))\n",
    "        # CHECK IF .JPG\n",
    "        # WRITE TO LOG\n",
    "        logging.info(img.get('src'))\n",
    "    #}\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_links_from_url(): #{\n",
    "    # RE-INSTANTIATE GLOBALS\n",
    "    global link_list\n",
    "    url = input(\"Enter a website to extract the URL's from: \")\n",
    "    r = requests.get(\"http://\" + url)\n",
    "    data = r.text\n",
    "    soup = BeautifulSoup(data)\n",
    "    for link in soup.find_all('a'): #{\n",
    "        # WRTIE TO LOG\n",
    "        logging.info(link.get('href'))\n",
    "        # CREATE VARIABLE OF POSSIBLE LINK\n",
    "        soup_link = str(link.get('href'))\n",
    "        # CHECK TO SEE IF VALID LINK\n",
    "        if fnmatch.fnmatch(soup_link, \"*view_video.php?*\"): #{\n",
    "            # IS A LEGIT LINK... now check if fully complete or not\n",
    "            #print(soup_link)\n",
    "            if fnmatch.fnmatch(soup_link, \"*https://www.pornhub.com/*\"): #{\n",
    "                # IT IS A COMPLETE LINK! append to list?\n",
    "                print(soup_link)\n",
    "                link_list.append(soup_link)\n",
    "            #}\n",
    "            else: #{\n",
    "                # ITS NOT COMPLETE! SO COMPLETE IT!\n",
    "                corrected_link = str(\"https://www.pornhub.com\" + soup_link)\n",
    "                print(\"CORRECTED LINK == \" + corrected_link)\n",
    "                link_list.append(soup_link)\n",
    "            #}\n",
    "        #}\n",
    "        else: #{\n",
    "            print(\"NOT LEGIT LINK!\")\n",
    "        #}\n",
    "        \n",
    "    #}\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": #{\n",
    "    \n",
    "#}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
