{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T15:24:49.528904Z",
     "start_time": "2020-03-25T15:24:46.761835Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import pyodbc\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.drawing.image import Image\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import tempfile\n",
    "from ttkthemes import ThemedStyle\n",
    "import tkinter as tk\n",
    "import tkinter.ttk as ttk\n",
    "from tkinter import messagebox, filedialog, commondialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T15:24:49.614873Z",
     "start_time": "2020-03-25T15:24:49.530876Z"
    }
   },
   "outputs": [],
   "source": [
    "class TISS_Metrics(): # {\n",
    "    \n",
    "    user_name = str(os.getlogin())\n",
    "    outbound_dir = \"C:/data/outbound/\" + str(pd.Timestamp.now())[:10]\n",
    "    desktop_dir = \"OneDrive - Agilent Technologies/Desktop\"\n",
    "    \n",
    "    def __init__(self, the_logger, materials_file): # {\n",
    "        self.the_logger = the_logger\n",
    "        self.materials_file = materials_file\n",
    "        # create dataframe from infile\n",
    "        self.df_infile = pd.read_csv(self.materials_file, header=0, dtype=np.str, engine='python')\n",
    "        # EXPORT?\n",
    "        self.df_infile.to_csv(os.path.join(self.outbound_dir, \"df_infile-\"\n",
    "                                          + str(pd.Timestamp.now())[:10]\n",
    "                                          + \".csv\"))\n",
    "        # Get/Set USERNAME & DESKTOP DIRECTORIES\n",
    "        self.user_name_dir = os.path.join(\"C:/Users/\", self.user_name)\n",
    "        self.desktop_dir = os.path.join(self.user_name_dir, self.desktop_dir)\n",
    "        print(self.user_name_dir)\n",
    "        print(self.desktop_dir)\n",
    "        self.run(day_range=30)\n",
    "    # }\n",
    "    \n",
    "    def run(self, day_range): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # [2020-02-28]\\\\self.time_unit = time_unit\n",
    "            # [2020-02-28]\\\\self.time_value = time_value\n",
    "            self.day_range = day_range\n",
    "            # get/set current date variable\n",
    "            # [2020-03-06]\\\\the_date = pd.Timestamp.now()\n",
    "            # [2020-03-11]\\\\the_date = pd.Timestamp(ts_input=str(self.end_date.get()))\n",
    "            the_date = pd.Timestamp.now()\n",
    "            # create variable for a month ago\n",
    "            one_month_ago = the_date - timedelta(days = int(day_range))\n",
    "            # [2020-02-28]\\\\\n",
    "            ##one_month_ago = the_date - pd.Timedelta(unit=str(self.time_unit), value=str(self.time_value))\n",
    "            print(type(one_month_ago))\n",
    "            # CREATE METRICS TABLE FROM CLASS METHOD\n",
    "            self.df_metrics_table = self.create_metrics_table()\n",
    "            #############################\n",
    "            # create .csv with no drops #\n",
    "            #############################\n",
    "            \"\"\"\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_metrics_noDrop.csv\"), \n",
    "                                         index=True)\n",
    "            # DROP ROWS WITH PRODUCT LEVEL && QCDATE = NONE\n",
    "            self.df_metrics_table.dropna(axis=0, subset=['QCDate', 'ProductLevel'], how='any', \n",
    "                                         inplace=True)\n",
    "            # create .csv with DROPS\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_metrics_DROP.csv\"), \n",
    "                                         index=True)\n",
    "            \"\"\"\n",
    "            # Set index of METRICS\n",
    "            # [2020-03-11]\\\\self.df_metrics_table.set_index(['QCDate'], inplace=True)\n",
    "            self.df_metrics_table.index = self.df_metrics_table['QCDate']\n",
    "            del self.df_metrics_table['QCDate']\n",
    "            print(self.df_metrics_table)\n",
    "            # Display Index\n",
    "            print(self.df_metrics_table.index)\n",
    "            #############################\n",
    "            # create .csv with UNSORTED #\n",
    "            #############################\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_TIS_metrics_UNSORTED.csv\"), \n",
    "                                         index=True)\n",
    "            # SORT INDEX\n",
    "            self.df_metrics_table.sort_index(inplace=True)\n",
    "            ###########################\n",
    "            # create .csv with SORTED #\n",
    "            ###########################\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_TIS_metrics_SORTED.csv\"), \n",
    "                                         index=True)\n",
    "            print(\"SORTED:\\n\")\n",
    "            print(self.df_metrics_table.index)\n",
    "            # SLICE & DICE THE DATAFRAME\n",
    "            # [2020-03-11]\\\\self.df_level_1s = self.df_metrics_table.loc['2017-01-02']\n",
    "            print(\"<<<<< df_level_1s >>>>>\\n\\t\" + str(self.df_metrics_table.loc['2017-01-02':'2020-01-01'].describe()))\n",
    "            \"\"\"\n",
    "            <<< SLICE AND DICE THE DATAFRAME TO A MONTH PERIOD >>>< \n",
    "            \"\"\"\n",
    "            df_month = self.df_metrics_table.loc['2020-02-01':'2020-03-31']\n",
    "            # ***COPY DATAFRAME WITH RESET INDEX TO BE SAVED FOR LATER***\n",
    "            df_month_no_IDX = df_month.reset_index(drop=False)\n",
    "            # export\n",
    "            df_month_no_IDX.to_csv(os.path.join(self.outbound_dir, \"df_month_no_IDX-\"\n",
    "                                               + str(pd.Timestamp.now())[:10]\n",
    "                                               + \".csv\"), index_label=\"INDEX\", index=True)\n",
    "            print(\"df_month == (INDEX):\\n\" + str(df_month_no_IDX.index))\n",
    "            # CREATE INDEX VAR TO SAVE OLD INDEX (to be re-used)\n",
    "            qcdate_idx = df_month.index\n",
    "            print(\"qcdate_idx == (TYPE):\\n\" + str(type(qcdate_idx)))\n",
    "            print(\"LENGTH == \" + str(len(qcdate_idx)))\n",
    "            # SAVE QCDATE *COLUMN* TO BECOME REG COLUMN\n",
    "            qcdate_col = df_month_no_IDX['QCDate']\n",
    "            print(\"qcdate_col == (TYPE):\\n\" + str(type(qcdate_col)))\n",
    "            print(\"LENGTH == \" + str(len(qcdate_col)))\n",
    "            productno_col = df_month['ProductNo']\n",
    "            print('productno_col == (TYPE):\\n' + str(type(productno_col)))\n",
    "            print(\"LENGTH == \" + str(len(productno_col)))\n",
    "            # RE-ASSIGN OLD INDEX BACK IN AS COLUMN (of copied DataFrame)\n",
    "            df_month['QCDate'] = qcdate_col\n",
    "            # export\n",
    "            df_month.to_csv(os.path.join(self.outbound_dir, \"TIS-MONTH-\"\n",
    "                                        + str(pd.Timestamp.now())[:10]\n",
    "                                        + \".csv\"), index_label=\"INDEX\", index=True)\n",
    "            # CREATE EMPTY DATAFRAME TO (was... to HOLD THE MONTH OF FEBRUARY)\n",
    "            df_month_FINALE = pd.DataFrame(data=None, dtype=np.str, index=None) #[2020-04-01]\\\\df_month.index)\n",
    "            # [2020-03-31]\\\\df_month_FINALE[\"QCDate\"] = df_month.index\n",
    "            # [2020-04-01]\\\\df_month_FINALE[\"QCDate\"] = df_month.index\n",
    "            # [2020-04-01]\\\\df_month_FINALE['QCDate'] = qcdate_col # re-assign OLD INDEX to COLUMN\n",
    "            # NARROW DOWN ON COLUMNS\n",
    "            # [2020-04-03]\\\\df_month_FINALE['QCDate'] = qcdate_col # re-assign OLD INDEX to column\n",
    "            df_month_FINALE['QCDATE'] = self.tblProdflow['QCDate']\n",
    "            df_month_FINALE[\"OrderID\"] = df_month[\"OrderID\"]\n",
    "            df_month_FINALE[\"ProductNo\"] = df_month[\"ProductNo\"]\n",
    "            df_month_FINALE[\"Volume\"] = df_month[\"Volume\"]\n",
    "            df_month_FINALE[\"BuildByDate\"] = df_month[\"BuildByDate\"]\n",
    "            df_month_FINALE[\"OrderDate\"] = df_month[\"OrderDate\"]\n",
    "            df_month_FINALE[\"PrepDate\"] = df_month[\"PrepDate\"]\n",
    "            df_month_FINALE[\"PrepVolume\"] = df_month[\"PrepVolume\"]\n",
    "            df_month_FINALE[\"UnitizeNLT\"] = df_month[\"UnitizeNLT\"]\n",
    "            df_month_FINALE[\"ShipNLTDate\"] = df_month[\"ShipNLTDate\"]\n",
    "            df_month_FINALE[\"BulkQCDate\"] = df_month[\"BulkQCDate\"]\n",
    "            df_month_FINALE[\"AmpDate\"] = df_month[\"AmpDate\"]\n",
    "            df_month_FINALE[\"GreenSheet\"] = df_month[\"GreenSheet\"]\n",
    "            df_month_FINALE[\"SOLink\"] = df_month[\"SOLink\"]\n",
    "            df_month_FINALE[\"Notes\"] = df_month[\"Notes\"]\n",
    "            print(\"df_month_FINALE **INDEX**:\\n\" + str(df_month_FINALE.index))\n",
    "            # NARROW DOWN DATAFRAME TO ONLY CONTAIN CERTAIN DATES\n",
    "            # [2020-04-01]\\\\df_month_FINALE.loc['2020-02-01':'2020-03-31']\n",
    "            # Export?\n",
    "            df_month_FINALE.to_csv(os.path.join(self.outbound_dir, \"TIS-MONTH-FINALE-\"\n",
    "                                        + str(pd.Timestamp.now())[:10]\n",
    "                                        + \".csv\"), index_label=\"QCDate\", index=True)\n",
    "            df_merge = pd.merge(df_month_FINALE, self.df_infile, on='ProductNo', how='inner')\n",
    "            # EXPORT ??\n",
    "            df_merge.to_csv(os.path.join(self.outbound_dir, \"df-TIS-M-MERGE-\"\n",
    "                                        + str(pd.Timestamp.now())[:10]\n",
    "                                        + \".csv\"), index=True)\n",
    "            # CREATE DATAFRAME TO HOLD SAID INDEX (to be re-used)\n",
    "            s_month = pd.Series(data=None, index=qcdate_idx, name='QCDate') # data=df_month['ProductNo'], index=qcdate_idx\n",
    "            print(\"s_month:\\n\" + str(s_month))\n",
    "            df_save_qcdate = pd.DataFrame(data=productno_col, index=df_month.index) # df_month[\"ProductNo\"], index=df_month['QCDAte']\n",
    "            # RESET INDEX SO IT BECOME COLUMN\n",
    "            df_save_qcdate.reset_index(inplace=True)\n",
    "            # CONVERT FROM INDEX TO COLUMN\n",
    "            \n",
    "            # SET BACK AGAIN BUT KEEP QCDATE AS A COLUMN?\n",
    "            \n",
    "            print(\"\\tdf_save_qcdate:\\n\" + str(df_save_qcdate.info()))\n",
    "            df_save_qcdate.to_csv(os.path.join(self.outbound_dir, \"df-SAVE-qcdate-\"\n",
    "                                                  + str(pd.Timestamp.now())[:10]\n",
    "                                                  + \".csv\"), index=True)\n",
    "            print(str(df_save_qcdate))\n",
    "            # <<< MERGE INDEX OF QCDATE \"back\" INTO DATAFRAME? >>>\n",
    "            # >>> WITH SERIES CREATED ABOVE\n",
    "            df_merge_idx = df_merge.join(s_month, how='inner')\n",
    "            # [2020-04-03]\\\\df_merge_idx = df_merge.join(df_save_qcdate.set_index('QCDate'), on='QCDate') #, how='left')\n",
    "            # SET INDEX IN THE NEW MERGED FRAME SO WE GET BACK THE QCDATE\n",
    "            df_merge_idx.set_index(['QCDate'], inplace=True)\n",
    "            #df_merge_idx = df_merge.join(df_save_qcdate, on='ProductNo', how='inner')\n",
    "            \"\"\"\n",
    "            df_merge_idx = pd.concat(objs=[df_merge, df_save_qcdate], join=\"inner\", ) # , left_on='ProductNo', right_index=True)\n",
    "            df_merge_idx = pd.merge(left=df_merge, right=s_month, how=\"inner\", right_index=True)\n",
    "            \"\"\"\n",
    "            df_merge_idx.to_csv(os.path.join(self.outbound_dir, \"df_____idx-TIS-M-MERGE-\"\n",
    "                                            + str(pd.Timestamp.now())[:10]\n",
    "                                            + \".csv\"), index_label=\"INDEX\", index=True)\n",
    "            # << CHANGE INDEX BACK TO QCDATE? >>>\n",
    "            # [2020-04-01]\\\\df_merge.set_index(['QCDate'], drop=True)\n",
    "            # [2020-04-01]\\\\df_merge.set_index(qcdate_idx, drop=True, inplace=True) \n",
    "            # GET TIMESTMP FOR TODAY\n",
    "            ts_now = pd.Timestamp.now()\n",
    "            # create timedelta for LAST WEEK\n",
    "            td_last_week = pd.Timedelta(days=7)\n",
    "            # create timedelta for YESTERDAY\n",
    "            td_yesterday = pd.Timedelta(days=2)\n",
    "            # create actual TIMESTAMP for last week (whenever it was)\n",
    "            ts_last_week = pd.Timestamp(ts_now - td_last_week)\n",
    "            # create actual TIMESTAMP for YESTERDAY\n",
    "            ts_yesterday = pd.Timestamp(ts_now - td_yesterday)\n",
    "            ## CREATE DATAFRAME OF LAST WEEK\n",
    "            df_last_week = self.df_metrics_table.loc[ts_last_week:ts_now]\n",
    "            ## CREATE DATAFRAME OF YESTERDAY\n",
    "            df_yesterday = self.df_metrics_table.loc[ts_yesterday:ts_now]\n",
    "            # EXPORT ??\n",
    "            df_last_week.to_csv(os.path.join(self.outbound_dir, \"df_TIS-last-week-\" \n",
    "                                             + str(pd.Timestamp.now())[:10] \n",
    "                                             + \".csv\"))\n",
    "            print(\"LAST WEEK COLS:\\n\" + str(df_last_week.columns))\n",
    "            # CREATE NEW EMPTY DATAFRAME (to hold SPEICIFIC columns)\n",
    "            df_yesterday_FINALE = pd.DataFrame(data=None, dtype=np.str, index=df_yesterday.index)\n",
    "            # [2020-03-12]\\\\df_yesterday_FINALE[\"QCDate\"] = df_yesterday[\"QCDate\"]\n",
    "            # [2020-03-24]\\\\df_yesterday_FINALE[\"QCDate\"] = df_yesterday.index\n",
    "            df_yesterday_FINALE[\"QCDate\"] = self.df_tblProdflow[\"QCDate\"]\n",
    "            df_yesterday_FINALE[\"OrderID\"] = df_yesterday[\"OrderID\"]\n",
    "            df_yesterday_FINALE[\"ProductNo\"] = df_yesterday[\"ProductNo\"]\n",
    "            df_yesterday_FINALE[\"Volume\"] = df_yesterday[\"Volume\"]\n",
    "            df_yesterday_FINALE[\"BuildByDate\"] = df_yesterday[\"BuildByDate\"]\n",
    "            df_yesterday_FINALE[\"OrderDate\"] = df_yesterday[\"OrderDate\"]\n",
    "            df_yesterday_FINALE[\"PrepDate\"] = df_yesterday[\"PrepDate\"]\n",
    "            df_yesterday_FINALE[\"PrepVolume\"] = df_yesterday[\"PrepVolume\"]\n",
    "            # [2020-03-13]\\\\df_yesterday_FINALE[\"QCDate\"] = df_yesterday[\"QCDate\"]\n",
    "            # [2020-03-17]\\\\df_yesterday_FINALE[\"QCDate\"] = df_yesterday.index\n",
    "            df_yesterday_FINALE[\"UnitizeNLT\"] = df_yesterday[\"UnitizeNLT\"]\n",
    "            df_yesterday_FINALE[\"ShipNLTDate\"] = df_yesterday[\"ShipNLTDate\"]\n",
    "            df_yesterday_FINALE[\"BulkQCDate\"] = df_yesterday[\"BulkQCDate\"]\n",
    "            df_yesterday_FINALE[\"AmpDate\"] = df_yesterday[\"AmpDate\"]\n",
    "            df_yesterday_FINALE[\"GreenSheet\"] = df_yesterday[\"GreenSheet\"]\n",
    "            df_yesterday_FINALE[\"SOLink\"] = df_yesterday[\"SOLink\"]\n",
    "            # [2020-03-17]\\\\df_yesterday_FINALE[\"QCExpDate\"] = df_yesterday[\"QCExpDate\"]\n",
    "            # [2020-03-17]\\\\df_yesterday_FINALE[\"QCMemo\"] = df_yesterday[\"QCMemo\"]\n",
    "            df_yesterday_FINALE[\"Notes\"] = df_yesterday[\"Notes\"]\n",
    "            \"\"\"\n",
    "            df_yesterday_FINALE[\"PrepDate\"] = df_yesterday[\"PrepDate\"]\n",
    "            df_yesterday_FINALE[\"BulkQCDate\"] = df_yesterday[\"BulkQCDate\"]\n",
    "            df_yesterday_FINALE[\"AmpDate\"] = df_yesterday[\"AmpDate\"]\n",
    "            df_yesterday_FINALE[\"ProductNo\"] = df_yesterday[\"ProductNo\"]\n",
    "            df_yesterday_FINALE[\"OrderID\"] = df_yesterday[\"OrderID\"]\n",
    "            df_yesterday_FINALE[\"OrderDate\"] = df_yesterday[\"OrderDate\"]\n",
    "            df_yesterday_FINALE[\"Notes\"] = df_yesterday[\"Notes\"]\n",
    "            \"\"\"\n",
    "            df_yesterday_FINALE.to_csv(os.path.join(self.outbound_dir, \"df_TIS-yesterday-\"\n",
    "                                             + str(pd.Timestamp.now())[:10]\n",
    "                                             + \".csv\"), index=True)\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "    \"\"\"\n",
    "    Referred to as \"ProdflowII\" in SQL-Server\n",
    "    \"\"\"\n",
    "    def pull_ProdflowII_table(self, table_name): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # CREATION CONNECTION STR\n",
    "            conn_str = str(\n",
    "                r'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "                r'SERVER=wtkngappflow1.is.agilent.net;'\n",
    "                r'DATABASE=ProdFlowII_Prod;'\n",
    "                r'Trusted_Connection=yes;'\n",
    "            )\n",
    "            # CREATE PYODBC CONNECTION\n",
    "            cnxn_ProdflowII = pyodbc.connect(conn_str)\n",
    "            # [2020-02-028]\\\\crsr_ProdflowII = cnxn_ProdflowII.cursor()\n",
    "            # PERFORM SQL QUERY AND SET AS DATAFRAME\n",
    "            df_ProdflowII_table = pd.read_sql_query(sql='SELECT * FROM ' + str(table_name),\n",
    "                                                    con=cnxn_ProdflowII\n",
    "                                                    )\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "            return df_ProdflowII_table\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "    \"\"\"\n",
    "    Referred to as \"Prodflow\" in SQL-Server\n",
    "    \"\"\"\n",
    "    def pull_ProdflowIII_table(self, table_name): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # CREATE CONNECTION STRING\n",
    "            conn_str = str(\n",
    "                r'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "                r'SERVER=wtkngappflow1.is.agilent.net;'\n",
    "                r'DATABASE=ProdFlow;'\n",
    "                r'Trusted_Connection=yes;'\n",
    "            )\n",
    "            # CREATE PYODBC CONNECTION\n",
    "            cnxn_ProdflowIII = pyodbc.connect(conn_str)\n",
    "            # [2020-02-28]\\\\crsr_ProdflowIII = cnxn_ProdflowIII,cursor()\n",
    "            # PERFORM SQL QUERY AND SET AS DATAFRAME\n",
    "            df_ProdflowIII_table = pd.read_sql_query(sql='SELECT * FROM ' + str(table_name),\n",
    "                                                     con=cnxn_ProdflowIII,\n",
    "                                                     parse_dates=['QCDate']\n",
    "                                                     )\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "            return df_ProdflowIII_table\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "    def create_metrics_table(self): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # pull ORDERS table\n",
    "            self.df_orders = self.pull_ProdflowII_table(table_name='Orders')\n",
    "            # EXPORT A SAMPLE\n",
    "            self.df_orders.sample(25).to_csv(os.path.join(self.outbound_dir, \"df-ORDERS-table-\"\n",
    "                                                         + str(pd.Timestamp.now())[:10]\n",
    "                                                         + \".csv\"))\n",
    "            # [2020-03-11]\\\\export_path = os.path.join(self.outbound_dir, \"df_orders.csv\")\n",
    "            # [2020-03-11]\\\\self.df_orders.to_csv(export_path, index=True)\n",
    "            # RENAME ['Product#'] column to [\"ProductNo\"]\n",
    "            self.df_orders.rename(columns={'Product#': 'ProductNo'}, inplace=True)\n",
    "            print(\"\\tORDERS-TABLE:\\n\" + str(self.df_orders.info()))\n",
    "            # pull tblProdflow TABLE\n",
    "            self.df_tblProdflow = self.pull_ProdflowIII_table(table_name='tblProdflow')\n",
    "            # EXPORT A SAMPLE\n",
    "            self.df_tblProdflow.sample(25).to_csv(os.path.join(self.outbound_dir, \"df-ORDERS-table-\"\n",
    "                                                         + str(pd.Timestamp.now())[:10]\n",
    "                                                         + \".csv\"))\n",
    "            print(self.df_tblProdflow.info())\n",
    "            ########################\n",
    "            # CREATE METRICS TABLE #\n",
    "            ########################\n",
    "            df_metrics_table = pd.merge(self.df_orders, self.df_tblProdflow, on='ProductNo', how='right')\n",
    "            ######################\n",
    "            # CHANGE DATA TYPES: #\n",
    "            ######################\n",
    "            \n",
    "            # CHANGE ['QCDate'] COLUMN TO DATETIME\n",
    "            df_metrics_table['QCDate'] = pd.to_datetime(df_metrics_table['QCDate'])\n",
    "            ####################################\n",
    "            # DROP ALL ROWS WITHOUT A 'QCDATE' #\n",
    "            ####################################\n",
    "            df_metrics_table.dropna(axis=0, subset=['QCDate'],\n",
    "                                   how='any', inplace=True)\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        #}\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "            return df_metrics_table\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "    def send_email(self, send_from, send_to, subject, message, files=[],\n",
    "                  server=\"cos.smtp.agilent.com\", port=587, use_tls=True): # {\n",
    "        print(\"SENDING E-MAIL...\\nDATE == \" + str(pd.Timestamp.now())[:10])\n",
    "        msg = MIMEMultipart()\n",
    "        msg['From'] = send_from\n",
    "        msg['To'] = COMMASPACE.join(send_to)\n",
    "        msg['Date'] = formatdate(localtime=True)\n",
    "        msg['Subject'] = subject\n",
    "        \n",
    "        msg.attach(MIMEText(message))\n",
    "    # }\n",
    "    \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T15:28:26.151615Z",
     "start_time": "2020-03-25T15:24:49.616874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/derbates\n",
      "C:/Users/derbates\\OneDrive - Agilent Technologies/Desktop\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "Operation Completed Successfully...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 106748 entries, 0 to 106747\n",
      "Data columns (total 28 columns):\n",
      "OrderID            106748 non-null int64\n",
      "Quote#             106742 non-null object\n",
      "ProductNo          106748 non-null object\n",
      "LineID             106739 non-null float64\n",
      "Quantity           106679 non-null float64\n",
      "SaleUnit           95228 non-null object\n",
      "Company            106482 non-null object\n",
      "Volume             106478 non-null float64\n",
      "VolUnit            40636 non-null object\n",
      "OrderDate          106742 non-null datetime64[ns]\n",
      "BuildByDate        106190 non-null object\n",
      "ShipNLTDate        106156 non-null object\n",
      "Route              106747 non-null float64\n",
      "FullValidation     106748 non-null bool\n",
      "Validation         76294 non-null float64\n",
      "Built              106748 non-null bool\n",
      "GreenSheet         78518 non-null object\n",
      "Notes              32844 non-null object\n",
      "Completed          106748 non-null bool\n",
      "SOLink             32152 non-null object\n",
      "UserFormulation    32638 non-null object\n",
      "UserUnitizing      0 non-null object\n",
      "UserBulkQC         0 non-null object\n",
      "UserQC             0 non-null object\n",
      "EquipShort         2 non-null object\n",
      "UnitizeNLT         35565 non-null object\n",
      "SpecialPrep        106748 non-null bool\n",
      "RushPriority       106748 non-null bool\n",
      "dtypes: bool(5), datetime64[ns](1), float64(5), int64(1), object(16)\n",
      "memory usage: 19.2+ MB\n",
      "\tORDERS-TABLE:\n",
      "None\n",
      "Operation Completed Successfully...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 109501 entries, 0 to 109500\n",
      "Data columns (total 53 columns):\n",
      "PfIDNo              109501 non-null int64\n",
      "PfBatchID           109501 non-null object\n",
      "ProductNo           109482 non-null object\n",
      "OrdID               93369 non-null float64\n",
      "QuoteNo             109465 non-null object\n",
      "PfSentTo            109436 non-null object\n",
      "PrepDate            108473 non-null datetime64[ns]\n",
      "PrepVolume          109456 non-null float64\n",
      "PrepUnit            109425 non-null object\n",
      "PrepVessel          109422 non-null float64\n",
      "PrepVBarcode        58813 non-null object\n",
      "PrdSaleUnit         90128 non-null object\n",
      "PrepMatrixNo        109426 non-null object\n",
      "PrepMatrixLot       108555 non-null object\n",
      "PrepInits           108314 non-null object\n",
      "PrepMemo            61895 non-null object\n",
      "PrepNotebookRef     48969 non-null object\n",
      "BulkQCStatus        24 non-null object\n",
      "BulkQCDate          75789 non-null datetime64[ns]\n",
      "BulkPassFail        74811 non-null object\n",
      "BulkQCInits         75774 non-null object\n",
      "BulkQCMemo          2207 non-null object\n",
      "BulkLotNo           74066 non-null object\n",
      "AmpRetains          52112 non-null float64\n",
      "AmpDate             93440 non-null datetime64[ns]\n",
      "AmpPreLabel         109501 non-null bool\n",
      "AmpNumberGood       93768 non-null float64\n",
      "AmpNumberBad        77980 non-null float64\n",
      "AmpBulkRemain       4573 non-null float64\n",
      "AmpTimeIn           93198 non-null datetime64[ns]\n",
      "AmpTimeOut          93198 non-null datetime64[ns]\n",
      "AmpInits            93406 non-null object\n",
      "QCStatus            573 non-null object\n",
      "QCDate              103957 non-null datetime64[ns]\n",
      "QCPassFail          104146 non-null object\n",
      "QCAuthInits         103945 non-null object\n",
      "QCMemo              55720 non-null object\n",
      "QCMethod            1209 non-null object\n",
      "LotNo               101237 non-null object\n",
      "QCExpMonth          94143 non-null float64\n",
      "QCExpDate           92560 non-null datetime64[ns]\n",
      "QCSellBy            0 non-null object\n",
      "QCFullValidation    109501 non-null bool\n",
      "QCValidation        109467 non-null float64\n",
      "FgInvCount          78635 non-null float64\n",
      "FgAccpacNote        19856 non-null object\n",
      "CofAHeaderNo        109469 non-null float64\n",
      "QCChromatogram      0 non-null object\n",
      "Correct             109501 non-null bool\n",
      "DoNotCorrect        109501 non-null bool\n",
      "DensityUnit         0 non-null object\n",
      "DensityTemp         0 non-null object\n",
      "recipeid            1 non-null object\n",
      "dtypes: bool(4), datetime64[ns](7), float64(11), int64(1), object(30)\n",
      "memory usage: 41.4+ MB\n",
      "None\n",
      "Operation Completed Successfully...\n",
      "            OrderID     Quote#    ProductNo  LineID  Quantity  \\\n",
      "QCDate                                                          \n",
      "2005-04-08      2.0  021004-27     CUS-5465     7.0      10.0   \n",
      "2005-04-08   3420.0  040405-54     CUS-5465     7.0       4.0   \n",
      "2004-04-13      2.0  021004-27     CUS-5465     7.0      10.0   \n",
      "2004-04-13   3420.0  040405-54     CUS-5465     7.0       4.0   \n",
      "2004-04-12      4.0  031504-11     CUS-5459     7.0      10.0   \n",
      "...             ...        ...          ...     ...       ...   \n",
      "2019-04-11      NaN        NaN  5190-0484-a     NaN       NaN   \n",
      "2019-10-04      NaN        NaN       BULK-2     NaN       NaN   \n",
      "2019-12-17      NaN        NaN      JHP-683     NaN       NaN   \n",
      "2020-02-05      NaN        NaN      JHP-327     NaN       NaN   \n",
      "2020-03-11      NaN        NaN      JHP-327     NaN       NaN   \n",
      "\n",
      "                                             SaleUnit  \\\n",
      "QCDate                                                  \n",
      "2005-04-08  1 mL in 2 mL Flame-Sealed Amber Ampule(s)   \n",
      "2005-04-08          1 mL Flame-Sealed Amber Ampule(s)   \n",
      "2004-04-13  1 mL in 2 mL Flame-Sealed Amber Ampule(s)   \n",
      "2004-04-13          1 mL Flame-Sealed Amber Ampule(s)   \n",
      "2004-04-12          1 mL Flame-Sealed Amber Ampule(s)   \n",
      "...                                               ...   \n",
      "2019-04-11                                        NaN   \n",
      "2019-10-04                                        NaN   \n",
      "2019-12-17                                        NaN   \n",
      "2020-02-05                                        NaN   \n",
      "2020-03-11                                        NaN   \n",
      "\n",
      "                               Company  Volume VolUnit  OrderDate  ...  \\\n",
      "QCDate                                                             ...   \n",
      "2005-04-08  Missouri American Water Co   850.0      mL 2014-05-05  ...   \n",
      "2005-04-08     Missouri American Water    25.0      mL 2005-04-05  ...   \n",
      "2004-04-13  Missouri American Water Co   850.0      mL 2014-05-05  ...   \n",
      "2004-04-13     Missouri American Water    25.0      mL 2005-04-05  ...   \n",
      "2004-04-12  Carnegie Mellon University    25.0      mL 2004-04-07  ...   \n",
      "...                                ...     ...     ...        ...  ...   \n",
      "2019-04-11                         NaN     NaN     NaN        NaT  ...   \n",
      "2019-10-04                         NaN     NaN     NaN        NaT  ...   \n",
      "2019-12-17                         NaN     NaN     NaN        NaT  ...   \n",
      "2020-02-05                         NaN     NaN     NaN        NaT  ...   \n",
      "2020-03-11                         NaN     NaN     NaN        NaT  ...   \n",
      "\n",
      "           QCValidation FgInvCount  FgAccpacNote CofAHeaderNo  QCChromatogram  \\\n",
      "QCDate                                                                          \n",
      "2005-04-08          1.0       16.0          None          1.0            None   \n",
      "2005-04-08          1.0       16.0          None          1.0            None   \n",
      "2004-04-13          1.0        NaN          None          1.0            None   \n",
      "2004-04-13          1.0        NaN          None          1.0            None   \n",
      "2004-04-12          1.0        NaN          None          1.0            None   \n",
      "...                 ...        ...           ...          ...             ...   \n",
      "2019-04-11          2.0       65.0          None          2.0            None   \n",
      "2019-10-04          2.0     2000.0    blue sheet          2.0            None   \n",
      "2019-12-17          1.0        NaN     no action         15.0            None   \n",
      "2020-02-05          1.0        NaN     no action         15.0            None   \n",
      "2020-03-11          1.0        NaN     no action         15.0            None   \n",
      "\n",
      "           Correct DoNotCorrect DensityUnit DensityTemp recipeid  \n",
      "QCDate                                                            \n",
      "2005-04-08   False         True        None        None     None  \n",
      "2005-04-08   False         True        None        None     None  \n",
      "2004-04-13   False         True        None        None     None  \n",
      "2004-04-13   False         True        None        None     None  \n",
      "2004-04-12   False         True        None        None     None  \n",
      "...            ...          ...         ...         ...      ...  \n",
      "2019-04-11   False        False        None        None     None  \n",
      "2019-10-04   False        False        None        None     None  \n",
      "2019-12-17   False         True        None        None     None  \n",
      "2020-02-05   False         True        None        None     None  \n",
      "2020-03-11   False         True        None        None     None  \n",
      "\n",
      "[1812678 rows x 79 columns]\n",
      "DatetimeIndex(['2005-04-08', '2005-04-08', '2004-04-13', '2004-04-13',\n",
      "               '2004-04-12', '2012-03-14', '2012-03-14', '2012-03-14',\n",
      "               '2012-03-14', '2012-03-14',\n",
      "               ...\n",
      "               '2019-05-01', '2019-02-01', '2019-07-03', '2019-02-19',\n",
      "               '2019-03-04', '2019-04-11', '2019-10-04', '2019-12-17',\n",
      "               '2020-02-05', '2020-03-11'],\n",
      "              dtype='datetime64[ns]', name='QCDate', length=1812678, freq=None)\n",
      "SORTED:\n",
      "\n",
      "DatetimeIndex(['1987-01-01', '1987-01-01', '1989-01-01', '1991-01-01',\n",
      "               '1991-01-01', '1991-01-01', '1991-01-01', '1992-01-01',\n",
      "               '1992-01-01', '1992-01-01',\n",
      "               ...\n",
      "               '2020-04-03', '2020-04-03', '2020-04-03', '2020-04-03',\n",
      "               '2020-04-03', '2020-04-03', '2020-04-03', '2020-04-03',\n",
      "               '2020-04-03', '2020-04-03'],\n",
      "              dtype='datetime64[ns]', name='QCDate', length=1812678, freq=None)\n",
      "<<<<< df_level_1s >>>>>\n",
      "\t             OrderID         LineID       Quantity        Volume     Route  \\\n",
      "count  489223.000000  489220.000000  489214.000000  4.886480e+05  489203.0   \n",
      "mean    66748.301729       9.105787       3.459688  6.043753e+04       1.0   \n",
      "std     29389.750123       5.269233      63.871560  3.008953e+05       0.0   \n",
      "min         7.000000       0.000000       0.000000  0.000000e+00       1.0   \n",
      "25%     43178.000000       7.000000       0.000000  2.500000e+02       1.0   \n",
      "50%     70606.000000       7.000000       0.000000  2.000000e+04       1.0   \n",
      "75%     93077.000000       8.000000       0.000000  2.000000e+04       1.0   \n",
      "max    108871.000000      22.000000   11000.000000  8.640000e+06       1.0   \n",
      "\n",
      "          Validation         PfIDNo          OrdID    PrepVolume  \\\n",
      "count  420703.000000  490352.000000  490303.000000  4.903520e+05   \n",
      "mean        0.000002  140210.901632   93507.812905  6.174207e+04   \n",
      "std         0.001542    7812.269041    8317.485637  2.990403e+05   \n",
      "min         0.000000     996.000000       0.000000  1.000000e-02   \n",
      "25%         0.000000  134158.000000   87389.000000  2.500000e+02   \n",
      "50%         0.000000  140875.000000   94321.000000  2.000000e+04   \n",
      "75%         0.000000  146415.250000  100143.000000  2.000000e+04   \n",
      "max         1.000000  152150.000000  105861.000000  2.000000e+06   \n",
      "\n",
      "          PrepVessel    AmpRetains  AmpNumberGood   AmpNumberBad  \\\n",
      "count  490352.000000  79565.000000   4.636430e+05  255902.000000   \n",
      "mean        2.196027      4.732885   1.405807e+03       4.429442   \n",
      "std         0.999678      1.086998   4.153118e+04      17.810452   \n",
      "min         1.000000      0.000000   0.000000e+00       0.000000   \n",
      "25%         1.000000      5.000000   4.200000e+01       0.000000   \n",
      "50%         3.000000      5.000000   4.300000e+01       0.000000   \n",
      "75%         3.000000      5.000000   4.300000e+01       5.000000   \n",
      "max         4.000000     15.000000   2.000000e+06    1100.000000   \n",
      "\n",
      "       AmpBulkRemain     QCExpMonth   QCValidation    FgInvCount  \\\n",
      "count   18405.000000  490347.000000  490352.000000  4.636490e+05   \n",
      "mean      666.891877      34.610382       1.648167  1.405615e+03   \n",
      "std      3639.022678      17.110816       0.503903  4.153079e+04   \n",
      "min         0.000000       0.000000       0.000000  0.000000e+00   \n",
      "25%        40.000000      24.000000       1.000000  4.200000e+01   \n",
      "50%        70.000000      48.000000       2.000000  4.300000e+01   \n",
      "75%       350.000000      48.000000       2.000000  4.300000e+01   \n",
      "max     60000.000000     120.000000       3.000000  2.000000e+06   \n",
      "\n",
      "        CofAHeaderNo  \n",
      "count  490352.000000  \n",
      "mean        2.315055  \n",
      "std         2.730212  \n",
      "min         1.000000  \n",
      "25%         1.000000  \n",
      "50%         2.000000  \n",
      "75%         2.000000  \n",
      "max        15.000000  \n",
      "df_month == (INDEX):\n",
      "RangeIndex(start=0, stop=42913, step=1)\n",
      "qcdate_idx == (TYPE):\n",
      "<class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "LENGTH == 42913\n",
      "qcdate_col == (TYPE):\n",
      "<class 'pandas.core.series.Series'>\n",
      "LENGTH == 42913\n",
      "productno_col == (TYPE):\n",
      "<class 'pandas.core.series.Series'>\n",
      "LENGTH == 42913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\derbates\\miniconda3\\envs\\py3\\lib\\site-packages\\ipykernel_launcher.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_month_FINALE **INDEX**:\n",
      "DatetimeIndex(['2020-02-03', '2020-02-03', '2020-02-03', '2020-02-03',\n",
      "               '2020-02-03', '2020-02-03', '2020-02-03', '2020-02-03',\n",
      "               '2020-02-03', '2020-02-03',\n",
      "               ...\n",
      "               '2020-03-31', '2020-03-31', '2020-03-31', '2020-03-31',\n",
      "               '2020-03-31', '2020-03-31', '2020-03-31', '2020-03-31',\n",
      "               '2020-03-31', '2020-03-31'],\n",
      "              dtype='datetime64[ns]', name='QCDate', length=42913, freq=None)\n",
      "s_month:\n",
      "QCDate\n",
      "2020-02-03   NaN\n",
      "2020-02-03   NaN\n",
      "2020-02-03   NaN\n",
      "2020-02-03   NaN\n",
      "2020-02-03   NaN\n",
      "              ..\n",
      "2020-03-31   NaN\n",
      "2020-03-31   NaN\n",
      "2020-03-31   NaN\n",
      "2020-03-31   NaN\n",
      "2020-03-31   NaN\n",
      "Name: QCDate, Length: 42913, dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42913 entries, 0 to 42912\n",
      "Data columns (total 2 columns):\n",
      "QCDate       42913 non-null datetime64[ns]\n",
      "ProductNo    42913 non-null object\n",
      "dtypes: datetime64[ns](1), object(1)\n",
      "memory usage: 670.6+ KB\n",
      "\tdf_save_qcdate:\n",
      "None\n",
      "          QCDate       ProductNo\n",
      "0     2020-02-03   G1969-85026-X\n",
      "1     2020-02-03   G1969-85026-X\n",
      "2     2020-02-03   G1969-85026-X\n",
      "3     2020-02-03   G1969-85026-X\n",
      "4     2020-02-03   G1969-85026-X\n",
      "...          ...             ...\n",
      "42908 2020-03-31  BK-220-95355-A\n",
      "42909 2020-03-31       CUS-11389\n",
      "42910 2020-03-31  BK-220-95355-A\n",
      "42911 2020-03-31  BK-220-95355-A\n",
      "42912 2020-03-31  BK-220-95355-A\n",
      "\n",
      "[42913 rows x 2 columns]\n",
      "\n",
      "TYPE : <class 'TypeError'>\n",
      "FILE : <ipython-input-2-f56b91e16e3e>\n",
      "LINE : 156\n",
      "MESG : \n",
      "\n",
      "<class 'TypeError'>\n",
      "'<' not supported between instances of 'Timestamp' and 'int'\n",
      "\t\t<traceback object at 0x000001A05A9FD648>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": # {\n",
    "    test_metrics = TISS_Metrics(the_logger=None, \n",
    "                                materials_file=\"C:/data/inbound/2020-04-01/material_list.csv\")\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
