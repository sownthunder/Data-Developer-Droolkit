{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T15:24:49.528904Z",
     "start_time": "2020-03-25T15:24:46.761835Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import pyodbc\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.drawing.image import Image\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import tempfile\n",
    "from ttkthemes import ThemedStyle\n",
    "import tkinter as tk\n",
    "import tkinter.ttk as ttk\n",
    "from tkinter import messagebox, filedialog, commondialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T15:24:49.614873Z",
     "start_time": "2020-03-25T15:24:49.530876Z"
    }
   },
   "outputs": [],
   "source": [
    "class TISS_Metrics(): # {\n",
    "    \n",
    "    user_name = str(os.getlogin())\n",
    "    outbound_dir = \"C:/data/outbound/\" + str(pd.Timestamp.now())[:10]\n",
    "    desktop_dir = \"OneDrive - Agilent Technologies/Desktop\"\n",
    "    \n",
    "    def __init__(self, the_logger, materials_file): # {\n",
    "        self.the_logger = the_logger\n",
    "        self.materials_file = materials_file\n",
    "        # create dataframe from infile\n",
    "        self.df_infile = pd.read_csv(self.materials_file, header=0, dtype=np.str, engine='python')\n",
    "        # EXPORT?\n",
    "        self.df_infile.to_csv(os.path.join(self.outbound_dir, \"df_infile-\"\n",
    "                                          + str(pd.Timestamp.now())[:10]\n",
    "                                          + \".csv\"))\n",
    "        # Get/Set USERNAME & DESKTOP DIRECTORIES\n",
    "        self.user_name_dir = os.path.join(\"C:/Users/\", self.user_name)\n",
    "        self.desktop_dir = os.path.join(self.user_name_dir, self.desktop_dir)\n",
    "        print(self.user_name_dir)\n",
    "        print(self.desktop_dir)\n",
    "        self.run(day_range=30)\n",
    "    # }\n",
    "    \n",
    "    def run(self, day_range): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # [2020-02-28]\\\\self.time_unit = time_unit\n",
    "            # [2020-02-28]\\\\self.time_value = time_value\n",
    "            self.day_range = day_range\n",
    "            # get/set current date variable\n",
    "            # [2020-03-06]\\\\the_date = pd.Timestamp.now()\n",
    "            # [2020-03-11]\\\\the_date = pd.Timestamp(ts_input=str(self.end_date.get()))\n",
    "            the_date = pd.Timestamp.now()\n",
    "            # create variable for a month ago\n",
    "            one_month_ago = the_date - timedelta(days = int(day_range))\n",
    "            # [2020-02-28]\\\\\n",
    "            ##one_month_ago = the_date - pd.Timedelta(unit=str(self.time_unit), value=str(self.time_value))\n",
    "            print(type(one_month_ago))\n",
    "            # CREATE METRICS TABLE FROM CLASS METHOD\n",
    "            self.df_metrics_table = self.create_metrics_table()\n",
    "            #############################\n",
    "            # create .csv with no drops #\n",
    "            #############################\n",
    "            \"\"\"\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_metrics_noDrop.csv\"), \n",
    "                                         index=True)\n",
    "            # DROP ROWS WITH PRODUCT LEVEL && QCDATE = NONE\n",
    "            self.df_metrics_table.dropna(axis=0, subset=['QCDate', 'ProductLevel'], how='any', \n",
    "                                         inplace=True)\n",
    "            # create .csv with DROPS\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_metrics_DROP.csv\"), \n",
    "                                         index=True)\n",
    "            \"\"\"\n",
    "            # Set index of METRICS\n",
    "            # [2020-03-11]\\\\self.df_metrics_table.set_index(['QCDate'], inplace=True)\n",
    "            self.df_metrics_table.index = self.df_metrics_table['QCDate']\n",
    "            del self.df_metrics_table['QCDate']\n",
    "            print(self.df_metrics_table)\n",
    "            # Display Index\n",
    "            print(self.df_metrics_table.index)\n",
    "            #############################\n",
    "            # create .csv with UNSORTED #\n",
    "            #############################\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_TIS_metrics_UNSORTED.csv\"), \n",
    "                                         index=True)\n",
    "            # SORT INDEX\n",
    "            self.df_metrics_table.sort_index(inplace=True)\n",
    "            ###########################\n",
    "            # create .csv with SORTED #\n",
    "            ###########################\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_TIS_metrics_SORTED.csv\"), \n",
    "                                         index=True)\n",
    "            print(\"SORTED:\\n\")\n",
    "            print(self.df_metrics_table.index)\n",
    "            # SLICE & DICE THE DATAFRAME\n",
    "            # [2020-03-11]\\\\self.df_level_1s = self.df_metrics_table.loc['2017-01-02']\n",
    "            print(\"<<<<< df_level_1s >>>>>\\n\\t\" + str(self.df_metrics_table.loc['2017-01-02':'2020-01-01'].info()))\n",
    "            # SLICE AND DICE THE DATAFRAME TO A MONTH PERIOD\n",
    "            df_month = self.df_metrics_table.loc['2020-02-01':'2020-02-29']\n",
    "            # CREATE EMPTY DATAFRAME TO HOLD THE MONTH OF FEBRUARY\n",
    "            df_month_FINALE = pd.DataFrame(data=None, dtype=np.str, index=df_month.index)\n",
    "            # NARROW DOWN ON COLUMNS\n",
    "            df_month_FINALE[\"QCDate\"] = df_month.index\n",
    "            df_month_FINALE[\"OrderID\"] = df_month[\"OrderID\"]\n",
    "            df_month_FINALE[\"ProductNo\"] = df_month[\"ProductNo\"]\n",
    "            df_month_FINALE[\"Volume\"] = df_month[\"Volume\"]\n",
    "            df_month_FINALE[\"BuildByDate\"] = df_month[\"BuildByDate\"]\n",
    "            df_month_FINALE[\"OrderDate\"] = df_month[\"OrderDate\"]\n",
    "            df_month_FINALE[\"PrepDate\"] = df_month[\"PrepDate\"]\n",
    "            df_month_FINALE[\"PrepVolume\"] = df_month[\"PrepVolume\"]\n",
    "            df_month_FINALE[\"UnitizeNLT\"] = df_month[\"UnitizeNLT\"]\n",
    "            df_month_FINALE[\"ShipNLTDate\"] = df_month[\"ShipNLTDate\"]\n",
    "            df_month_FINALE[\"BulkQCDate\"] = df_month[\"BulkQCDate\"]\n",
    "            df_month_FINALE[\"AmpDate\"] = df_month[\"AmpDate\"]\n",
    "            df_month_FINALE[\"GreenSheet\"] = df_month[\"GreenSheet\"]\n",
    "            df_month_FINALE[\"SOLink\"] = df_month[\"SOLink\"]\n",
    "            df_month_FINALE[\"Notes\"] = df_month[\"Notes\"]\n",
    "            # Export?\n",
    "            df_month_FINALE.to_csv(os.path.join(self.outbound_dir, \"df-TIS-month-\"\n",
    "                                        + str(pd.Timestamp.now())[:10]\n",
    "                                        + \".csv\"), index=True)\n",
    "            df_merge = pd.merge(df_month_FINALE, self.df_infile, on='ProductNo', how='inner')\n",
    "            # RESET INDEX BACK TO QCDATE?\n",
    "            # <<<< >>>> \n",
    "            # EXPORT ??\n",
    "            df_merge.to_csv(os.path.join(self.outbound_dir, \"df-TIS-month-MATERIAL-MERGE-\"\n",
    "                                        + str(pd.Timestamp.now())[:10]\n",
    "                                        + \".csv\"), index=True)\n",
    "            # GET TIMESTMP FOR TODAY\n",
    "            ts_now = pd.Timestamp.now()\n",
    "            # create timedelta for LAST WEEK\n",
    "            td_last_week = pd.Timedelta(days=7)\n",
    "            # create timedelta for YESTERDAY\n",
    "            td_yesterday = pd.Timedelta(days=2)\n",
    "            # create actual TIMESTAMP for last week (whenever it was)\n",
    "            ts_last_week = pd.Timestamp(ts_now - td_last_week)\n",
    "            # create actual TIMESTAMP for YESTERDAY\n",
    "            ts_yesterday = pd.Timestamp(ts_now - td_yesterday)\n",
    "            ## CREATE DATAFRAME OF LAST WEEK\n",
    "            df_last_week = self.df_metrics_table.loc[ts_last_week:ts_now]\n",
    "            ## CREATE DATAFRAME OF YESTERDAY\n",
    "            df_yesterday = self.df_metrics_table.loc[ts_yesterday:ts_now]\n",
    "            # EXPORT ??\n",
    "            df_last_week.to_csv(os.path.join(self.outbound_dir, \"df_TIS-last-week-\" \n",
    "                                             + str(pd.Timestamp.now())[:10] \n",
    "                                             + \".csv\"))\n",
    "            print(\"LAST WEEK COLS:\\n\" + str(df_last_week.columns))\n",
    "            # CREATE NEW EMPTY DATAFRAME (to hold SPEICIFIC columns)\n",
    "            df_yesterday_FINALE = pd.DataFrame(data=None, dtype=np.str, index=df_yesterday.index)\n",
    "            # [2020-03-12]\\\\df_yesterday_FINALE[\"QCDate\"] = df_yesterday[\"QCDate\"]\n",
    "            # [2020-03-24]\\\\df_yesterday_FINALE[\"QCDate\"] = df_yesterday.index\n",
    "            df_yesterday_FINALE[\"QCDate\"] = self.df_tblProdflow[\"QCDate\"]\n",
    "            df_yesterday_FINALE[\"OrderID\"] = df_yesterday[\"OrderID\"]\n",
    "            df_yesterday_FINALE[\"ProductNo\"] = df_yesterday[\"ProductNo\"]\n",
    "            df_yesterday_FINALE[\"Volume\"] = df_yesterday[\"Volume\"]\n",
    "            df_yesterday_FINALE[\"BuildByDate\"] = df_yesterday[\"BuildByDate\"]\n",
    "            df_yesterday_FINALE[\"OrderDate\"] = df_yesterday[\"OrderDate\"]\n",
    "            df_yesterday_FINALE[\"PrepDate\"] = df_yesterday[\"PrepDate\"]\n",
    "            df_yesterday_FINALE[\"PrepVolume\"] = df_yesterday[\"PrepVolume\"]\n",
    "            # [2020-03-13]\\\\df_yesterday_FINALE[\"QCDate\"] = df_yesterday[\"QCDate\"]\n",
    "            # [2020-03-17]\\\\df_yesterday_FINALE[\"QCDate\"] = df_yesterday.index\n",
    "            df_yesterday_FINALE[\"UnitizeNLT\"] = df_yesterday[\"UnitizeNLT\"]\n",
    "            df_yesterday_FINALE[\"ShipNLTDate\"] = df_yesterday[\"ShipNLTDate\"]\n",
    "            df_yesterday_FINALE[\"BulkQCDate\"] = df_yesterday[\"BulkQCDate\"]\n",
    "            df_yesterday_FINALE[\"AmpDate\"] = df_yesterday[\"AmpDate\"]\n",
    "            df_yesterday_FINALE[\"GreenSheet\"] = df_yesterday[\"GreenSheet\"]\n",
    "            df_yesterday_FINALE[\"SOLink\"] = df_yesterday[\"SOLink\"]\n",
    "            # [2020-03-17]\\\\df_yesterday_FINALE[\"QCExpDate\"] = df_yesterday[\"QCExpDate\"]\n",
    "            # [2020-03-17]\\\\df_yesterday_FINALE[\"QCMemo\"] = df_yesterday[\"QCMemo\"]\n",
    "            df_yesterday_FINALE[\"Notes\"] = df_yesterday[\"Notes\"]\n",
    "            \"\"\"\n",
    "            df_yesterday_FINALE[\"PrepDate\"] = df_yesterday[\"PrepDate\"]\n",
    "            df_yesterday_FINALE[\"BulkQCDate\"] = df_yesterday[\"BulkQCDate\"]\n",
    "            df_yesterday_FINALE[\"AmpDate\"] = df_yesterday[\"AmpDate\"]\n",
    "            df_yesterday_FINALE[\"ProductNo\"] = df_yesterday[\"ProductNo\"]\n",
    "            df_yesterday_FINALE[\"OrderID\"] = df_yesterday[\"OrderID\"]\n",
    "            df_yesterday_FINALE[\"OrderDate\"] = df_yesterday[\"OrderDate\"]\n",
    "            df_yesterday_FINALE[\"Notes\"] = df_yesterday[\"Notes\"]\n",
    "            \"\"\"\n",
    "            df_yesterday_FINALE.to_csv(os.path.join(self.outbound_dir, \"df_TIS-yesterday-\"\n",
    "                                             + str(pd.Timestamp.now())[:10]\n",
    "                                             + \".csv\"), index=True)\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "    \"\"\"\n",
    "    Referred to as \"ProdflowII\" in SQL-Server\n",
    "    \"\"\"\n",
    "    def pull_ProdflowII_table(self, table_name): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # CREATION CONNECTION STR\n",
    "            conn_str = str(\n",
    "                r'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "                r'SERVER=wtkngappflow1.is.agilent.net;'\n",
    "                r'DATABASE=ProdFlowII_Prod;'\n",
    "                r'Trusted_Connection=yes;'\n",
    "            )\n",
    "            # CREATE PYODBC CONNECTION\n",
    "            cnxn_ProdflowII = pyodbc.connect(conn_str)\n",
    "            # [2020-02-028]\\\\crsr_ProdflowII = cnxn_ProdflowII.cursor()\n",
    "            # PERFORM SQL QUERY AND SET AS DATAFRAME\n",
    "            df_ProdflowII_table = pd.read_sql_query(sql='SELECT * FROM ' + str(table_name),\n",
    "                                                    con=cnxn_ProdflowII\n",
    "                                                    )\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "            return df_ProdflowII_table\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "    \"\"\"\n",
    "    Referred to as \"Prodflow\" in SQL-Server\n",
    "    \"\"\"\n",
    "    def pull_ProdflowIII_table(self, table_name): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # CREATE CONNECTION STRING\n",
    "            conn_str = str(\n",
    "                r'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "                r'SERVER=wtkngappflow1.is.agilent.net;'\n",
    "                r'DATABASE=ProdFlow;'\n",
    "                r'Trusted_Connection=yes;'\n",
    "            )\n",
    "            # CREATE PYODBC CONNECTION\n",
    "            cnxn_ProdflowIII = pyodbc.connect(conn_str)\n",
    "            # [2020-02-28]\\\\crsr_ProdflowIII = cnxn_ProdflowIII,cursor()\n",
    "            # PERFORM SQL QUERY AND SET AS DATAFRAME\n",
    "            df_ProdflowIII_table = pd.read_sql_query(sql='SELECT * FROM ' + str(table_name),\n",
    "                                                     con=cnxn_ProdflowIII,\n",
    "                                                     parse_dates=['QCDate']\n",
    "                                                     )\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "            return df_ProdflowIII_table\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "    def create_metrics_table(self): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # pull ORDERS table\n",
    "            self.df_orders = self.pull_ProdflowII_table(table_name='Orders')\n",
    "            # EXPORT A SAMPLE\n",
    "            self.df_orders.sample(25).to_csv(os.path.join(self.outbound_dir, \"df-ORDERS-table-\"\n",
    "                                                         + str(pd.Timestamp.now())[:10]\n",
    "                                                         + \".csv\"))\n",
    "            # [2020-03-11]\\\\export_path = os.path.join(self.outbound_dir, \"df_orders.csv\")\n",
    "            # [2020-03-11]\\\\self.df_orders.to_csv(export_path, index=True)\n",
    "            # RENAME ['Product#'] column to [\"ProductNo\"]\n",
    "            self.df_orders.rename(columns={'Product#': 'ProductNo'}, inplace=True)\n",
    "            print(\"\\tORDERS-TABLE:\\n\" + str(self.df_orders.info()))\n",
    "            # pull tblProdflow TABLE\n",
    "            self.df_tblProdflow = self.pull_ProdflowIII_table(table_name='tblProdflow')\n",
    "            # EXPORT A SAMPLE\n",
    "            self.df_tblProdflow.sample(25).to_csv(os.path.join(self.outbound_dir, \"df-ORDERS-table-\"\n",
    "                                                         + str(pd.Timestamp.now())[:10]\n",
    "                                                         + \".csv\"))\n",
    "            print(self.df_tblProdflow.info())\n",
    "            ########################\n",
    "            # CREATE METRICS TABLE #\n",
    "            ########################\n",
    "            df_metrics_table = pd.merge(self.df_orders, self.df_tblProdflow, on='ProductNo', how='right')\n",
    "            ######################\n",
    "            # CHANGE DATA TYPES: #\n",
    "            ######################\n",
    "            \n",
    "            # CHANGE ['QCDate'] COLUMN TO DATETIME\n",
    "            df_metrics_table['QCDate'] = pd.to_datetime(df_metrics_table['QCDate'])\n",
    "            ####################################\n",
    "            # DROP ALL ROWS WITHOUT A 'QCDATE' #\n",
    "            ####################################\n",
    "            df_metrics_table.dropna(axis=0, subset=['QCDate'],\n",
    "                                   how='any', inplace=True)\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        #}\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "            return df_metrics_table\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "    def send_email(self, send_from, send_to, subject, message, files=[],\n",
    "                  server=\"cos.smtp.agilent.com\", port=587, use_tls=True): # {\n",
    "        print(\"SENDING E-MAIL...\\nDATE == \" + str(pd.Timestamp.now())[:10])\n",
    "        msg = MIMEMultipart()\n",
    "        msg['From'] = send_from\n",
    "        msg['To'] = COMMASPACE.join(send_to)\n",
    "        msg['Date'] = formatdate(localtime=True)\n",
    "        msg['Subject'] = subject\n",
    "        \n",
    "        msg.attach(MIMEText(message))\n",
    "    # }\n",
    "    \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T15:28:26.151615Z",
     "start_time": "2020-03-25T15:24:49.616874Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/derbates\n",
      "C:/Users/derbates\\OneDrive - Agilent Technologies/Desktop\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "Operation Completed Successfully...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 106559 entries, 0 to 106558\n",
      "Data columns (total 28 columns):\n",
      "OrderID            106559 non-null int64\n",
      "Quote#             106553 non-null object\n",
      "ProductNo          106559 non-null object\n",
      "LineID             106550 non-null float64\n",
      "Quantity           106490 non-null float64\n",
      "SaleUnit           95030 non-null object\n",
      "Company            106293 non-null object\n",
      "Volume             106293 non-null float64\n",
      "VolUnit            40636 non-null object\n",
      "OrderDate          106553 non-null datetime64[ns]\n",
      "BuildByDate        106008 non-null object\n",
      "ShipNLTDate        105974 non-null object\n",
      "Route              106558 non-null float64\n",
      "FullValidation     106559 non-null bool\n",
      "Validation         76105 non-null float64\n",
      "Built              106559 non-null bool\n",
      "GreenSheet         78364 non-null object\n",
      "Notes              32719 non-null object\n",
      "Completed          106559 non-null bool\n",
      "SOLink             32000 non-null object\n",
      "UserFormulation    32430 non-null object\n",
      "UserUnitizing      0 non-null object\n",
      "UserBulkQC         0 non-null object\n",
      "UserQC             0 non-null object\n",
      "EquipShort         2 non-null object\n",
      "UnitizeNLT         35411 non-null object\n",
      "SpecialPrep        106559 non-null bool\n",
      "RushPriority       106559 non-null bool\n",
      "dtypes: bool(5), datetime64[ns](1), float64(5), int64(1), object(16)\n",
      "memory usage: 19.2+ MB\n",
      "\tORDERS-TABLE:\n",
      "None\n",
      "Operation Completed Successfully...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 109247 entries, 0 to 109246\n",
      "Data columns (total 53 columns):\n",
      "PfIDNo              109247 non-null int64\n",
      "PfBatchID           109247 non-null object\n",
      "ProductNo           109228 non-null object\n",
      "OrdID               93115 non-null float64\n",
      "QuoteNo             109211 non-null object\n",
      "PfSentTo            109182 non-null object\n",
      "PrepDate            108224 non-null datetime64[ns]\n",
      "PrepVolume          109201 non-null float64\n",
      "PrepUnit            109171 non-null object\n",
      "PrepVessel          109168 non-null float64\n",
      "PrepVBarcode        58560 non-null object\n",
      "PrdSaleUnit         89921 non-null object\n",
      "PrepMatrixNo        109172 non-null object\n",
      "PrepMatrixLot       108303 non-null object\n",
      "PrepInits           108061 non-null object\n",
      "PrepMemo            61707 non-null object\n",
      "PrepNotebookRef     48969 non-null object\n",
      "BulkQCStatus        24 non-null object\n",
      "BulkQCDate          75521 non-null datetime64[ns]\n",
      "BulkPassFail        74578 non-null object\n",
      "BulkQCInits         75505 non-null object\n",
      "BulkQCMemo          2171 non-null object\n",
      "BulkLotNo           73833 non-null object\n",
      "AmpRetains          52050 non-null float64\n",
      "AmpDate             93221 non-null datetime64[ns]\n",
      "AmpPreLabel         109247 non-null bool\n",
      "AmpNumberGood       93548 non-null float64\n",
      "AmpNumberBad        77828 non-null float64\n",
      "AmpBulkRemain       4422 non-null float64\n",
      "AmpTimeIn           92978 non-null datetime64[ns]\n",
      "AmpTimeOut          92978 non-null datetime64[ns]\n",
      "AmpInits            93186 non-null object\n",
      "QCStatus            573 non-null object\n",
      "QCDate              103691 non-null datetime64[ns]\n",
      "QCPassFail          103880 non-null object\n",
      "QCAuthInits         103679 non-null object\n",
      "QCMemo              55580 non-null object\n",
      "QCMethod            1207 non-null object\n",
      "LotNo               100972 non-null object\n",
      "QCExpMonth          93889 non-null float64\n",
      "QCExpDate           92301 non-null datetime64[ns]\n",
      "QCSellBy            0 non-null object\n",
      "QCFullValidation    109247 non-null bool\n",
      "QCValidation        109213 non-null float64\n",
      "FgInvCount          78415 non-null float64\n",
      "FgAccpacNote        19760 non-null object\n",
      "CofAHeaderNo        109215 non-null float64\n",
      "QCChromatogram      0 non-null object\n",
      "Correct             109247 non-null bool\n",
      "DoNotCorrect        109247 non-null bool\n",
      "DensityUnit         0 non-null object\n",
      "DensityTemp         0 non-null object\n",
      "recipeid            1 non-null object\n",
      "dtypes: bool(4), datetime64[ns](7), float64(11), int64(1), object(30)\n",
      "memory usage: 41.3+ MB\n",
      "None\n",
      "Operation Completed Successfully...\n",
      "            OrderID     Quote#    ProductNo  LineID  Quantity  \\\n",
      "QCDate                                                          \n",
      "2005-04-08      2.0  021004-27     CUS-5465     7.0      10.0   \n",
      "2005-04-08   3420.0  040405-54     CUS-5465     7.0       4.0   \n",
      "2004-04-13      2.0  021004-27     CUS-5465     7.0      10.0   \n",
      "2004-04-13   3420.0  040405-54     CUS-5465     7.0       4.0   \n",
      "2004-04-12      4.0  031504-11     CUS-5459     7.0      10.0   \n",
      "...             ...        ...          ...     ...       ...   \n",
      "2019-04-11      NaN        NaN  5190-0484-a     NaN       NaN   \n",
      "2019-10-04      NaN        NaN       BULK-2     NaN       NaN   \n",
      "2019-12-17      NaN        NaN      JHP-683     NaN       NaN   \n",
      "2020-02-05      NaN        NaN      JHP-327     NaN       NaN   \n",
      "2020-03-11      NaN        NaN      JHP-327     NaN       NaN   \n",
      "\n",
      "                                             SaleUnit  \\\n",
      "QCDate                                                  \n",
      "2005-04-08  1 mL in 2 mL Flame-Sealed Amber Ampule(s)   \n",
      "2005-04-08          1 mL Flame-Sealed Amber Ampule(s)   \n",
      "2004-04-13  1 mL in 2 mL Flame-Sealed Amber Ampule(s)   \n",
      "2004-04-13          1 mL Flame-Sealed Amber Ampule(s)   \n",
      "2004-04-12          1 mL Flame-Sealed Amber Ampule(s)   \n",
      "...                                               ...   \n",
      "2019-04-11                                        NaN   \n",
      "2019-10-04                                        NaN   \n",
      "2019-12-17                                        NaN   \n",
      "2020-02-05                                        NaN   \n",
      "2020-03-11                                        NaN   \n",
      "\n",
      "                               Company  Volume VolUnit  OrderDate  ...  \\\n",
      "QCDate                                                             ...   \n",
      "2005-04-08  Missouri American Water Co   850.0      mL 2014-05-05  ...   \n",
      "2005-04-08     Missouri American Water    25.0      mL 2005-04-05  ...   \n",
      "2004-04-13  Missouri American Water Co   850.0      mL 2014-05-05  ...   \n",
      "2004-04-13     Missouri American Water    25.0      mL 2005-04-05  ...   \n",
      "2004-04-12  Carnegie Mellon University    25.0      mL 2004-04-07  ...   \n",
      "...                                ...     ...     ...        ...  ...   \n",
      "2019-04-11                         NaN     NaN     NaN        NaT  ...   \n",
      "2019-10-04                         NaN     NaN     NaN        NaT  ...   \n",
      "2019-12-17                         NaN     NaN     NaN        NaT  ...   \n",
      "2020-02-05                         NaN     NaN     NaN        NaT  ...   \n",
      "2020-03-11                         NaN     NaN     NaN        NaT  ...   \n",
      "\n",
      "           QCValidation FgInvCount  FgAccpacNote CofAHeaderNo  QCChromatogram  \\\n",
      "QCDate                                                                          \n",
      "2005-04-08          1.0       16.0          None          1.0            None   \n",
      "2005-04-08          1.0       16.0          None          1.0            None   \n",
      "2004-04-13          1.0        NaN          None          1.0            None   \n",
      "2004-04-13          1.0        NaN          None          1.0            None   \n",
      "2004-04-12          1.0        NaN          None          1.0            None   \n",
      "...                 ...        ...           ...          ...             ...   \n",
      "2019-04-11          2.0       65.0          None          2.0            None   \n",
      "2019-10-04          2.0     2000.0    blue sheet          2.0            None   \n",
      "2019-12-17          1.0        NaN     no action         15.0            None   \n",
      "2020-02-05          1.0        NaN     no action         15.0            None   \n",
      "2020-03-11          1.0        NaN     no action         15.0            None   \n",
      "\n",
      "           Correct DoNotCorrect DensityUnit DensityTemp recipeid  \n",
      "QCDate                                                            \n",
      "2005-04-08   False         True        None        None     None  \n",
      "2005-04-08   False         True        None        None     None  \n",
      "2004-04-13   False         True        None        None     None  \n",
      "2004-04-13   False         True        None        None     None  \n",
      "2004-04-12   False         True        None        None     None  \n",
      "...            ...          ...         ...         ...      ...  \n",
      "2019-04-11   False        False        None        None     None  \n",
      "2019-10-04   False        False        None        None     None  \n",
      "2019-12-17   False         True        None        None     None  \n",
      "2020-02-05   False         True        None        None     None  \n",
      "2020-03-11   False         True        None        None     None  \n",
      "\n",
      "[1800304 rows x 79 columns]\n",
      "DatetimeIndex(['2005-04-08', '2005-04-08', '2004-04-13', '2004-04-13',\n",
      "               '2004-04-12', '2012-03-14', '2012-03-14', '2012-03-14',\n",
      "               '2012-03-14', '2012-03-14',\n",
      "               ...\n",
      "               '2019-05-01', '2019-02-01', '2019-07-03', '2019-02-19',\n",
      "               '2019-03-04', '2019-04-11', '2019-10-04', '2019-12-17',\n",
      "               '2020-02-05', '2020-03-11'],\n",
      "              dtype='datetime64[ns]', name='QCDate', length=1800304, freq=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SORTED:\n",
      "\n",
      "DatetimeIndex(['1987-01-01', '1987-01-01', '1989-01-01', '1991-01-01',\n",
      "               '1991-01-01', '1991-01-01', '1991-01-01', '1992-01-01',\n",
      "               '1992-01-01', '1992-01-01',\n",
      "               ...\n",
      "               '2020-03-25', '2020-03-25', '2020-03-25', '2020-03-25',\n",
      "               '2020-03-25', '2020-03-25', '2020-03-25', '2020-03-25',\n",
      "               '2020-03-25', '2020-03-25'],\n",
      "              dtype='datetime64[ns]', name='QCDate', length=1800304, freq=None)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 488341 entries, 2017-01-03 to 2019-12-31\n",
      "Data columns (total 79 columns):\n",
      "OrderID             487197 non-null float64\n",
      "Quote#              487193 non-null object\n",
      "ProductNo           488341 non-null object\n",
      "LineID              487194 non-null float64\n",
      "Quantity            487188 non-null float64\n",
      "SaleUnit            463217 non-null object\n",
      "Company             486733 non-null object\n",
      "Volume              486622 non-null float64\n",
      "VolUnit             110728 non-null object\n",
      "OrderDate           487197 non-null datetime64[ns]\n",
      "BuildByDate         485633 non-null object\n",
      "ShipNLTDate         485671 non-null object\n",
      "Route               487177 non-null float64\n",
      "FullValidation      487197 non-null object\n",
      "Validation          418672 non-null float64\n",
      "Built               487197 non-null object\n",
      "GreenSheet          268886 non-null object\n",
      "Notes               151273 non-null object\n",
      "Completed           487197 non-null object\n",
      "SOLink              177005 non-null object\n",
      "UserFormulation     205188 non-null object\n",
      "UserUnitizing       0 non-null object\n",
      "UserBulkQC          0 non-null object\n",
      "UserQC              0 non-null object\n",
      "EquipShort          6 non-null object\n",
      "UnitizeNLT          224800 non-null object\n",
      "SpecialPrep         487197 non-null object\n",
      "RushPriority        487197 non-null object\n",
      "PfIDNo              488341 non-null int64\n",
      "PfBatchID           488341 non-null object\n",
      "OrdID               488292 non-null float64\n",
      "QuoteNo             488341 non-null object\n",
      "PfSentTo            488341 non-null object\n",
      "PrepDate            487874 non-null datetime64[ns]\n",
      "PrepVolume          488341 non-null float64\n",
      "PrepUnit            488341 non-null object\n",
      "PrepVessel          488341 non-null float64\n",
      "PrepVBarcode        464034 non-null object\n",
      "PrdSaleUnit         428801 non-null object\n",
      "PrepMatrixNo        488341 non-null object\n",
      "PrepMatrixLot       488341 non-null object\n",
      "PrepInits           488341 non-null object\n",
      "PrepMemo            408248 non-null object\n",
      "PrepNotebookRef     104 non-null object\n",
      "BulkQCStatus        1 non-null object\n",
      "BulkQCDate          466679 non-null datetime64[ns]\n",
      "BulkPassFail        466603 non-null object\n",
      "BulkQCInits         466664 non-null object\n",
      "BulkQCMemo          14518 non-null object\n",
      "BulkLotNo           463950 non-null object\n",
      "AmpRetains          79297 non-null float64\n",
      "AmpDate             463380 non-null datetime64[ns]\n",
      "AmpPreLabel         488341 non-null bool\n",
      "AmpNumberGood       461762 non-null float64\n",
      "AmpNumberBad        254939 non-null float64\n",
      "AmpBulkRemain       18346 non-null float64\n",
      "AmpTimeIn           463378 non-null datetime64[ns]\n",
      "AmpTimeOut          463378 non-null datetime64[ns]\n",
      "AmpInits            463377 non-null object\n",
      "QCStatus            5 non-null object\n",
      "QCPassFail          488269 non-null object\n",
      "QCAuthInits         488329 non-null object\n",
      "QCMemo              117262 non-null object\n",
      "QCMethod            6146 non-null object\n",
      "LotNo               481747 non-null object\n",
      "QCExpMonth          488336 non-null float64\n",
      "QCExpDate           485679 non-null datetime64[ns]\n",
      "QCSellBy            0 non-null object\n",
      "QCFullValidation    488341 non-null bool\n",
      "QCValidation        488341 non-null float64\n",
      "FgInvCount          461768 non-null float64\n",
      "FgAccpacNote        30143 non-null object\n",
      "CofAHeaderNo        488341 non-null float64\n",
      "QCChromatogram      0 non-null object\n",
      "Correct             488341 non-null bool\n",
      "DoNotCorrect        488341 non-null bool\n",
      "DensityUnit         0 non-null object\n",
      "DensityTemp         0 non-null object\n",
      "recipeid            1 non-null object\n",
      "dtypes: bool(4), datetime64[ns](7), float64(17), int64(1), object(50)\n",
      "memory usage: 285.0+ MB\n",
      "<<<<< df_level_1s >>>>>\n",
      "\tNone\n",
      "LAST WEEK COLS:\n",
      "Index(['OrderID', 'Quote#', 'ProductNo', 'LineID', 'Quantity', 'SaleUnit',\n",
      "       'Company', 'Volume', 'VolUnit', 'OrderDate', 'BuildByDate',\n",
      "       'ShipNLTDate', 'Route', 'FullValidation', 'Validation', 'Built',\n",
      "       'GreenSheet', 'Notes', 'Completed', 'SOLink', 'UserFormulation',\n",
      "       'UserUnitizing', 'UserBulkQC', 'UserQC', 'EquipShort', 'UnitizeNLT',\n",
      "       'SpecialPrep', 'RushPriority', 'PfIDNo', 'PfBatchID', 'OrdID',\n",
      "       'QuoteNo', 'PfSentTo', 'PrepDate', 'PrepVolume', 'PrepUnit',\n",
      "       'PrepVessel', 'PrepVBarcode', 'PrdSaleUnit', 'PrepMatrixNo',\n",
      "       'PrepMatrixLot', 'PrepInits', 'PrepMemo', 'PrepNotebookRef',\n",
      "       'BulkQCStatus', 'BulkQCDate', 'BulkPassFail', 'BulkQCInits',\n",
      "       'BulkQCMemo', 'BulkLotNo', 'AmpRetains', 'AmpDate', 'AmpPreLabel',\n",
      "       'AmpNumberGood', 'AmpNumberBad', 'AmpBulkRemain', 'AmpTimeIn',\n",
      "       'AmpTimeOut', 'AmpInits', 'QCStatus', 'QCPassFail', 'QCAuthInits',\n",
      "       'QCMemo', 'QCMethod', 'LotNo', 'QCExpMonth', 'QCExpDate', 'QCSellBy',\n",
      "       'QCFullValidation', 'QCValidation', 'FgInvCount', 'FgAccpacNote',\n",
      "       'CofAHeaderNo', 'QCChromatogram', 'Correct', 'DoNotCorrect',\n",
      "       'DensityUnit', 'DensityTemp', 'recipeid'],\n",
      "      dtype='object')\n",
      "Operation Completed Successfully...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": # {\n",
    "    test_metrics = TISS_Metrics(the_logger=None, \n",
    "                                materials_file=\"C:/data/inbound/2020-03-19/material_list.csv\")\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
