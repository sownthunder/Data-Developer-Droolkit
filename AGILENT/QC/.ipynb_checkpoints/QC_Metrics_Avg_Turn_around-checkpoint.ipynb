{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T20:22:59.908541Z",
     "start_time": "2020-03-24T20:22:56.713527Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import pyodbc\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.drawing.image import Image\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import tempfile\n",
    "from ttkthemes import ThemedStyle\n",
    "import tkinter as tk\n",
    "import tkinter.ttk as ttk\n",
    "from tkinter import messagebox, filedialog, commondialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T20:23:00.005546Z",
     "start_time": "2020-03-24T20:22:59.910543Z"
    },
    "code_folding": [
     37,
     40,
     43,
     60,
     67
    ]
   },
   "outputs": [],
   "source": [
    "class QC_Metrics_AvgTurnAround(): # {\n",
    "    \n",
    "    user_name = str(os.getlogin())\n",
    "    outbound_dir = \"C:/data/outbound/\" + str(pd.Timestamp.now())[:10]\n",
    "    desktop_dir = \"OneDrive - Agilent Technologies/Desktop\"\n",
    "    \n",
    "    def __init__(self, the_logger): # {\n",
    "        self.the_logger = the_logger\n",
    "        # Get/Set USERNAME & DESKTOP DIRECTORIES\n",
    "        self.user_name_dir = os.path.join(\"C:/Users/\", self.user_name)\n",
    "        self.desktop_dir = os.path.join(self.user_name_dir, self.desktop_dir)\n",
    "        print(self.user_name_dir)\n",
    "        print(self.desktop_dir)\n",
    "        self.run(day_range=30)\n",
    "    # }\n",
    "    \n",
    "    def run(self, day_range): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # [2020-02-28]\\\\self.time_unit = time_unit\n",
    "            # [2020-02-28]\\\\self.time_value = time_value\n",
    "            self.day_range = day_range\n",
    "            # get/set current date variable\n",
    "            # [2020-03-06]\\\\the_date = pd.Timestamp.now()\n",
    "            # [2020-03-11]\\\\the_date = pd.Timestamp(ts_input=str(self.end_date.get()))\n",
    "            the_date = pd.Timestamp.now()\n",
    "            # create variable for a month ago\n",
    "            one_month_ago = the_date - timedelta(days = int(day_range))\n",
    "            # [2020-02-28]\\\\\n",
    "            ##one_month_ago = the_date - pd.Timedelta(unit=str(self.time_unit), value=str(self.time_value))\n",
    "            print(type(one_month_ago))\n",
    "            # CREATE METRICS TABLE FROM CLASS METHOD\n",
    "            self.df_metrics_table = self.create_metrics_table()\n",
    "            #############################\n",
    "            # create .csv with no drops #\n",
    "            #############################\n",
    "            \"\"\"\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_metrics_noDrop.csv\"), \n",
    "                                         index=True)\n",
    "            # DROP ROWS WITH PRODUCT LEVEL && QCDATE = NONE\n",
    "            self.df_metrics_table.dropna(axis=0, subset=['QCDate', 'ProductLevel'], how='any', \n",
    "                                         inplace=True)\n",
    "            # create .csv with DROPS\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_metrics_DROP.csv\"), \n",
    "                                         index=True)\n",
    "            \"\"\"\n",
    "            # Set index of METRICS\n",
    "            # [2020-03-11]\\\\self.df_metrics_table.set_index(['QCDate', 'ProductLevel'], inplace=True)\n",
    "            \"\"\"\n",
    "            self.df_metrics_table.index = self.df_metrics_table['QCDate']\n",
    "            del self.df_metrics_table['QCDate']\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            # [2020-03-11]\\\\del self.df_metrics_table['ProductLevel']\n",
    "            print(self.df_metrics_table)\n",
    "            # Display Index\n",
    "            print(self.df_metrics_table.index)\n",
    "            #############################\n",
    "            # create .csv with UNSORTED #\n",
    "            #############################\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_QC_metrics_UNSORTED.csv\"), \n",
    "                                         index=True)\n",
    "            # SORT INDEX\n",
    "            self.df_metrics_table.sort_index(inplace=True)\n",
    "            ###########################\n",
    "            # create .csv with SORTED #\n",
    "            ###########################\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_QC_metrics_SORTED.csv\"), \n",
    "                                         index=True)\n",
    "            print(\"SORTED:\\n\")\n",
    "            print(self.df_metrics_table.index)\n",
    "            \"\"\"\n",
    "            # SLICE & DICE THE DATAFRAME\n",
    "            df_metrics_range = self.df_metrics_table[(self.df_metrics_table['QCDate'] > '2020-01-01') & (self.df_metrics_table['QCDate'] <= '2020-03-01')]\n",
    "            # DETERMINE DAYS IN QC\n",
    "            df_days_in_QC = pd.DataFrame(data=df_metrics_range['PfBatchID'])\n",
    "            calculation = df_metrics_range['QCDate'] - df_metrics_range['AmpDate']\n",
    "            df_days_in_QC['time-in-QC'] = calculation\n",
    "            df_days_in_QC['ProductLevel'] = df_metrics_range['ProductLevel']\n",
    "            df_days_in_QC.to_csv(\"C:/data/Outbound/2020-03-24/\" \n",
    "                                 + str(pd.Timestamp.now())[:10] \n",
    "                                 + \"-days-in-QC.csv\")\n",
    "            \"\"\"\n",
    "            { PERFORM GROUPBYS HERE }\n",
    "            \"\"\"\n",
    "            df_groupie_1 = df_metrics_range.groupby(['QCDate', 'ProductLevel'])[['PfBatchID']]\n",
    "            df_groupie_1_ct = df_groupie_1.count()\n",
    "            df_groupie_1_avg = df_metrics_range.mean()\n",
    "            \"\"\"\n",
    "            { PERFORM GROUPBY HERE }\n",
    "            \"\"\"\n",
    "            x = df_metrics_range.groupby([\"ProductLevel\"])[[\"QCDate\"]]\n",
    "            y = df_metrics_range.groupby([\"QCDate\"])[[\"ProductLevel\"]]\n",
    "            df_x = pd.DataFrame(data=x.mean())\n",
    "            df_x.to_csv(os.path.join(\"c:/data/Outbound/2020-03-24/\", \n",
    "                                         str(pd.Timestamp.now())[:10]\n",
    "                                         + \"-x-mean.csv\"), index=True)\n",
    "            df_y = pd.DataFrame(data=y.mean())\n",
    "            df_y.to_csv(os.path.join(\"c:/data/Outbound/2020-03-24/\",\n",
    "                                         str(pd.Timestamp.now())[:10]\n",
    "                                         + \"-y-mean.csv\"), index=True)\n",
    "            # HOW MANY PfBatchID per ProductLevel, per QCDate?\n",
    "            self.ProdsPerDay = df_metrics_range.groupby(['QCDate', 'ProductLevel'])[['PfBatchID']].count()\n",
    "            df_prods_per_day = pd.DataFrame(data=self.ProdsPerDay)\n",
    "            self.ProdsPerDay.to_csv(os.path.join(\"c:/data/Outbound/2020-03-24/\",\n",
    "                                                 str(pd.Timestamp.now())[:10]\n",
    "                                                 + \"-ProdsPerDay.csv\"), index=True)\n",
    "            \"\"\"\n",
    "            { PERFORM DATA-AGGREGATION HERE }\n",
    "            { PERFORM DATA-AGGREGATION HERE }\n",
    "            \"\"\"\n",
    "            # rolling window?\n",
    "            r = df_groupie_1.rolling(window=3).mean()\n",
    "            # [2020-03-24]\\\\print(r['PfBatchID'].aggregate(['mean']))\n",
    "            #print(r.agg({'PfBatchID':'mean'}))\n",
    "            ##########\n",
    "            # EXPORT #\n",
    "            ##########\n",
    "            df_groupie_1.to_csv(os.path.join(self.outbound_dir, \"df-groupie-1-\"\n",
    "                                             + str(pd.Timestamp.now())[:10]\n",
    "                                             + \".csv\"), index=True)\n",
    "            df_groupie_1_ct.to_csv(os.path.join(self.outbound_dir, \"df-groupie-1-ct-\"\n",
    "                                                + str(pd.Timestamp.now())[:10]\n",
    "                                                + \".csv\"), index=True)\n",
    "            df_groupie_1_avg.to_csv(os.path.join(self.outbound_dir, \"df-groupie-1-avg-\"\n",
    "                                                 + str(pd.Timestamp.now())[:10]\n",
    "                                                 + \".csv\"), index=True)\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "    def perform_groupBy(self, dataframe): # { \n",
    "        pass\n",
    "    # }\n",
    "    \n",
    "    \"\"\"\n",
    "    Referred to as \"ProdflowII\" in SQL-Server\n",
    "    \"\"\"\n",
    "    def pull_ProdflowII_table(self, table_name): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # CREATION CONNECTION STR\n",
    "            conn_str = str(\n",
    "                r'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "                r'SERVER=wtkngappflow1.is.agilent.net;'\n",
    "                r'DATABASE=ProdFlowII_Prod;'\n",
    "                r'Trusted_Connection=yes;'\n",
    "            )\n",
    "            # CREATE PYODBC CONNECTION\n",
    "            cnxn_ProdflowII = pyodbc.connect(conn_str)\n",
    "            # [2020-02-028]\\\\crsr_ProdflowII = cnxn_ProdflowII.cursor()\n",
    "            # PERFORM SQL QUERY AND SET AS DATAFRAME\n",
    "            df_ProdflowII_table = pd.read_sql_query(sql='SELECT * FROM ' + str(table_name),\n",
    "                                                    con=cnxn_ProdflowII\n",
    "                                                    )\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "            return df_ProdflowII_table\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "    \"\"\"\n",
    "    Referred to as \"Prodflow\" in SQL-Server\n",
    "    \"\"\"\n",
    "    def pull_ProdflowIII_table(self, table_name): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # CREATE CONNECTION STRING\n",
    "            conn_str = str(\n",
    "                r'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "                r'SERVER=wtkngappflow1.is.agilent.net;'\n",
    "                r'DATABASE=ProdFlow;'\n",
    "                r'Trusted_Connection=yes;'\n",
    "            )\n",
    "            # CREATE PYODBC CONNECTION\n",
    "            cnxn_ProdflowIII = pyodbc.connect(conn_str)\n",
    "            # [2020-02-28]\\\\crsr_ProdflowIII = cnxn_ProdflowIII,cursor()\n",
    "            # PERFORM SQL QUERY AND SET AS DATAFRAME\n",
    "            df_ProdflowIII_table = pd.read_sql_query(sql='SELECT * FROM ' + str(table_name),\n",
    "                                                     con=cnxn_ProdflowIII,\n",
    "                                                     parse_dates=['QCDate']\n",
    "                                                     )\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "            return df_ProdflowIII_table\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "    def create_metrics_table(self): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # pull PRODUCTS table\n",
    "            self.df_products = self.pull_ProdflowII_table(table_name='Products')\n",
    "            # RENAME ['Product#'] column to [\"ProductNo\"]\n",
    "            self.df_products.rename(columns={'Product#': 'ProductNo'}, inplace=True)\n",
    "            self.df_products.to_csv(os.path.join(self.outbound_dir, \"df-PRODUCTS-table-\" \n",
    "                                                + str(pd.Timestamp.now())[:10]\n",
    "                                                + \".csv\"), index=False)\n",
    "            print(\"\\tORDERS-TABLE:\\n\" + str(self.df_products.info()))\n",
    "            # pull tblProdflow TABLE\n",
    "            self.df_tblProdflow = self.pull_ProdflowIII_table(table_name='tblProdflow')\n",
    "            self.df_tblProdflow.to_csv(os.path.join(self.outbound_dir, \"df-tblProdflow-\"\n",
    "                                                    + str(pd.Timestamp.now())[:10] \n",
    "                                                    + \".csv\"), index=False)\n",
    "            print(self.df_tblProdflow.info())\n",
    "            ########################\n",
    "            # CREATE METRICS TABLE #\n",
    "            ########################\n",
    "            df_metrics_table = pd.merge(self.df_products, self.df_tblProdflow, on='ProductNo', how='right')\n",
    "            ######################\n",
    "            # CHANGE DATA TYPES: #\n",
    "            ######################\n",
    "            # CHANGE ['QCDate'] COLUMN TO DATETIME\n",
    "            df_metrics_table['QCDate'] = pd.to_datetime(df_metrics_table['QCDate'])\n",
    "            # SAME WITH OTHER COLUMNS\n",
    "            df_metrics_table['AmpDate'] = pd.to_datetime(df_metrics_table['AmpDate'])\n",
    "            df_metrics_table['OriginationDate'] = pd.to_datetime(df_metrics_table['OriginationDate'])\n",
    "            df_metrics_table['EntryDate'] = pd.to_datetime(df_metrics_table['EntryDate'])\n",
    "            # CHANGE ['ProductLevel'] COLUMN TO FLOAT\n",
    "            # [2020-03-11]\\\\df_metrics_table['ProductLevel'] = df_metrics_table['ProductLevel'].values.astype(float)\n",
    "            # [2020-03-11]\\\\df_metrics_table.ProductLevel = df_metrics_table.astype(float)\n",
    "            # [2020-03-11]\\\\df_metrics_table['ProductLevel'] = df_metrics_table['ProductLevel'].values.astype(int)\n",
    "            \"\"\"\n",
    "            # CHANGE 'ProductLevel' to CATEGORICAL\n",
    "            df_metrics_table['ProductLevel'] = pd.Categorical(df_metrics_table['ProductLevel'],\n",
    "                                                          categories=[1, 2, 3], ordered=False)\n",
    "            \"\"\"\n",
    "            #####################################################\n",
    "            # DROP ALL ROWS WITHOUT A 'QCDATE' & 'ProductLevel' #\n",
    "            #####################################################\n",
    "            df_metrics_table.dropna(axis=0, subset=['QCDate', 'ProductLevel'], \n",
    "                                    how='any', inplace=True)\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "            return df_metrics_table\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-24T20:22:56.719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/derbates\n",
      "C:/Users/derbates\\OneDrive - Agilent Technologies/Desktop\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "Operation Completed Successfully...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108554 entries, 0 to 108553\n",
      "Data columns (total 42 columns):\n",
      "ProductID          108554 non-null int64\n",
      "ProductNo          108554 non-null object\n",
      "ProductName        108526 non-null object\n",
      "LineID             108554 non-null int64\n",
      "Description        5976 non-null object\n",
      "Specials           2443 non-null object\n",
      "OriginationDate    108160 non-null datetime64[ns]\n",
      "EntryDate          108552 non-null datetime64[ns]\n",
      "Status             6036 non-null object\n",
      "MatrixNumber       107669 non-null object\n",
      "Components         108554 non-null int64\n",
      "Availability       4843 non-null object\n",
      "EquivalentSoln     103110 non-null object\n",
      "EquivalentNeat     103268 non-null object\n",
      "Packaging          107585 non-null object\n",
      "Storage            100905 non-null object\n",
      "ExpirationDate     108529 non-null float64\n",
      "ShipType           95298 non-null object\n",
      "UN#                93615 non-null object\n",
      "ShipClass          87522 non-null object\n",
      "PackGrp            87404 non-null object\n",
      "ShipSpecial        83179 non-null object\n",
      "Hazard1            2475 non-null object\n",
      "Hazard2            4258 non-null object\n",
      "Hazard3            124 non-null object\n",
      "Prop65             6140 non-null object\n",
      "MSDS               6138 non-null object\n",
      "Analysis           5696 non-null object\n",
      "CofAHeader         102370 non-null float64\n",
      "Agilent#           694 non-null object\n",
      "Tedia#             2330 non-null object\n",
      "ProdNotes          94042 non-null object\n",
      "MatrixNotes        9197 non-null object\n",
      "RecipeId           81196 non-null object\n",
      "RushPriority       108554 non-null bool\n",
      "IsVoided           93520 non-null object\n",
      "SagePartNumber     32234 non-null object\n",
      "ProductLevel       91506 non-null float64\n",
      "DateInserted       38 non-null datetime64[ns]\n",
      "CofATemplate       79518 non-null object\n",
      "UniqueRequestID    5 non-null object\n",
      "Test_Timestamp     108554 non-null object\n",
      "dtypes: bool(1), datetime64[ns](3), float64(3), int64(3), object(32)\n",
      "memory usage: 34.1+ MB\n",
      "\tORDERS-TABLE:\n",
      "None\n",
      "Operation Completed Successfully...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 109229 entries, 0 to 109228\n",
      "Data columns (total 53 columns):\n",
      "PfIDNo              109229 non-null int64\n",
      "PfBatchID           109229 non-null object\n",
      "ProductNo           109210 non-null object\n",
      "OrdID               93097 non-null float64\n",
      "QuoteNo             109193 non-null object\n",
      "PfSentTo            109164 non-null object\n",
      "PrepDate            108207 non-null datetime64[ns]\n",
      "PrepVolume          109183 non-null float64\n",
      "PrepUnit            109153 non-null object\n",
      "PrepVessel          109150 non-null float64\n",
      "PrepVBarcode        58542 non-null object\n",
      "PrdSaleUnit         89905 non-null object\n",
      "PrepMatrixNo        109154 non-null object\n",
      "PrepMatrixLot       108285 non-null object\n",
      "PrepInits           108043 non-null object\n",
      "PrepMemo            61697 non-null object\n",
      "PrepNotebookRef     48969 non-null object\n",
      "BulkQCStatus        24 non-null object\n",
      "BulkQCDate          75493 non-null datetime64[ns]\n",
      "BulkPassFail        74569 non-null object\n",
      "BulkQCInits         75477 non-null object\n",
      "BulkQCMemo          2152 non-null object\n",
      "BulkLotNo           73824 non-null object\n",
      "AmpRetains          52044 non-null float64\n",
      "AmpDate             93206 non-null datetime64[ns]\n",
      "AmpPreLabel         109229 non-null bool\n",
      "AmpNumberGood       93533 non-null float64\n",
      "AmpNumberBad        77822 non-null float64\n",
      "AmpBulkRemain       4413 non-null float64\n",
      "AmpTimeIn           92963 non-null datetime64[ns]\n",
      "AmpTimeOut          92963 non-null datetime64[ns]\n",
      "AmpInits            93171 non-null object\n",
      "QCStatus            573 non-null object\n",
      "QCDate              103685 non-null datetime64[ns]\n",
      "QCPassFail          103874 non-null object\n",
      "QCAuthInits         103673 non-null object\n",
      "QCMemo              55555 non-null object\n",
      "QCMethod            1206 non-null object\n",
      "LotNo               100966 non-null object\n",
      "QCExpMonth          93871 non-null float64\n",
      "QCExpDate           92289 non-null datetime64[ns]\n",
      "QCSellBy            0 non-null object\n",
      "QCFullValidation    109229 non-null bool\n",
      "QCValidation        109195 non-null float64\n",
      "FgInvCount          78400 non-null float64\n",
      "FgAccpacNote        19751 non-null object\n",
      "CofAHeaderNo        109197 non-null float64\n",
      "QCChromatogram      0 non-null object\n",
      "Correct             109229 non-null bool\n",
      "DoNotCorrect        109229 non-null bool\n",
      "DensityUnit         0 non-null object\n",
      "DensityTemp         0 non-null object\n",
      "recipeid            1 non-null object\n",
      "dtypes: bool(4), datetime64[ns](7), float64(11), int64(1), object(30)\n",
      "memory usage: 41.3+ MB\n",
      "None\n",
      "Operation Completed Successfully...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": # {\n",
    "    test_metrics = QC_Metrics_AvgTurnAround(the_logger=None)\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
