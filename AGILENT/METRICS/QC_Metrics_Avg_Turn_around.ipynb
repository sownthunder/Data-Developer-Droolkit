{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T19:57:32.042857Z",
     "start_time": "2020-03-12T19:57:29.032690Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import pyodbc\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.drawing.image import Image\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import tempfile\n",
    "from ttkthemes import ThemedStyle\n",
    "import tkinter as tk\n",
    "import tkinter.ttk as ttk\n",
    "from tkinter import messagebox, filedialog, commondialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T19:57:32.100859Z",
     "start_time": "2020-03-12T19:57:32.045835Z"
    }
   },
   "outputs": [],
   "source": [
    "class QC_Metrics_AvgTurnAround(): # {\n",
    "    \n",
    "    user_name = str(os.getlogin())\n",
    "    outbound_dir = \"C:/data/outbound/\" + str(pd.Timestamp.now())[:10]\n",
    "    desktop_dir = \"OneDrive - Agilent Technologies/Desktop\"\n",
    "    \n",
    "    def __init__(self, the_logger): # {\n",
    "        self.the_logger = the_logger\n",
    "        # Get/Set USERNAME & DESKTOP DIRECTORIES\n",
    "        self.user_name_dir = os.path.join(\"C:/Users/\", self.user_name)\n",
    "        self.desktop_dir = os.path.join(self.user_name_dir, self.desktop_dir)\n",
    "        print(self.user_name_dir)\n",
    "        print(self.desktop_dir)\n",
    "        self.run(day_range=30)\n",
    "    # }\n",
    "    \n",
    "    def run(self, day_range): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # [2020-02-28]\\\\self.time_unit = time_unit\n",
    "            # [2020-02-28]\\\\self.time_value = time_value\n",
    "            self.day_range = day_range\n",
    "            # get/set current date variable\n",
    "            # [2020-03-06]\\\\the_date = pd.Timestamp.now()\n",
    "            # [2020-03-11]\\\\the_date = pd.Timestamp(ts_input=str(self.end_date.get()))\n",
    "            the_date = pd.Timestamp.now()\n",
    "            # create variable for a month ago\n",
    "            one_month_ago = the_date - timedelta(days = int(day_range))\n",
    "            # [2020-02-28]\\\\\n",
    "            ##one_month_ago = the_date - pd.Timedelta(unit=str(self.time_unit), value=str(self.time_value))\n",
    "            print(type(one_month_ago))\n",
    "            # CREATE METRICS TABLE FROM CLASS METHOD\n",
    "            self.df_metrics_table = self.create_metrics_table()\n",
    "            #############################\n",
    "            # create .csv with no drops #\n",
    "            #############################\n",
    "            \"\"\"\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_metrics_noDrop.csv\"), \n",
    "                                         index=True)\n",
    "            # DROP ROWS WITH PRODUCT LEVEL && QCDATE = NONE\n",
    "            self.df_metrics_table.dropna(axis=0, subset=['QCDate', 'ProductLevel'], how='any', \n",
    "                                         inplace=True)\n",
    "            # create .csv with DROPS\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_metrics_DROP.csv\"), \n",
    "                                         index=True)\n",
    "            \"\"\"\n",
    "            # Set index of METRICS\n",
    "            # [2020-03-11]\\\\self.df_metrics_table.set_index(['QCDate', 'ProductLevel'], inplace=True)\n",
    "            \"\"\"\n",
    "            SET INDEX TO QCDAte\n",
    "            \"\"\"\n",
    "            # [2020-03-20]\\\\self.df_metrics_table.index = self.df_metrics_table['QCDate']\n",
    "            # [2020-03-20]\\\\del self.df_metrics_table['QCDate']\n",
    "            # [2020-03-11]\\\\del self.df_metrics_table['ProductLevel']\n",
    "            print(self.df_metrics_table)\n",
    "            # Display Index\n",
    "            print(self.df_metrics_table.index)\n",
    "            #############################\n",
    "            # create .csv with UNSORTED #\n",
    "            #############################\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_QC_metrics_UNSORTED.csv\"), \n",
    "                                         index=True)\n",
    "            # SORT INDEX\n",
    "            self.df_metrics_table.sort_index(inplace=True)\n",
    "            ###########################\n",
    "            # create .csv with SORTED #\n",
    "            ###########################\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_QC_metrics_SORTED.csv\"), \n",
    "                                         index=True)\n",
    "            print(\"SORTED:\\n\")\n",
    "            print(self.df_metrics_table.index)\n",
    "            # SLICE & DICE THE DATAFRAME\n",
    "            # [2020-03-11]\\\\self.df_level_1s = self.df_metrics_table.loc[('2017-01-02', 1.0)]\n",
    "            # [2020-03-11]\\\\print(self.df_metrics_table.loc[('2017-01-02', '1')])\n",
    "            print(\"<<<<< df_level_1s >>>>\\n\" + str(self.df_metrics_table.loc['2020-01-01':'2020-03-19'].describe()))\n",
    "            df_random_range = self.df_metrics_table.loc['2019-01-01':'2020-03-01']\n",
    "            df_random_range.to_csv(os.path.join(self.outbound_dir, 'df-random-range-'\n",
    "                                                + str(pd.Timestamp.now())[:10]\n",
    "                                                + \".csv\"), index=True)\n",
    "            \"\"\"\n",
    "            # GROUP THE DATA BY DAY, AND TAKE THE MEAN FOR EACH GROUP (i.e each day)\n",
    "            df_random_range_d_mean = df_random_range.resample('D').mean()\n",
    "            df_random_range_d_mean.to_csv(os.path.join(self.outbound_dir, \"df-random-range-d-mean-\" \n",
    "                                                      + str(pd.Timestamp.now())[:10]\n",
    "                                                      + \".csv\"), index=True)\n",
    "            # GROUP THE DATA BY DAY, AND TAKE THE SUM FOR EACH GROUP (i.e. each day)\n",
    "            df_random_range_d_sum = df_random_range.resample('D').sum()\n",
    "            df_random_range_d_mean.to_csv(os.path.join(self.outbound_dir, 'df-random-range-d-sum-'\n",
    "                                                      + str(pd.Timestamp.now())[:10]\n",
    "                                                      + \".csv\"), index=True)\n",
    "            \"\"\"\n",
    "            # CHECK OUT COLUMNS\n",
    "            # [2020-03-11]\\\\print(\"COLUMNS:\\n\" + str(self.df_level_1s.columns))\n",
    "            # [2020-03-11]\\\\print(self.df_level_1s)\n",
    "            \"\"\"\n",
    "            { PERFORM GROUPBY HERE }\n",
    "            { PERFORM GROUPBY HERE }\n",
    "            \"\"\"\n",
    "            # how many PfBatchID, ProductLevels, and Products, are they each month?\n",
    "            df_groupby_test_1 = df_random_range.groupby(['PfBatchID', 'ProductLevel'], as_index=False)['QCDate'].count()\n",
    "            df_groupby_test_1.to_csv(os.path.join(self.outbound_dir, 'df-groupby-test-1-'\n",
    "                                                 + str(pd.Timestamp.now())[:10]\n",
    "                                                 + \".csv\"), index=True)\n",
    "            df_groupby_test_2 = df_random_range.groupby('QCDate', as_index=True).agg({\"ProductLevel\":\"sum\"})\n",
    "            df_groupby_test_2.to_csv(os.path.join(self.outbound_dir, \"df-groupby-test-2-\"\n",
    "                                                + str(pd.Timestamp.now())[:10]\n",
    "                                                + \".csv\"), index=True)\n",
    "            # GROUP BY [\"ProductLevel\"]\n",
    "            df_by_product_level = df_random_range.groupby(['QCDate', 'ProductLevel'])['PfBatchID'].count()\n",
    "            # [2020-03-20]\\\\df_by_product_level = df_random_range.groupby('ProductLevel')\n",
    "            # PRINT GROUPS\n",
    "            print(df_by_product_level.groups)\n",
    "            # CHECK OUT THE TYPE OF OBJECT\n",
    "            print(\"TYPE == \" + str(type(df_by_product_level)))\n",
    "            # SUMARY STATS OVER THE LEVELS\n",
    "            print(df_by_product_level.describe().head())\n",
    "            # CAST GROUPING as a LIST AND CHECK OUT ONE LEVEL\n",
    "            print(\"level-listing #1 :\\n\" + str(list(df_by_product_level)[1]))\n",
    "            level_1 = pd.DataFrame(data=list(df_by_product_level)[1]) # , dtype=np.str, index=['QCDate'])\n",
    "            level_2 = pd.DataFrame(data=list(df_by_product_level)[2]) #, dtype=np.str, index=['QCDate'])\n",
    "            level_3 = pd.DataFrame(data=list(df_by_product_level)[3]) #, dtype=np.str, index=['QCDate'])\n",
    "            # EXPORT ??\n",
    "            level_1.to_csv(os.path.join(self.outbound_dir, 'df-level-1-'\n",
    "                                        + str(pd.Timestamp.now())[:10]\n",
    "                                        + \".csv\"), index=True)\n",
    "            level_2.to_csv(os.path.join(self.outbound_dir, 'df-level-2-'\n",
    "                                        + str(pd.Timestamp.now())[:10]\n",
    "                                        + \".csv\"), index=True)\n",
    "            level_3.to_csv(os.path.join(self.outbound_dir, 'df-level-3-'\n",
    "                                        + str(pd.Timestamp.now())[:10]\n",
    "                                        + \".csv\"), index=True)\n",
    "            \"\"\"\n",
    "            # GET MEDIAN VALUES BY PRODUCT LEVEL AND PRINT FIRST 5 ROWS\n",
    "            df_med_by_product_level = df_by_product_level.median()\n",
    "            df_med_by_product_level.head()\n",
    "            # Slice out PfBatchID and plot?\n",
    "            df_id_by_p_level = df_med_by_product_level['PfBatchID']\n",
    "            df_id_by_p_level.to_csv(os.path.join(self.outbound_dir, 'df-id-by-p-level-'\n",
    "                                                 + str(pd.Timestamp.now())[:10]\n",
    "                                                 + '.csv'), index=False)\n",
    "            \"\"\"\n",
    "            # AGGREGATE INTO DAYS BY SUMMING UP VALUES OF EACH HOURLY OBSERVATION\n",
    "            df_by_product_level.resample('D').sum().to_csv(os.path.join(self.outbound_dir, 'df-product-level-samples-'\n",
    "                                                                        + str(pd.Timestamp.now())[:10]\n",
    "                                                                        + \".csv\"), index=True)\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "    \"\"\"\n",
    "    Referred to as \"ProdflowII\" in SQL-Server\n",
    "    \"\"\"\n",
    "    def pull_ProdflowII_table(self, table_name): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # CREATION CONNECTION STR\n",
    "            conn_str = str(\n",
    "                r'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "                r'SERVER=wtkngappflow1.is.agilent.net;'\n",
    "                r'DATABASE=ProdFlowII_Prod;'\n",
    "                r'Trusted_Connection=yes;'\n",
    "            )\n",
    "            # CREATE PYODBC CONNECTION\n",
    "            cnxn_ProdflowII = pyodbc.connect(conn_str)\n",
    "            # [2020-02-028]\\\\crsr_ProdflowII = cnxn_ProdflowII.cursor()\n",
    "            # PERFORM SQL QUERY AND SET AS DATAFRAME\n",
    "            df_ProdflowII_table = pd.read_sql_query(sql='SELECT * FROM ' + str(table_name),\n",
    "                                                    con=cnxn_ProdflowII\n",
    "                                                    )\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "            return df_ProdflowII_table\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "    \"\"\"\n",
    "    Referred to as \"Prodflow\" in SQL-Server\n",
    "    \"\"\"\n",
    "    def pull_ProdflowIII_table(self, table_name): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # CREATE CONNECTION STRING\n",
    "            conn_str = str(\n",
    "                r'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "                r'SERVER=wtkngappflow1.is.agilent.net;'\n",
    "                r'DATABASE=ProdFlow;'\n",
    "                r'Trusted_Connection=yes;'\n",
    "            )\n",
    "            # CREATE PYODBC CONNECTION\n",
    "            cnxn_ProdflowIII = pyodbc.connect(conn_str)\n",
    "            # [2020-02-28]\\\\crsr_ProdflowIII = cnxn_ProdflowIII,cursor()\n",
    "            # PERFORM SQL QUERY AND SET AS DATAFRAME\n",
    "            df_ProdflowIII_table = pd.read_sql_query(sql='SELECT * FROM ' + str(table_name),\n",
    "                                                     con=cnxn_ProdflowIII,\n",
    "                                                     parse_dates=['QCDate']\n",
    "                                                     )\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "            return df_ProdflowIII_table\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "    def create_metrics_table(self): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # pull PRODUCTS table\n",
    "            self.df_products = self.pull_ProdflowII_table(table_name='Products')\n",
    "            # RENAME ['Product#'] column to [\"ProductNo\"]\n",
    "            self.df_products.rename(columns={'Product#': 'ProductNo'}, inplace=True)\n",
    "            self.df_products.to_csv(os.path.join(self.outbound_dir, \"df-PRODUCTS-table-\" \n",
    "                                                + str(pd.Timestamp.now())[:10]\n",
    "                                                + \".csv\"), index=False)\n",
    "            print(\"\\tORDERS-TABLE:\\n\" + str(self.df_products.info()))\n",
    "            # pull tblProdflow TABLE\n",
    "            self.df_tblProdflow = self.pull_ProdflowIII_table(table_name='tblProdflow')\n",
    "            self.df_tblProdflow.to_csv(os.path.join(self.outbound_dir, \"df-tblProdflow-\"\n",
    "                                                    + str(pd.Timestamp.now())[:10] \n",
    "                                                    + \".csv\"), index=False)\n",
    "            print(self.df_tblProdflow.info())\n",
    "            ########################\n",
    "            # CREATE METRICS TABLE #\n",
    "            ########################\n",
    "            df_metrics_table = pd.merge(self.df_products, self.df_tblProdflow, on='ProductNo', how='right')\n",
    "            ######################\n",
    "            # CHANGE DATA TYPES: #\n",
    "            ######################\n",
    "            # CHANGE ['QCDate'] COLUMN TO DATETIME\n",
    "            df_metrics_table['QCDate'] = pd.to_datetime(df_metrics_table['QCDate'])\n",
    "            # CHANGE ['ProductLevel'] COLUMN TO FLOAT\n",
    "            # [2020-03-11]\\\\df_metrics_table['ProductLevel'] = df_metrics_table['ProductLevel'].values.astype(float)\n",
    "            # [2020-03-11]\\\\df_metrics_table.ProductLevel = df_metrics_table.astype(float)\n",
    "            # [2020-03-11]\\\\df_metrics_table['ProductLevel'] = df_metrics_table['ProductLevel'].values.astype(int)\n",
    "            \"\"\"\n",
    "            # CHANGE 'ProductLevel' to CATEGORICAL\n",
    "            df_metrics_table['ProductLevel'] = pd.Categorical(df_metrics_table['ProductLevel'],\n",
    "                                                          categories=[1, 2, 3], ordered=False)\n",
    "            \"\"\"\n",
    "            #####################################################\n",
    "            # DROP ALL ROWS WITHOUT A 'QCDATE' & 'ProductLevel' #\n",
    "            #####################################################\n",
    "            df_metrics_table.dropna(axis=0, subset=['QCDate', 'ProductLevel'], \n",
    "                                    how='any', inplace=True)\n",
    "            df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df-QC-metrics-table-\"\n",
    "                                                 + str(pd.Timestamp.now())[:10]\n",
    "                                                 + \".csv\"), index=True)\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "            return df_metrics_table\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T19:57:57.490544Z",
     "start_time": "2020-03-12T19:57:32.102831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/derbates\n",
      "C:/Users/derbates\\OneDrive - Agilent Technologies/Desktop\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "Operation Completed Successfully...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108535 entries, 0 to 108534\n",
      "Data columns (total 42 columns):\n",
      "ProductID          108535 non-null int64\n",
      "ProductNo          108535 non-null object\n",
      "ProductName        108507 non-null object\n",
      "LineID             108535 non-null int64\n",
      "Description        5976 non-null object\n",
      "Specials           2443 non-null object\n",
      "OriginationDate    108141 non-null datetime64[ns]\n",
      "EntryDate          108533 non-null datetime64[ns]\n",
      "Status             6036 non-null object\n",
      "MatrixNumber       107650 non-null object\n",
      "Components         108535 non-null int64\n",
      "Availability       4843 non-null object\n",
      "EquivalentSoln     103091 non-null object\n",
      "EquivalentNeat     103249 non-null object\n",
      "Packaging          107581 non-null object\n",
      "Storage            100889 non-null object\n",
      "ExpirationDate     108510 non-null float64\n",
      "ShipType           95284 non-null object\n",
      "UN#                93601 non-null object\n",
      "ShipClass          87508 non-null object\n",
      "PackGrp            87390 non-null object\n",
      "ShipSpecial        83163 non-null object\n",
      "Hazard1            2475 non-null object\n",
      "Hazard2            4258 non-null object\n",
      "Hazard3            124 non-null object\n",
      "Prop65             6140 non-null object\n",
      "MSDS               6138 non-null object\n",
      "Analysis           5696 non-null object\n",
      "CofAHeader         102351 non-null float64\n",
      "Agilent#           694 non-null object\n",
      "Tedia#             2330 non-null object\n",
      "ProdNotes          94004 non-null object\n",
      "MatrixNotes        9197 non-null object\n",
      "RecipeId           81196 non-null object\n",
      "RushPriority       108535 non-null bool\n",
      "IsVoided           93495 non-null object\n",
      "SagePartNumber     32234 non-null object\n",
      "ProductLevel       91487 non-null float64\n",
      "DateInserted       38 non-null datetime64[ns]\n",
      "CofATemplate       79518 non-null object\n",
      "UniqueRequestID    5 non-null object\n",
      "Test_Timestamp     108535 non-null object\n",
      "dtypes: bool(1), datetime64[ns](3), float64(3), int64(3), object(32)\n",
      "memory usage: 34.1+ MB\n",
      "\tORDERS-TABLE:\n",
      "None\n",
      "Operation Completed Successfully...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 109147 entries, 0 to 109146\n",
      "Data columns (total 53 columns):\n",
      "PfIDNo              109147 non-null int64\n",
      "PfBatchID           109147 non-null object\n",
      "ProductNo           109128 non-null object\n",
      "OrdID               93015 non-null float64\n",
      "QuoteNo             109111 non-null object\n",
      "PfSentTo            109082 non-null object\n",
      "PrepDate            108127 non-null datetime64[ns]\n",
      "PrepVolume          109102 non-null float64\n",
      "PrepUnit            109071 non-null object\n",
      "PrepVessel          109068 non-null float64\n",
      "PrepVBarcode        58459 non-null object\n",
      "PrdSaleUnit         89843 non-null object\n",
      "PrepMatrixNo        109072 non-null object\n",
      "PrepMatrixLot       108203 non-null object\n",
      "PrepInits           107961 non-null object\n",
      "PrepMemo            61642 non-null object\n",
      "PrepNotebookRef     48969 non-null object\n",
      "BulkQCStatus        24 non-null object\n",
      "BulkQCDate          75440 non-null datetime64[ns]\n",
      "BulkPassFail        74516 non-null object\n",
      "BulkQCInits         75424 non-null object\n",
      "BulkQCMemo          2150 non-null object\n",
      "BulkLotNo           73771 non-null object\n",
      "AmpRetains          52023 non-null float64\n",
      "AmpDate             93157 non-null datetime64[ns]\n",
      "AmpPreLabel         109147 non-null bool\n",
      "AmpNumberGood       93485 non-null float64\n",
      "AmpNumberBad        77782 non-null float64\n",
      "AmpBulkRemain       4376 non-null float64\n",
      "AmpTimeIn           92915 non-null datetime64[ns]\n",
      "AmpTimeOut          92915 non-null datetime64[ns]\n",
      "AmpInits            93123 non-null object\n",
      "QCStatus            573 non-null object\n",
      "QCDate              103624 non-null datetime64[ns]\n",
      "QCPassFail          103812 non-null object\n",
      "QCAuthInits         103611 non-null object\n",
      "QCMemo              55537 non-null object\n",
      "QCMethod            1205 non-null object\n",
      "LotNo               100906 non-null object\n",
      "QCExpMonth          93789 non-null float64\n",
      "QCExpDate           92231 non-null datetime64[ns]\n",
      "QCSellBy            0 non-null object\n",
      "QCFullValidation    109147 non-null bool\n",
      "QCValidation        109113 non-null float64\n",
      "FgInvCount          78352 non-null float64\n",
      "FgAccpacNote        19730 non-null object\n",
      "CofAHeaderNo        109115 non-null float64\n",
      "QCChromatogram      0 non-null object\n",
      "Correct             109147 non-null bool\n",
      "DoNotCorrect        109147 non-null bool\n",
      "DensityUnit         0 non-null object\n",
      "DensityTemp         0 non-null object\n",
      "recipeid            1 non-null object\n",
      "dtypes: bool(4), datetime64[ns](7), float64(11), int64(1), object(30)\n",
      "memory usage: 41.2+ MB\n",
      "None\n",
      "Operation Completed Successfully...\n",
      "        ProductID      ProductNo               ProductName  LineID  \\\n",
      "5          5420.0    01080-68703           Gradient Sample     7.0   \n",
      "6          5420.0    01080-68703           Gradient Sample     7.0   \n",
      "7          5420.0    01080-68703           Gradient Sample     7.0   \n",
      "8          5420.0    01080-68703           Gradient Sample     7.0   \n",
      "9          5420.0    01080-68703           Gradient Sample     7.0   \n",
      "...           ...            ...                       ...     ...   \n",
      "104249    50108.0  ZX-TESTMIX-01  GC x GC Testing Solution     7.0   \n",
      "104250    50108.0  ZX-TESTMIX-01  GC x GC Testing Solution     7.0   \n",
      "104253    50108.0  ZX-TESTMIX-01  GC x GC Testing Solution     7.0   \n",
      "104254    50108.0  ZX-TESTMIX-01  GC x GC Testing Solution     7.0   \n",
      "104255    50108.0  ZX-TESTMIX-01  GC x GC Testing Solution     7.0   \n",
      "\n",
      "       Description     Specials OriginationDate  EntryDate Status  \\\n",
      "5             None  01080-68703      1998-02-04 2011-05-09    oem   \n",
      "6             None  01080-68703      1998-02-04 2011-05-09    oem   \n",
      "7             None  01080-68703      1998-02-04 2011-05-09    oem   \n",
      "8             None  01080-68703      1998-02-04 2011-05-09    oem   \n",
      "9             None  01080-68703      1998-02-04 2011-05-09    oem   \n",
      "...            ...          ...             ...        ...    ...   \n",
      "104249        None         None      2011-04-19 2011-05-09   None   \n",
      "104250        None         None      2011-04-19 2011-05-09   None   \n",
      "104253        None         None      2011-04-19 2011-05-09   None   \n",
      "104254        None         None      2011-04-19 2011-05-09   None   \n",
      "104255        None         None      2011-04-19 2011-05-09   None   \n",
      "\n",
      "       MatrixNumber  ...  QCValidation FgInvCount  \\\n",
      "5           JHP-021  ...           2.0     2600.0   \n",
      "6           JHP-021  ...           2.0     2123.0   \n",
      "7           JHP-021  ...           2.0     3400.0   \n",
      "8           JHP-021  ...           2.0     1563.0   \n",
      "9           JHP-021  ...           2.0     1156.0   \n",
      "...             ...  ...           ...        ...   \n",
      "104249      JHP-031  ...           2.0      129.0   \n",
      "104250      JHP-031  ...           2.0      602.0   \n",
      "104253      JHP-031  ...           2.0      366.0   \n",
      "104254      JHP-031  ...           2.0      320.0   \n",
      "104255      JHP-031  ...           2.0      320.0   \n",
      "\n",
      "                                  FgAccpacNote CofAHeaderNo QCChromatogram  \\\n",
      "5                                         None          2.0           None   \n",
      "6                                         None          2.0           None   \n",
      "7                                         None          2.0           None   \n",
      "8                                      back up          2.0           None   \n",
      "9            zero out ce-3778 (1390) stability          2.0           None   \n",
      "...                                        ...          ...            ...   \n",
      "104249                                    None          2.0           None   \n",
      "104250                                    None          2.0           None   \n",
      "104253                                    None          2.0           None   \n",
      "104254                                    None          2.0           None   \n",
      "104255  purge cs-0774 (70) cp-1554a (5) retain          2.0           None   \n",
      "\n",
      "       Correct  DoNotCorrect DensityUnit DensityTemp recipeid  \n",
      "5        False         False        None        None     None  \n",
      "6        False         False        None        None     None  \n",
      "7        False          True        None        None     None  \n",
      "8        False          True        None        None     None  \n",
      "9        False          True        None        None     None  \n",
      "...        ...           ...         ...         ...      ...  \n",
      "104249   False          True        None        None     None  \n",
      "104250   False         False        None        None     None  \n",
      "104253   False         False        None        None     None  \n",
      "104254   False         False        None        None     None  \n",
      "104255   False         False        None        None     None  \n",
      "\n",
      "[85104 rows x 94 columns]\n",
      "Int64Index([     5,      6,      7,      8,      9,     10,     11,     12,\n",
      "                13,     14,\n",
      "            ...\n",
      "            104244, 104245, 104246, 104247, 104248, 104249, 104250, 104253,\n",
      "            104254, 104255],\n",
      "           dtype='int64', length=85104)\n",
      "SORTED:\n",
      "\n",
      "Int64Index([     5,      6,      7,      8,      9,     10,     11,     12,\n",
      "                13,     14,\n",
      "            ...\n",
      "            104244, 104245, 104246, 104247, 104248, 104249, 104250, 104253,\n",
      "            104254, 104255],\n",
      "           dtype='int64', length=85104)\n",
      "<<<<< df_level_1s >>>>\n",
      "       ProductID  LineID  Components  ExpirationDate  CofAHeader  \\\n",
      "count        0.0     0.0         0.0             0.0         0.0   \n",
      "mean         NaN     NaN         NaN             NaN         NaN   \n",
      "std          NaN     NaN         NaN             NaN         NaN   \n",
      "min          NaN     NaN         NaN             NaN         NaN   \n",
      "25%          NaN     NaN         NaN             NaN         NaN   \n",
      "50%          NaN     NaN         NaN             NaN         NaN   \n",
      "75%          NaN     NaN         NaN             NaN         NaN   \n",
      "max          NaN     NaN         NaN             NaN         NaN   \n",
      "\n",
      "       ProductLevel  PfIDNo  OrdID  PrepVolume  PrepVessel  AmpRetains  \\\n",
      "count           0.0     0.0    0.0         0.0         0.0         0.0   \n",
      "mean            NaN     NaN    NaN         NaN         NaN         NaN   \n",
      "std             NaN     NaN    NaN         NaN         NaN         NaN   \n",
      "min             NaN     NaN    NaN         NaN         NaN         NaN   \n",
      "25%             NaN     NaN    NaN         NaN         NaN         NaN   \n",
      "50%             NaN     NaN    NaN         NaN         NaN         NaN   \n",
      "75%             NaN     NaN    NaN         NaN         NaN         NaN   \n",
      "max             NaN     NaN    NaN         NaN         NaN         NaN   \n",
      "\n",
      "       AmpNumberGood  AmpNumberBad  AmpBulkRemain  QCExpMonth  QCValidation  \\\n",
      "count            0.0           0.0            0.0         0.0           0.0   \n",
      "mean             NaN           NaN            NaN         NaN           NaN   \n",
      "std              NaN           NaN            NaN         NaN           NaN   \n",
      "min              NaN           NaN            NaN         NaN           NaN   \n",
      "25%              NaN           NaN            NaN         NaN           NaN   \n",
      "50%              NaN           NaN            NaN         NaN           NaN   \n",
      "75%              NaN           NaN            NaN         NaN           NaN   \n",
      "max              NaN           NaN            NaN         NaN           NaN   \n",
      "\n",
      "       FgInvCount  CofAHeaderNo  \n",
      "count         0.0           0.0  \n",
      "mean          NaN           NaN  \n",
      "std           NaN           NaN  \n",
      "min           NaN           NaN  \n",
      "25%           NaN           NaN  \n",
      "50%           NaN           NaN  \n",
      "75%           NaN           NaN  \n",
      "max           NaN           NaN  \n",
      "\n",
      "TYPE : <class 'AttributeError'>\n",
      "FILE : <ipython-input-2-8af10cd0dd61>\n",
      "LINE : 112\n",
      "MESG : \n",
      "\n",
      "<class 'AttributeError'>\n",
      "'Series' object has no attribute 'groups'\n",
      "\t\t<traceback object at 0x000002AE5E8368C8>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": # {\n",
    "    test_metrics = QC_Metrics_AvgTurnAround(the_logger=None)\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
