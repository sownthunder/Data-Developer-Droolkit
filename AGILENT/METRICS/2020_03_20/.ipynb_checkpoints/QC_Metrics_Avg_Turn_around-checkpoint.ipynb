{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T19:57:32.042857Z",
     "start_time": "2020-03-12T19:57:29.032690Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import pyodbc\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.drawing.image import Image\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import tempfile\n",
    "from ttkthemes import ThemedStyle\n",
    "import tkinter as tk\n",
    "import tkinter.ttk as ttk\n",
    "from tkinter import messagebox, filedialog, commondialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T19:57:32.100859Z",
     "start_time": "2020-03-12T19:57:32.045835Z"
    }
   },
   "outputs": [],
   "source": [
    "class QC_Metrics_AvgTurnAround(): # {\n",
    "    \n",
    "    user_name = str(os.getlogin())\n",
    "    outbound_dir = \"C:/data/outbound/\" + str(pd.Timestamp.now())[:10]\n",
    "    desktop_dir = \"OneDrive - Agilent Technologies/Desktop\"\n",
    "    \n",
    "    def __init__(self, the_logger): # {\n",
    "        self.the_logger = the_logger\n",
    "        # Get/Set USERNAME & DESKTOP DIRECTORIES\n",
    "        self.user_name_dir = os.path.join(\"C:/Users/\", self.user_name)\n",
    "        self.desktop_dir = os.path.join(self.user_name_dir, self.desktop_dir)\n",
    "        print(self.user_name_dir)\n",
    "        print(self.desktop_dir)\n",
    "        self.run(day_range=30)\n",
    "    # }\n",
    "    \n",
    "    def run(self, day_range): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # [2020-02-28]\\\\self.time_unit = time_unit\n",
    "            # [2020-02-28]\\\\self.time_value = time_value\n",
    "            self.day_range = day_range\n",
    "            # get/set current date variable\n",
    "            # [2020-03-06]\\\\the_date = pd.Timestamp.now()\n",
    "            # [2020-03-11]\\\\the_date = pd.Timestamp(ts_input=str(self.end_date.get()))\n",
    "            the_date = pd.Timestamp.now()\n",
    "            # create variable for a month ago\n",
    "            one_month_ago = the_date - timedelta(days = int(day_range))\n",
    "            # [2020-02-28]\\\\\n",
    "            ##one_month_ago = the_date - pd.Timedelta(unit=str(self.time_unit), value=str(self.time_value))\n",
    "            print(type(one_month_ago))\n",
    "            # CREATE METRICS TABLE FROM CLASS METHOD\n",
    "            self.df_metrics_table = self.create_metrics_table()\n",
    "            #############################\n",
    "            # create .csv with no drops #\n",
    "            #############################\n",
    "            \"\"\"\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_metrics_noDrop.csv\"), \n",
    "                                         index=True)\n",
    "            # DROP ROWS WITH PRODUCT LEVEL && QCDATE = NONE\n",
    "            self.df_metrics_table.dropna(axis=0, subset=['QCDate', 'ProductLevel'], how='any', \n",
    "                                         inplace=True)\n",
    "            # create .csv with DROPS\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_metrics_DROP.csv\"), \n",
    "                                         index=True)\n",
    "            \"\"\"\n",
    "            # Set index of METRICS\n",
    "            # [2020-03-11]\\\\self.df_metrics_table.set_index(['QCDate', 'ProductLevel'], inplace=True)\n",
    "            \"\"\"\n",
    "            self.df_metrics_table.index = self.df_metrics_table['QCDate']\n",
    "            del self.df_metrics_table['QCDate']\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            # [2020-03-11]\\\\del self.df_metrics_table['ProductLevel']\n",
    "            print(self.df_metrics_table)\n",
    "            # Display Index\n",
    "            print(self.df_metrics_table.index)\n",
    "            #############################\n",
    "            # create .csv with UNSORTED #\n",
    "            #############################\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_QC_metrics_UNSORTED.csv\"), \n",
    "                                         index=True)\n",
    "            # SORT INDEX\n",
    "            self.df_metrics_table.sort_index(inplace=True)\n",
    "            ###########################\n",
    "            # create .csv with SORTED #\n",
    "            ###########################\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_QC_metrics_SORTED.csv\"), \n",
    "                                         index=True)\n",
    "            print(\"SORTED:\\n\")\n",
    "            print(self.df_metrics_table.index)\n",
    "            \"\"\"\n",
    "            # SLICE & DICE THE DATAFRAME\n",
    "            # [2020-03-11]\\\\self.df_level_1s = self.df_metrics_table.loc[('2017-01-02', 1.0)]\n",
    "            # [2020-03-11]\\\\print(self.df_metrics_table.loc[('2017-01-02', '1')])\n",
    "            print(\"<<<<< df_level_1s >>>>\\n\" + str(self.df_metrics_table.loc['2017-01-02':'2020-01-01'].describe()))\n",
    "            df_random_range = self.df_metrics_table.loc['2019-01-01':'2020-03-01']\n",
    "            # GROUP THE DATA BY DAY, AND TAKE THE MEAN FOR EACH GROUP (i.e each day)\n",
    "            df_random_range_d_mean = df_random_range.resample('D').mean()\n",
    "            df_random_range_d_mean.to_csv(os.path.join(self.outbound_dir, \"df-random-range-d-mean-\" \n",
    "                                                      + str(pd.Timestamp.now())[:10]\n",
    "                                                      + \".csv\"), index=False)\n",
    "            # GROUP THE DATA BY DAY, AND TAKE THE SUM FOR EACH GROUP (i.e. each day)\n",
    "            df_random_range_d_sum = df_random_range.resample('D').sum()\n",
    "            df_random_range_d_mean.to_csv(os.path.join(self.outbound_dir, 'df-random-range-d-sum-'\n",
    "                                                      + str(pd.Timestamp.now())[:10]\n",
    "                                                      + \".csv\"), index=False)\n",
    "            # CHECK OUT COLUMNS\n",
    "            # [2020-03-11]\\\\print(\"COLUMNS:\\n\" + str(self.df_level_1s.columns))\n",
    "            # [2020-03-11]\\\\print(self.df_level_1s)\n",
    "            \"\"\"\n",
    "            { PERFORM GROUPBY HERE }\n",
    "            { PERFORM GROUPBY HERE }\n",
    "            \"\"\"\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "    \"\"\"\n",
    "    Referred to as \"ProdflowII\" in SQL-Server\n",
    "    \"\"\"\n",
    "    def pull_ProdflowII_table(self, table_name): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # CREATION CONNECTION STR\n",
    "            conn_str = str(\n",
    "                r'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "                r'SERVER=wtkngappflow1.is.agilent.net;'\n",
    "                r'DATABASE=ProdFlowII_Prod;'\n",
    "                r'Trusted_Connection=yes;'\n",
    "            )\n",
    "            # CREATE PYODBC CONNECTION\n",
    "            cnxn_ProdflowII = pyodbc.connect(conn_str)\n",
    "            # [2020-02-028]\\\\crsr_ProdflowII = cnxn_ProdflowII.cursor()\n",
    "            # PERFORM SQL QUERY AND SET AS DATAFRAME\n",
    "            df_ProdflowII_table = pd.read_sql_query(sql='SELECT * FROM ' + str(table_name),\n",
    "                                                    con=cnxn_ProdflowII\n",
    "                                                    )\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "            return df_ProdflowII_table\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "    \"\"\"\n",
    "    Referred to as \"Prodflow\" in SQL-Server\n",
    "    \"\"\"\n",
    "    def pull_ProdflowIII_table(self, table_name): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # CREATE CONNECTION STRING\n",
    "            conn_str = str(\n",
    "                r'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "                r'SERVER=wtkngappflow1.is.agilent.net;'\n",
    "                r'DATABASE=ProdFlow;'\n",
    "                r'Trusted_Connection=yes;'\n",
    "            )\n",
    "            # CREATE PYODBC CONNECTION\n",
    "            cnxn_ProdflowIII = pyodbc.connect(conn_str)\n",
    "            # [2020-02-28]\\\\crsr_ProdflowIII = cnxn_ProdflowIII,cursor()\n",
    "            # PERFORM SQL QUERY AND SET AS DATAFRAME\n",
    "            df_ProdflowIII_table = pd.read_sql_query(sql='SELECT * FROM ' + str(table_name),\n",
    "                                                     con=cnxn_ProdflowIII,\n",
    "                                                     parse_dates=['QCDate']\n",
    "                                                     )\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "            return df_ProdflowIII_table\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "    def create_metrics_table(self): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # pull PRODUCTS table\n",
    "            self.df_products = self.pull_ProdflowII_table(table_name='Products')\n",
    "            # RENAME ['Product#'] column to [\"ProductNo\"]\n",
    "            self.df_products.rename(columns={'Product#': 'ProductNo'}, inplace=True)\n",
    "            self.df_products.to_csv(os.path.join(self.outbound_dir, \"df-PRODUCTS-table-\" \n",
    "                                                + str(pd.Timestamp.now())[:10]\n",
    "                                                + \".csv\"), index=False)\n",
    "            print(\"\\tORDERS-TABLE:\\n\" + str(self.df_products.info()))\n",
    "            # pull tblProdflow TABLE\n",
    "            self.df_tblProdflow = self.pull_ProdflowIII_table(table_name='tblProdflow')\n",
    "            self.df_tblProdflow.to_csv(os.path.join(self.outbound_dir, \"df-tblProdflow-\"\n",
    "                                                    + str(pd.Timestamp.now())[:10] \n",
    "                                                    + \".csv\"), index=False)\n",
    "            print(self.df_tblProdflow.info())\n",
    "            ########################\n",
    "            # CREATE METRICS TABLE #\n",
    "            ########################\n",
    "            df_metrics_table = pd.merge(self.df_products, self.df_tblProdflow, on='ProductNo', how='right')\n",
    "            ######################\n",
    "            # CHANGE DATA TYPES: #\n",
    "            ######################\n",
    "            # CHANGE ['QCDate'] COLUMN TO DATETIME\n",
    "            df_metrics_table['QCDate'] = pd.to_datetime(df_metrics_table['QCDate'])\n",
    "            # CHANGE ['ProductLevel'] COLUMN TO FLOAT\n",
    "            # [2020-03-11]\\\\df_metrics_table['ProductLevel'] = df_metrics_table['ProductLevel'].values.astype(float)\n",
    "            # [2020-03-11]\\\\df_metrics_table.ProductLevel = df_metrics_table.astype(float)\n",
    "            # [2020-03-11]\\\\df_metrics_table['ProductLevel'] = df_metrics_table['ProductLevel'].values.astype(int)\n",
    "            \"\"\"\n",
    "            # CHANGE 'ProductLevel' to CATEGORICAL\n",
    "            df_metrics_table['ProductLevel'] = pd.Categorical(df_metrics_table['ProductLevel'],\n",
    "                                                          categories=[1, 2, 3], ordered=False)\n",
    "            \"\"\"\n",
    "            #####################################################\n",
    "            # DROP ALL ROWS WITHOUT A 'QCDATE' & 'ProductLevel' #\n",
    "            #####################################################\n",
    "            df_metrics_table.dropna(axis=0, subset=['QCDate', 'ProductLevel'], \n",
    "                                    how='any', inplace=True)\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "            return df_metrics_table\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T19:57:57.490544Z",
     "start_time": "2020-03-12T19:57:32.102831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/derbates\n",
      "C:/Users/derbates\\OneDrive - Agilent Technologies/Desktop\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "Operation Completed Successfully...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108529 entries, 0 to 108528\n",
      "Data columns (total 42 columns):\n",
      "ProductID          108529 non-null int64\n",
      "ProductNo          108529 non-null object\n",
      "ProductName        108501 non-null object\n",
      "LineID             108529 non-null int64\n",
      "Description        5976 non-null object\n",
      "Specials           2443 non-null object\n",
      "OriginationDate    108135 non-null datetime64[ns]\n",
      "EntryDate          108527 non-null datetime64[ns]\n",
      "Status             6036 non-null object\n",
      "MatrixNumber       107644 non-null object\n",
      "Components         108529 non-null int64\n",
      "Availability       4843 non-null object\n",
      "EquivalentSoln     103085 non-null object\n",
      "EquivalentNeat     103243 non-null object\n",
      "Packaging          107577 non-null object\n",
      "Storage            100876 non-null object\n",
      "ExpirationDate     108504 non-null float64\n",
      "ShipType           95271 non-null object\n",
      "UN#                93588 non-null object\n",
      "ShipClass          87495 non-null object\n",
      "PackGrp            87377 non-null object\n",
      "ShipSpecial        83150 non-null object\n",
      "Hazard1            2475 non-null object\n",
      "Hazard2            4258 non-null object\n",
      "Hazard3            124 non-null object\n",
      "Prop65             6140 non-null object\n",
      "MSDS               6138 non-null object\n",
      "Analysis           5696 non-null object\n",
      "CofAHeader         102345 non-null float64\n",
      "Agilent#           694 non-null object\n",
      "Tedia#             2330 non-null object\n",
      "ProdNotes          94002 non-null object\n",
      "MatrixNotes        9197 non-null object\n",
      "RecipeId           81196 non-null object\n",
      "RushPriority       108529 non-null bool\n",
      "IsVoided           93487 non-null object\n",
      "SagePartNumber     32234 non-null object\n",
      "ProductLevel       91481 non-null float64\n",
      "DateInserted       38 non-null datetime64[ns]\n",
      "CofATemplate       79518 non-null object\n",
      "UniqueRequestID    5 non-null object\n",
      "Test_Timestamp     108529 non-null object\n",
      "dtypes: bool(1), datetime64[ns](3), float64(3), int64(3), object(32)\n",
      "memory usage: 34.1+ MB\n",
      "\tORDERS-TABLE:\n",
      "None\n",
      "Operation Completed Successfully...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 109126 entries, 0 to 109125\n",
      "Data columns (total 53 columns):\n",
      "PfIDNo              109126 non-null int64\n",
      "PfBatchID           109126 non-null object\n",
      "ProductNo           109107 non-null object\n",
      "OrdID               92994 non-null float64\n",
      "QuoteNo             109090 non-null object\n",
      "PfSentTo            109061 non-null object\n",
      "PrepDate            108106 non-null datetime64[ns]\n",
      "PrepVolume          109081 non-null float64\n",
      "PrepUnit            109050 non-null object\n",
      "PrepVessel          109047 non-null float64\n",
      "PrepVBarcode        58437 non-null object\n",
      "PrdSaleUnit         89823 non-null object\n",
      "PrepMatrixNo        109051 non-null object\n",
      "PrepMatrixLot       108181 non-null object\n",
      "PrepInits           107939 non-null object\n",
      "PrepMemo            61620 non-null object\n",
      "PrepNotebookRef     48969 non-null object\n",
      "BulkQCStatus        24 non-null object\n",
      "BulkQCDate          75420 non-null datetime64[ns]\n",
      "BulkPassFail        74496 non-null object\n",
      "BulkQCInits         75404 non-null object\n",
      "BulkQCMemo          2150 non-null object\n",
      "BulkLotNo           73751 non-null object\n",
      "AmpRetains          52013 non-null float64\n",
      "AmpDate             93140 non-null datetime64[ns]\n",
      "AmpPreLabel         109126 non-null bool\n",
      "AmpNumberGood       93467 non-null float64\n",
      "AmpNumberBad        77772 non-null float64\n",
      "AmpBulkRemain       4364 non-null float64\n",
      "AmpTimeIn           92897 non-null datetime64[ns]\n",
      "AmpTimeOut          92897 non-null datetime64[ns]\n",
      "AmpInits            93105 non-null object\n",
      "QCStatus            573 non-null object\n",
      "QCDate              103600 non-null datetime64[ns]\n",
      "QCPassFail          103788 non-null object\n",
      "QCAuthInits         103587 non-null object\n",
      "QCMemo              55530 non-null object\n",
      "QCMethod            1205 non-null object\n",
      "LotNo               100882 non-null object\n",
      "QCExpMonth          93768 non-null float64\n",
      "QCExpDate           92207 non-null datetime64[ns]\n",
      "QCSellBy            0 non-null object\n",
      "QCFullValidation    109126 non-null bool\n",
      "QCValidation        109092 non-null float64\n",
      "FgInvCount          78334 non-null float64\n",
      "FgAccpacNote        19730 non-null object\n",
      "CofAHeaderNo        109094 non-null float64\n",
      "QCChromatogram      0 non-null object\n",
      "Correct             109126 non-null bool\n",
      "DoNotCorrect        109126 non-null bool\n",
      "DensityUnit         0 non-null object\n",
      "DensityTemp         0 non-null object\n",
      "recipeid            1 non-null object\n",
      "dtypes: bool(4), datetime64[ns](7), float64(11), int64(1), object(30)\n",
      "memory usage: 41.2+ MB\n",
      "None\n",
      "Operation Completed Successfully...\n",
      "            ProductID      ProductNo               ProductName  LineID  \\\n",
      "QCDate                                                                   \n",
      "2012-09-05     5420.0    01080-68703           Gradient Sample     7.0   \n",
      "2013-10-31     5420.0    01080-68703           Gradient Sample     7.0   \n",
      "2012-04-26     5420.0    01080-68703           Gradient Sample     7.0   \n",
      "2012-04-26     5420.0    01080-68703           Gradient Sample     7.0   \n",
      "2009-12-04     5420.0    01080-68703           Gradient Sample     7.0   \n",
      "...               ...            ...                       ...     ...   \n",
      "2012-01-17    50108.0  ZX-TESTMIX-01  GC x GC Testing Solution     7.0   \n",
      "2016-03-11    50108.0  ZX-TESTMIX-01  GC x GC Testing Solution     7.0   \n",
      "2018-02-20    50108.0  ZX-TESTMIX-01  GC x GC Testing Solution     7.0   \n",
      "2018-02-20    50108.0  ZX-TESTMIX-01  GC x GC Testing Solution     7.0   \n",
      "2019-06-10    50108.0  ZX-TESTMIX-01  GC x GC Testing Solution     7.0   \n",
      "\n",
      "           Description     Specials OriginationDate  EntryDate Status  \\\n",
      "QCDate                                                                  \n",
      "2012-09-05        None  01080-68703      1998-02-04 2011-05-09    oem   \n",
      "2013-10-31        None  01080-68703      1998-02-04 2011-05-09    oem   \n",
      "2012-04-26        None  01080-68703      1998-02-04 2011-05-09    oem   \n",
      "2012-04-26        None  01080-68703      1998-02-04 2011-05-09    oem   \n",
      "2009-12-04        None  01080-68703      1998-02-04 2011-05-09    oem   \n",
      "...                ...          ...             ...        ...    ...   \n",
      "2012-01-17        None         None      2011-04-19 2011-05-09   None   \n",
      "2016-03-11        None         None      2011-04-19 2011-05-09   None   \n",
      "2018-02-20        None         None      2011-04-19 2011-05-09   None   \n",
      "2018-02-20        None         None      2011-04-19 2011-05-09   None   \n",
      "2019-06-10        None         None      2011-04-19 2011-05-09   None   \n",
      "\n",
      "           MatrixNumber  ...  QCValidation FgInvCount  \\\n",
      "QCDate                   ...                            \n",
      "2012-09-05      JHP-021  ...           2.0     2600.0   \n",
      "2013-10-31      JHP-021  ...           2.0     2123.0   \n",
      "2012-04-26      JHP-021  ...           2.0     3400.0   \n",
      "2012-04-26      JHP-021  ...           2.0     1563.0   \n",
      "2009-12-04      JHP-021  ...           2.0     1156.0   \n",
      "...                 ...  ...           ...        ...   \n",
      "2012-01-17      JHP-031  ...           2.0      129.0   \n",
      "2016-03-11      JHP-031  ...           2.0      602.0   \n",
      "2018-02-20      JHP-031  ...           2.0      366.0   \n",
      "2018-02-20      JHP-031  ...           2.0      320.0   \n",
      "2019-06-10      JHP-031  ...           2.0      320.0   \n",
      "\n",
      "                                      FgAccpacNote CofAHeaderNo  \\\n",
      "QCDate                                                            \n",
      "2012-09-05                                    None          2.0   \n",
      "2013-10-31                                    None          2.0   \n",
      "2012-04-26                                    None          2.0   \n",
      "2012-04-26                                 back up          2.0   \n",
      "2009-12-04       zero out ce-3778 (1390) stability          2.0   \n",
      "...                                            ...          ...   \n",
      "2012-01-17                                    None          2.0   \n",
      "2016-03-11                                    None          2.0   \n",
      "2018-02-20                                    None          2.0   \n",
      "2018-02-20                                    None          2.0   \n",
      "2019-06-10  purge cs-0774 (70) cp-1554a (5) retain          2.0   \n",
      "\n",
      "           QCChromatogram Correct  DoNotCorrect DensityUnit DensityTemp  \\\n",
      "QCDate                                                                    \n",
      "2012-09-05           None   False         False        None        None   \n",
      "2013-10-31           None   False         False        None        None   \n",
      "2012-04-26           None   False          True        None        None   \n",
      "2012-04-26           None   False          True        None        None   \n",
      "2009-12-04           None   False          True        None        None   \n",
      "...                   ...     ...           ...         ...         ...   \n",
      "2012-01-17           None   False          True        None        None   \n",
      "2016-03-11           None   False         False        None        None   \n",
      "2018-02-20           None   False         False        None        None   \n",
      "2018-02-20           None   False         False        None        None   \n",
      "2019-06-10           None   False         False        None        None   \n",
      "\n",
      "           recipeid  \n",
      "QCDate               \n",
      "2012-09-05     None  \n",
      "2013-10-31     None  \n",
      "2012-04-26     None  \n",
      "2012-04-26     None  \n",
      "2009-12-04     None  \n",
      "...             ...  \n",
      "2012-01-17     None  \n",
      "2016-03-11     None  \n",
      "2018-02-20     None  \n",
      "2018-02-20     None  \n",
      "2019-06-10     None  \n",
      "\n",
      "[85083 rows x 93 columns]\n",
      "DatetimeIndex(['2012-09-05', '2013-10-31', '2012-04-26', '2012-04-26',\n",
      "               '2009-12-04', '2008-07-02', '2005-03-02', '2003-08-21',\n",
      "               '2003-08-05', '2002-08-12',\n",
      "               ...\n",
      "               '2018-04-06', '2017-06-14', '2017-07-03', '2012-01-19',\n",
      "               '2013-10-17', '2012-01-17', '2016-03-11', '2018-02-20',\n",
      "               '2018-02-20', '2019-06-10'],\n",
      "              dtype='datetime64[ns]', name='QCDate', length=85083, freq=None)\n",
      "SORTED:\n",
      "\n",
      "DatetimeIndex(['1991-01-01', '1991-01-01', '1991-01-01', '1992-01-01',\n",
      "               '1992-01-01', '1992-01-01', '1992-01-02', '1992-04-07',\n",
      "               '1993-07-28', '1994-08-24',\n",
      "               ...\n",
      "               '2020-03-19', '2020-03-19', '2020-03-19', '2020-03-19',\n",
      "               '2020-03-19', '2020-03-19', '2020-03-19', '2020-03-19',\n",
      "               '2020-03-19', '2020-03-19'],\n",
      "              dtype='datetime64[ns]', name='QCDate', length=85083, freq=None)\n",
      "<<<<< df_level_1s >>>>\n",
      "           ProductID        LineID    Components  ExpirationDate  \\\n",
      "count   20310.000000  20310.000000  20310.000000    20310.000000   \n",
      "mean    61204.609650      6.265387      6.735549       23.637322   \n",
      "std     35170.606308      4.374576     10.290738       15.501505   \n",
      "min        36.000000      1.000000      0.000000        0.000000   \n",
      "25%     31306.500000      1.000000      1.000000       12.000000   \n",
      "50%     64829.000000      7.000000      2.000000       24.000000   \n",
      "75%     92773.000000      7.000000      9.000000       24.000000   \n",
      "max    113596.000000     22.000000     96.000000       96.000000   \n",
      "\n",
      "         CofAHeader  ProductLevel         PfIDNo          OrdID    PrepVolume  \\\n",
      "count  19823.000000  20310.000000   20310.000000   20263.000000  2.031000e+04   \n",
      "mean       0.885638      1.476120  138202.060512   91861.168534  1.964419e+04   \n",
      "std        2.905828      0.562501   12223.043890   10031.058530  1.682142e+05   \n",
      "min        0.000000      0.000000     996.000000       0.000000  1.000000e-02   \n",
      "25%        0.000000      1.000000  132903.250000   86119.500000  5.000000e+01   \n",
      "50%        0.000000      1.000000  139670.500000   93008.000000  1.000000e+02   \n",
      "75%        1.000000      2.000000  145987.750000   99469.500000  5.000000e+02   \n",
      "max       84.000000      3.000000  152132.000000  105861.000000  2.000000e+06   \n",
      "\n",
      "         PrepVessel   AmpRetains  AmpNumberGood  AmpNumberBad  AmpBulkRemain  \\\n",
      "count  20310.000000  8316.000000   1.986600e+04  15085.000000    1314.000000   \n",
      "mean       1.186657     4.811929   2.632987e+03      6.383825     629.213090   \n",
      "std        0.646385     0.899245   5.309436e+04     13.938755    3134.872173   \n",
      "min        1.000000     0.000000   0.000000e+00      0.000000       0.000000   \n",
      "25%        1.000000     5.000000   1.100000e+01      3.000000      40.000000   \n",
      "50%        1.000000     5.000000   3.200000e+01      5.000000      60.000000   \n",
      "75%        1.000000     5.000000   7.100000e+01      8.000000     180.000000   \n",
      "max        4.000000    15.000000   2.000000e+06   1100.000000   50000.000000   \n",
      "\n",
      "         QCExpMonth  QCValidation    FgInvCount  CofAHeaderNo  \n",
      "count  20305.000000  20310.000000  1.986800e+04  20310.000000  \n",
      "mean      23.441911      1.537125  2.630121e+03      1.829591  \n",
      "std       15.434902      0.529754  5.309063e+04      1.865105  \n",
      "min        0.000000      0.000000  0.000000e+00      1.000000  \n",
      "25%       12.000000      1.000000  1.100000e+01      1.000000  \n",
      "50%       24.000000      2.000000  3.200000e+01      2.000000  \n",
      "75%       24.000000      2.000000  7.100000e+01      2.000000  \n",
      "max       96.000000      3.000000  2.000000e+06     15.000000  \n",
      "Operation Completed Successfully...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": # {\n",
    "    test_metrics = QC_Metrics_AvgTurnAround(the_logger=None)\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
