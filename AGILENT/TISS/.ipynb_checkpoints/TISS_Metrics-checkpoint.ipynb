{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T16:29:27.053103Z",
     "start_time": "2020-03-10T16:29:24.389997Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import pyodbc\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.drawing.image import Image\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import tempfile\n",
    "from ttkthemes import ThemedStyle\n",
    "import tkinter as tk\n",
    "import tkinter.ttk as ttk\n",
    "from tkinter import messagebox, filedialog, commondialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TISS_Metrics(): # {\n",
    "    \n",
    "    user_name = str(os.getlogin())\n",
    "    outbound_dir = \"C:/data/outbound/\"\n",
    "    desktop_dir = \"OneDrive - Agilent Technologies/Desktop\"\n",
    "    \n",
    "    def __init__(self, the_logger): # {\n",
    "        self.the_logger = the_logger\n",
    "        # Get/Set USERNAME & DESKTOP DIRECTORIES\n",
    "        self.user_name_dir = os.path.join(\"C:/Users/\", self.user_name)\n",
    "        self.desktop_dir = os.path.join(self.user_name_dir, self.desktop_dir)\n",
    "        print(self.user_name_dir)\n",
    "        print(self.desktop_dir)\n",
    "        self.run(day_range=30)\n",
    "    # }\n",
    "    \n",
    "    def run(self, day_range): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # [2020-02-28]\\\\self.time_unit = time_unit\n",
    "            # [2020-02-28]\\\\self.time_value = time_value\n",
    "            self.day_range = day_range\n",
    "            # get/set current date variable\n",
    "            # [2020-03-06]\\\\the_date = pd.Timestamp.now()\n",
    "            # [2020-03-11]\\\\the_date = pd.Timestamp(ts_input=str(self.end_date.get()))\n",
    "            the_date = pd.Timestamp.now()\n",
    "            # create variable for a month ago\n",
    "            one_month_ago = the_date - timedelta(days = int(day_range))\n",
    "            # [2020-02-28]\\\\\n",
    "            ##one_month_ago = the_date - pd.Timedelta(unit=str(self.time_unit), value=str(self.time_value))\n",
    "            print(type(one_month_ago))\n",
    "            # CREATE METRICS TABLE FROM CLASS METHOD\n",
    "            self.df_metrics_table = self.create_metrics_table()\n",
    "            #############################\n",
    "            # create .csv with no drops #\n",
    "            #############################\n",
    "            \"\"\"\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_metrics_noDrop.csv\"), \n",
    "                                         index=True)\n",
    "            # DROP ROWS WITH PRODUCT LEVEL && QCDATE = NONE\n",
    "            self.df_metrics_table.dropna(axis=0, subset=['QCDate', 'ProductLevel'], how='any', \n",
    "                                         inplace=True)\n",
    "            # create .csv with DROPS\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_metrics_DROP.csv\"), \n",
    "                                         index=True)\n",
    "            \"\"\"\n",
    "            # Set index of METRICS\n",
    "            # [2020-03-11]\\\\self.df_metrics_table.set_index(['QCDate'], inplace=True)\n",
    "            self.df_metrics_table.index = self.df_metrics_table['QCDate']\n",
    "            del self.df_metrics_table['QCDate']\n",
    "            print(self.df_metrics_table)\n",
    "            # Display Index\n",
    "            print(self.df_metrics_table.index)\n",
    "            #############################\n",
    "            # create .csv with UNSORTED #\n",
    "            #############################\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_metrics_UNSORTED.csv\"), \n",
    "                                         index=True)\n",
    "            # SORT INDEX\n",
    "            self.df_metrics_table.sort_index(inplace=True)\n",
    "            ###########################\n",
    "            # create .csv with SORTED #\n",
    "            ###########################\n",
    "            self.df_metrics_table.to_csv(os.path.join(self.outbound_dir, \"df_metrics_SORTED.csv\"), \n",
    "                                         index=True)\n",
    "            print(\"SORTED:\\n\")\n",
    "            print(self.df_metrics_table.index)\n",
    "            # SLICE & DICE THE DATAFRAME\n",
    "            # [2020-03-11]\\\\self.df_level_1s = self.df_metrics_table.loc['2017-01-02']\n",
    "            print(\"<<<<< df_level_1s >>>>>\\n\\t\" + str(self.df_metrics_table.loc['2017-01-02']))\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "    \"\"\"\n",
    "    Referred to as \"ProdflowII\" in SQL-Server\n",
    "    \"\"\"\n",
    "    def pull_ProdflowII_table(self, table_name): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # CREATION CONNECTION STR\n",
    "            conn_str = str(\n",
    "                r'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "                r'SERVER=wtkngappflow1.is.agilent.net;'\n",
    "                r'DATABASE=ProdFlowII_Prod;'\n",
    "                r'Trusted_Connection=yes;'\n",
    "            )\n",
    "            # CREATE PYODBC CONNECTION\n",
    "            cnxn_ProdflowII = pyodbc.connect(conn_str)\n",
    "            # [2020-02-028]\\\\crsr_ProdflowII = cnxn_ProdflowII.cursor()\n",
    "            # PERFORM SQL QUERY AND SET AS DATAFRAME\n",
    "            df_ProdflowII_table = pd.read_sql_query(sql='SELECT * FROM ' + str(table_name),\n",
    "                                                    con=cnxn_ProdflowII\n",
    "                                                    )\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "            return df_ProdflowII_table\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "    \"\"\"\n",
    "    Referred to as \"Prodflow\" in SQL-Server\n",
    "    \"\"\"\n",
    "    def pull_ProdflowIII_table(self, table_name): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # CREATE CONNECTION STRING\n",
    "            conn_str = str(\n",
    "                r'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "                r'SERVER=wtkngappflow1.is.agilent.net;'\n",
    "                r'DATABASE=ProdFlow;'\n",
    "                r'Trusted_Connection=yes;'\n",
    "            )\n",
    "            # CREATE PYODBC CONNECTION\n",
    "            cnxn_ProdflowIII = pyodbc.connect(conn_str)\n",
    "            # [2020-02-28]\\\\crsr_ProdflowIII = cnxn_ProdflowIII,cursor()\n",
    "            # PERFORM SQL QUERY AND SET AS DATAFRAME\n",
    "            df_ProdflowIII_table = pd.read_sql_query(sql='SELECT * FROM ' + str(table_name),\n",
    "                                                     con=cnxn_ProdflowIII,\n",
    "                                                     parse_dates=['QCDate']\n",
    "                                                     )\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        # }\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "            return df_ProdflowIII_table\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "    def create_metrics_table(self): # {\n",
    "        # TRY THE FOLLOWING\n",
    "        try: # {\n",
    "            # pull ORDERS table\n",
    "            self.df_orders = self.pull_ProdflowII_table(table_name='Orders')\n",
    "            # [2020-03-11]\\\\export_path = os.path.join(self.outbound_dir, \"df_orders.csv\")\n",
    "            # [2020-03-11]\\\\self.df_orders.to_csv(export_path, index=True)\n",
    "            # RENAME ['Product#'] column to [\"ProductNo\"]\n",
    "            self.df_orders.rename(columns={'Product#': 'ProductNo'}, inplace=True)\n",
    "            print(\"\\tORDERS-TABLE:\\n\" + str(self.df_orders.info()))\n",
    "            # pull tblProdflow TABLE\n",
    "            self.df_tblProdflow = self.pull_ProdflowIII_table(table_name='tblProdflow')\n",
    "            print(self.df_tblProdflow.info())\n",
    "            ########################\n",
    "            # CREATE METRICS TABLE #\n",
    "            ########################\n",
    "            df_metrics_table = pd.merge(self.df_orders, self.df_tblProdflow, on='ProductNo', how='right')\n",
    "            ######################\n",
    "            # CHANGE DATA TYPES: #\n",
    "            ######################\n",
    "            \n",
    "            # CHANGE ['QCDate'] COLUMN TO DATETIME\n",
    "            df_metrics_table['QCDate'] = pd.to_datetime(df_metrics_table['QCDate'])\n",
    "            ####################################\n",
    "            # DROP ALL ROWS WITHOUT A 'QCDATE' #\n",
    "            ####################################\n",
    "            df_metrics_table.dropna(axis=0, subset=['QCDate'],\n",
    "                                   how='any', inplace=True)\n",
    "        # }\n",
    "        except: # {\n",
    "            errorMessage = str(sys.exc_info()[0]) + \"\\n\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[1]) + \"\\n\\t\\t\"\n",
    "            errorMessage = errorMessage + str(sys.exc_info()[2]) + \"\\n\"\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            typeE = str(\"TYPE : \" + str(exc_type))\n",
    "            fileE = str(\"FILE : \" + str(fname))\n",
    "            lineE = str(\"LINE : \" + str(exc_tb.tb_lineno))\n",
    "            messageE = str(\"MESG : \" + \"\\n\\n\" + str(errorMessage) + \"\\n\")\n",
    "            print(\"\\n\" + typeE + \n",
    "                  \"\\n\" + fileE + \n",
    "                  \"\\n\" + lineE + \n",
    "                  \"\\n\" + messageE)\n",
    "        #}\n",
    "        else: # {\n",
    "            print(\"Operation Completed Successfully...\")\n",
    "            return df_metrics_table\n",
    "        # }\n",
    "    # }\n",
    "    \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/derbates\n",
      "C:/Users/derbates\\OneDrive - Agilent Technologies/Desktop\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "Operation Completed Successfully...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 106214 entries, 0 to 106213\n",
      "Data columns (total 28 columns):\n",
      "OrderID            106214 non-null int64\n",
      "Quote#             106208 non-null object\n",
      "ProductNo          106214 non-null object\n",
      "LineID             106205 non-null float64\n",
      "Quantity           106145 non-null float64\n",
      "SaleUnit           94690 non-null object\n",
      "Company            105948 non-null object\n",
      "Volume             105948 non-null float64\n",
      "VolUnit            40636 non-null object\n",
      "OrderDate          106208 non-null datetime64[ns]\n",
      "BuildByDate        105667 non-null object\n",
      "ShipNLTDate        105633 non-null object\n",
      "Route              106213 non-null float64\n",
      "FullValidation     106214 non-null bool\n",
      "Validation         75760 non-null float64\n",
      "Built              106214 non-null bool\n",
      "GreenSheet         78063 non-null object\n",
      "Notes              32466 non-null object\n",
      "Completed          106214 non-null bool\n",
      "SOLink             31699 non-null object\n",
      "UserFormulation    32182 non-null object\n",
      "UserUnitizing      0 non-null object\n",
      "UserBulkQC         0 non-null object\n",
      "UserQC             0 non-null object\n",
      "EquipShort         2 non-null object\n",
      "UnitizeNLT         35110 non-null object\n",
      "SpecialPrep        106214 non-null bool\n",
      "RushPriority       106214 non-null bool\n",
      "dtypes: bool(5), datetime64[ns](1), float64(5), int64(1), object(16)\n",
      "memory usage: 19.1+ MB\n",
      "\tORDERS-TABLE:\n",
      "None\n",
      "Operation Completed Successfully...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108945 entries, 0 to 108944\n",
      "Data columns (total 53 columns):\n",
      "PfIDNo              108945 non-null int64\n",
      "PfBatchID           108945 non-null object\n",
      "ProductNo           108926 non-null object\n",
      "OrdID               92813 non-null float64\n",
      "QuoteNo             108909 non-null object\n",
      "PfSentTo            108880 non-null object\n",
      "PrepDate            107927 non-null datetime64[ns]\n",
      "PrepVolume          108900 non-null float64\n",
      "PrepUnit            108869 non-null object\n",
      "PrepVessel          108866 non-null float64\n",
      "PrepVBarcode        58258 non-null object\n",
      "PrdSaleUnit         89688 non-null object\n",
      "PrepMatrixNo        108870 non-null object\n",
      "PrepMatrixLot       108001 non-null object\n",
      "PrepInits           107759 non-null object\n",
      "PrepMemo            61488 non-null object\n",
      "PrepNotebookRef     48969 non-null object\n",
      "BulkQCStatus        24 non-null object\n",
      "BulkQCDate          75264 non-null datetime64[ns]\n",
      "BulkPassFail        74353 non-null object\n",
      "BulkQCInits         75248 non-null object\n",
      "BulkQCMemo          2132 non-null object\n",
      "BulkLotNo           73608 non-null object\n",
      "AmpRetains          51962 non-null float64\n",
      "AmpDate             92982 non-null datetime64[ns]\n",
      "AmpPreLabel         108945 non-null bool\n",
      "AmpNumberGood       93308 non-null float64\n",
      "AmpNumberBad        77652 non-null float64\n",
      "AmpBulkRemain       4281 non-null float64\n",
      "AmpTimeIn           92738 non-null datetime64[ns]\n",
      "AmpTimeOut          92738 non-null datetime64[ns]\n",
      "AmpInits            92946 non-null object\n",
      "QCStatus            573 non-null object\n",
      "QCDate              103432 non-null datetime64[ns]\n",
      "QCPassFail          103622 non-null object\n",
      "QCAuthInits         103421 non-null object\n",
      "QCMemo              55454 non-null object\n",
      "QCMethod            1199 non-null object\n",
      "LotNo               100718 non-null object\n",
      "QCExpMonth          93587 non-null float64\n",
      "QCExpDate           92044 non-null datetime64[ns]\n",
      "QCSellBy            0 non-null object\n",
      "QCFullValidation    108945 non-null bool\n",
      "QCValidation        108911 non-null float64\n",
      "FgInvCount          78175 non-null float64\n",
      "FgAccpacNote        19676 non-null object\n",
      "CofAHeaderNo        108913 non-null float64\n",
      "QCChromatogram      0 non-null object\n",
      "Correct             108945 non-null bool\n",
      "DoNotCorrect        108945 non-null bool\n",
      "DensityUnit         0 non-null object\n",
      "DensityTemp         0 non-null object\n",
      "recipeid            1 non-null object\n",
      "dtypes: bool(4), datetime64[ns](7), float64(11), int64(1), object(30)\n",
      "memory usage: 41.1+ MB\n",
      "None\n",
      "Operation Completed Successfully...\n",
      "            OrderID     Quote#    ProductNo  LineID  Quantity  \\\n",
      "QCDate                                                          \n",
      "2005-04-08      2.0  021004-27     CUS-5465     7.0      10.0   \n",
      "2005-04-08   3420.0  040405-54     CUS-5465     7.0       4.0   \n",
      "2004-04-13      2.0  021004-27     CUS-5465     7.0      10.0   \n",
      "2004-04-13   3420.0  040405-54     CUS-5465     7.0       4.0   \n",
      "2004-04-12      4.0  031504-11     CUS-5459     7.0      10.0   \n",
      "...             ...        ...          ...     ...       ...   \n",
      "2019-04-11      NaN        NaN  5190-0484-a     NaN       NaN   \n",
      "2019-10-04      NaN        NaN       BULK-2     NaN       NaN   \n",
      "2019-12-17      NaN        NaN      JHP-683     NaN       NaN   \n",
      "2020-02-05      NaN        NaN      JHP-327     NaN       NaN   \n",
      "2020-03-11      NaN        NaN      JHP-327     NaN       NaN   \n",
      "\n",
      "                                             SaleUnit  \\\n",
      "QCDate                                                  \n",
      "2005-04-08  1 mL in 2 mL Flame-Sealed Amber Ampule(s)   \n",
      "2005-04-08          1 mL Flame-Sealed Amber Ampule(s)   \n",
      "2004-04-13  1 mL in 2 mL Flame-Sealed Amber Ampule(s)   \n",
      "2004-04-13          1 mL Flame-Sealed Amber Ampule(s)   \n",
      "2004-04-12          1 mL Flame-Sealed Amber Ampule(s)   \n",
      "...                                               ...   \n",
      "2019-04-11                                        NaN   \n",
      "2019-10-04                                        NaN   \n",
      "2019-12-17                                        NaN   \n",
      "2020-02-05                                        NaN   \n",
      "2020-03-11                                        NaN   \n",
      "\n",
      "                               Company  Volume VolUnit  OrderDate  ...  \\\n",
      "QCDate                                                             ...   \n",
      "2005-04-08  Missouri American Water Co   850.0      mL 2014-05-05  ...   \n",
      "2005-04-08     Missouri American Water    25.0      mL 2005-04-05  ...   \n",
      "2004-04-13  Missouri American Water Co   850.0      mL 2014-05-05  ...   \n",
      "2004-04-13     Missouri American Water    25.0      mL 2005-04-05  ...   \n",
      "2004-04-12  Carnegie Mellon University    25.0      mL 2004-04-07  ...   \n",
      "...                                ...     ...     ...        ...  ...   \n",
      "2019-04-11                         NaN     NaN     NaN        NaT  ...   \n",
      "2019-10-04                         NaN     NaN     NaN        NaT  ...   \n",
      "2019-12-17                         NaN     NaN     NaN        NaT  ...   \n",
      "2020-02-05                         NaN     NaN     NaN        NaT  ...   \n",
      "2020-03-11                         NaN     NaN     NaN        NaT  ...   \n",
      "\n",
      "           QCValidation FgInvCount  FgAccpacNote CofAHeaderNo  QCChromatogram  \\\n",
      "QCDate                                                                          \n",
      "2005-04-08          1.0       16.0          None          1.0            None   \n",
      "2005-04-08          1.0       16.0          None          1.0            None   \n",
      "2004-04-13          1.0        NaN          None          1.0            None   \n",
      "2004-04-13          1.0        NaN          None          1.0            None   \n",
      "2004-04-12          1.0        NaN          None          1.0            None   \n",
      "...                 ...        ...           ...          ...             ...   \n",
      "2019-04-11          2.0       65.0          None          2.0            None   \n",
      "2019-10-04          2.0     2000.0    blue sheet          2.0            None   \n",
      "2019-12-17          1.0        NaN     no action         15.0            None   \n",
      "2020-02-05          1.0        NaN     no action         15.0            None   \n",
      "2020-03-11          1.0        NaN          None         15.0            None   \n",
      "\n",
      "           Correct DoNotCorrect DensityUnit DensityTemp recipeid  \n",
      "QCDate                                                            \n",
      "2005-04-08   False         True        None        None     None  \n",
      "2005-04-08   False         True        None        None     None  \n",
      "2004-04-13   False         True        None        None     None  \n",
      "2004-04-13   False         True        None        None     None  \n",
      "2004-04-12   False         True        None        None     None  \n",
      "...            ...          ...         ...         ...      ...  \n",
      "2019-04-11   False        False        None        None     None  \n",
      "2019-10-04   False        False        None        None     None  \n",
      "2019-12-17   False         True        None        None     None  \n",
      "2020-02-05   False         True        None        None     None  \n",
      "2020-03-11   False         True        None        None     None  \n",
      "\n",
      "[1782344 rows x 79 columns]\n",
      "DatetimeIndex(['2005-04-08', '2005-04-08', '2004-04-13', '2004-04-13',\n",
      "               '2004-04-12', '2012-03-14', '2012-03-14', '2012-03-14',\n",
      "               '2012-03-14', '2012-03-14',\n",
      "               ...\n",
      "               '2019-02-01', '2019-07-03', '2019-02-19', '2019-02-28',\n",
      "               '2019-03-04', '2019-04-11', '2019-10-04', '2019-12-17',\n",
      "               '2020-02-05', '2020-03-11'],\n",
      "              dtype='datetime64[ns]', name='QCDate', length=1782344, freq=None)\n",
      "SORTED:\n",
      "\n",
      "DatetimeIndex(['1987-01-01', '1987-01-01', '1989-01-01', '1991-01-01',\n",
      "               '1991-01-01', '1991-01-01', '1991-01-01', '1992-01-01',\n",
      "               '1992-01-01', '1992-01-01',\n",
      "               ...\n",
      "               '2020-03-11', '2020-03-11', '2020-03-11', '2020-03-11',\n",
      "               '2020-03-11', '2020-03-11', '2020-03-11', '2020-03-11',\n",
      "               '2020-03-11', '2020-03-11'],\n",
      "              dtype='datetime64[ns]', name='QCDate', length=1782344, freq=None)\n",
      "\n",
      "TYPE : <class 'KeyError'>\n",
      "FILE : <ipython-input-2-86cc8b21139d>\n",
      "LINE : 69\n",
      "MESG : \n",
      "\n",
      "<class 'KeyError'>\n",
      "'2017-01-02'\n",
      "\t\t<traceback object at 0x00000195C5783408>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": # {\n",
    "    test_metrics = TISS_Metrics(the_logger=None)\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
